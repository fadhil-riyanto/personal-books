<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"
      xmlns:og="http://ogp.me/ns#"
      xmlns:fb="https://www.facebook.com/2008/fbml">

<!-- Mirrored from eli.thegreenplace.net/2018/the-confusion-matrix-in-statistical-tests/ by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 16 Feb 2025 23:58:35 GMT -->
<head>
    <title>The Confusion Matrix in statistical tests - Eli Bendersky's website</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link href="../../favicon.ico" rel="icon">

    <!-- Bootstrap -->
        <link rel="stylesheet" href="../../theme/css/bootstrap.min.css" type="text/css"/>
    <link href="../../theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="../../theme/css/pygments/vs.css" rel="stylesheet">
    <link rel="stylesheet" href="../../theme/css/style.css" type="text/css"/>

        <link href="../../feeds/all.atom.xml" type="application/atom+xml" rel="alternate"
              title="Eli Bendersky's website ATOM Feed"/>

</head>
<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="../../index.html" class="navbar-brand">
                <img src="../../images/logosmall.png" width="32" height="32"/>
Eli Bendersky's website            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="../../pages/about.html">
                        <i class="fa fa-question"></i>
                        <span class="icon-label">About</span>
                    </a>
                </li>
                <li>
                    <a href="../../pages/projects.html">
                        <i class="fa fa-github"></i>
                        <span class="icon-label">Projects</span>
                    </a>
                </li>
                <li>
                    <a href="../../archives/all.html">
                        <i class="fa fa-th-list"></i>
                        <span class="icon-label">Archives</span>
                    </a>
                </li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->

<div class="container">
    <div class="row">
    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="index.html"
                       rel="bookmark"
                       title="Permalink to The Confusion Matrix in statistical tests">
                        The Confusion Matrix in statistical tests
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="published">
        <i class="fa fa-calendar"></i>
        <time> March 26, 2018 at 05:47</time>
    </span>
<span class="label label-default">Tags</span>
    <a href="../../tag/math.html">Math</a>
</footer><!-- /.post-info -->                    </div>
                </div>
                <p>This winter was one of the worst flu seasons in recent years, so I found myself
curious to learn more about the diagnostic flu tests available to doctors in
addition to the usual &quot;looks like bad cold but no signs of bacteria&quot; strategy.
There's a wide array of RIDTs (Rapid Influenza Dignostic Tests) available to
doctors today <a class="footnote-reference" href="#footnote-1" id="footnote-reference-1">[1]</a>, and reading through literature quickly gets you to decipher
statements like:</p>
<blockquote>
Overall, RIDTs had a modest <em>sensitivity</em> of 62.3% and a high <em>specificity</em> of
98.2%, corresponding to a <em>positive likelihood ratio</em> of 34.5 and a <em>negative
likelihood ratio of 0.38</em>. For the clinician, this means that although
<em>false-negatives</em> are frequent (occurring in nearly four out of ten negative
RIDTs), a positive test is unlikely to be a <em>false-positive</em> result. A
diagnosis of influenza can thus confidently be made in the presence of a
positive RIDT. However, a negative RIDT result is unreliable and should be
confirmed by traditional diagnostic tests if the result is likely to affect
patient management.</blockquote>
<p>While I heard about statistical test quality measures like <em>sensitivity</em> before,
there are too many terms here to remember for someone not dealing with these
things routinely; this post is my attempt at documenting this understanding for
future use.</p>
<div class="section" id="a-table-of-test-outcomes">
<h2>A table of test outcomes</h2>
<p>Let's say there is a condition with a binary outcome (&quot;yes&quot; vs. &quot;no&quot;, 1 vs 0, or
whatever you want to call it). Suppose we conduct a test that is designed to
detect this condition; the test also has a binary outcome. The totality of
outcomes can thus be represented with a 2-by-2 table, which is also called the
<a class="reference external" href="https://en.wikipedia.org/wiki/Confusion_matrix">Confusion Matrix</a>.</p>
<p>Suppose 10000 patients get tested for flu; out of them, 9000 are actually
healthy and 1000 are actually sick. For the sick people, a test was positive for
620 and negative for 380. For the healthy people, the same test was positive for
180 and negative for 8820. Let's summarize these results in a table:</p>
<img alt="Confusion matrix with numbers only" class="align-center" src="../../images/2018/confusionmatrix.png" />
<p>Now comes our first batch of definitions.</p>
<ul class="simple">
<li><strong>True Positive (TP)</strong>: positive test result matches reality - person is
actually sick and tested positive.</li>
<li><strong>False Positive (FP)</strong>: positive test result doesn't match reality - test is
positive but the person is not actually sick.</li>
<li><strong>True Negative (TN)</strong>: negative test result matches reality - person is not
sick and tested negative.</li>
<li><strong>False Negative (FN)</strong>: negative test result doesn't match reality - test is
negative but the person is actually sick.</li>
</ul>
<p>Folks get confused with these often, so here's a useful heuristic: positive vs.
negative reflects the test outcome; true vs. false reflects whether the test got
it right or got it wrong.</p>
<p>Since the rest of the definitions build upon these, here's the confusion matrix
again now with them embedded:</p>
<img alt="Confusion matrix with TP, FP, TN, FN marked" class="align-center" src="../../images/2018/confusionmatrix-tptnfpfn.png" />
</div>
<div class="section" id="definition-soup">
<h2>Definition soup</h2>
<p>Armed with these and <strong>N</strong> for the <em>total population</em> (10000 in our case), we
are now ready to tackle the multitude of definitions statisticians have produced
over the years to describe the performance of tests:</p>
<ul class="simple">
<li><strong>Prevalence</strong>: how common is the actual disease in the population<ul>
<li>(FN+TP)/N</li>
<li>In the example: (380+620)/10000=0.1</li>
</ul>
</li>
<li><strong>Accuracy</strong>: how often is the test correct<ul>
<li>(TP+TN)/N</li>
<li>In the example: (620+8820)/10000=0.944</li>
</ul>
</li>
<li><strong>Misclassification rate</strong>: how often the test is wrong<ul>
<li>1 - Accuracy = (FP+FN)/N</li>
<li>In the example: (180+380)/10000=0.056</li>
</ul>
</li>
<li><strong>Sensitivity</strong> or <strong>True Positive Rate (TPR)</strong> or <strong>Recall</strong>: when the
patient is sick, how often does the test actually predict it correctly<ul>
<li>TP/(TP+FN)</li>
<li>In the example: 620/(620+380)=0.62</li>
</ul>
</li>
<li><strong>Specificity</strong> or <strong>True Negative Rate (TNR)</strong>: when the patient is not sick,
how often does the test actually predict it correctly<ul>
<li>TN/(TN+FP)</li>
<li>In the example: 8820/(8820+180)=0.98</li>
</ul>
</li>
<li><strong>False Positive Rate (FPR)</strong>: probability of false alarm<ul>
<li>1 - Specificity = FP/(TN+FP)</li>
<li>In the example: 180/(8820+180)=0.02</li>
</ul>
</li>
<li><strong>False Negative Rage (FNR)</strong>: miss rate, probability of missing a sickness
with a test<ul>
<li>1 - Sensitivity = FN/(TP+FN)</li>
<li>In the example: 380/(620+380)=0.38</li>
</ul>
</li>
<li><strong>Precision</strong> or <strong>Positive Predictive Value (PPV)</strong>: when the prediction
is positive, how often is it correct<ul>
<li>TP/(TP+FP)</li>
<li>In the example: 620/(620+180)=0.775</li>
</ul>
</li>
<li><strong>Negative Predictive Value (NPV)</strong>: when the prediction is negative, how
often is it correct<ul>
<li>TN/(TN+FN)</li>
<li>In the example: 8820/(8820+380)=0.959</li>
</ul>
</li>
<li><strong>Positive Likelihood Ratio</strong>: odds of a positive prediction given that the
person is sick (used with odds formulations of probability)<ul>
<li>TPR/FPR</li>
<li>In the example: 0.62/0.02=31</li>
</ul>
</li>
<li><strong>Negative Likelihood Ratio</strong>: odds of a positive prediction given that the
person is not sick<ul>
<li>FNR/TNR</li>
<li>In the example: 0.38/0.98=0.388</li>
</ul>
</li>
</ul>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Confusion_matrix">The wikipedia page</a> has even
more.</p>
</div>
<div class="section" id="deciphering-our-example">
<h2>Deciphering our example</h2>
<p>Now back to the flu test example this post began with. RIDTs are said to have
sensitivity of 62.3%; this is just a clever way of saying that for a person with
flu, the test will be positive 62.3% of the time. For people who do not have the
flu, the test is more accurate since its specificity is 98.2% - only 1.8% of
healthy people will be flagged positive.</p>
<p>The positive likelihood ratio is said to be 34.5; let's see how it was computed:</p>
<object class="align-center" data="../../images/math/85bd9dc7996bdc9198da6226a73cfb1e900734ea.svg" style="height: 41px;" type="image/svg+xml">\[PLR=\frac{TPR}{FPR}=\frac{Sensitivity}{1-Specificity}=\frac{0.623}{1-0.982}=35\]</object>
<p>This is to say - if the person is sick, odds are 35-to-1 that the test will be
positive.</p>
<p>And the negative likelihood ratio is said to be 0.38:</p>
<object class="align-center" data="../../images/math/895921ee70c59a531ceaff02c94404e5d5316697.svg" style="height: 41px;" type="image/svg+xml">\[NLR=\frac{FNR}{TNR}=\frac{1-Sensitivity}{Specificity}=\frac{1-0.623}{0.982}=0.38\]</object>
<p>This is to say - if the person is not sick, odds are 1-to-3 that the test will
be positive.</p>
<p>In other words, these flu tests are pretty good when a person is actually sick,
but not great when the person is not sick. Which is exactly what the quoted
paragraph at the top of the post ends up saying.</p>
</div>
<div class="section" id="back-to-bayes">
<h2>Back to Bayes</h2>
<p>An astute reader will notice that the previous sections talk about the
probability of test outcomes given sickness, when we're usually interested in
the opposite - given a positive test, how likely is it that the person is
actually sick.</p>
<p><a class="reference external" href="../conditional-probability-and-bayes-theorem/index.html">My previous post on the Bayes theorem</a>
covered this issue in depth <a class="footnote-reference" href="#footnote-2" id="footnote-reference-2">[2]</a>. Let's recap, using the actual numbers from our
example. The events are:</p>
<ul class="simple">
<li><img alt="T" class="valign-0" src="../../images/math/c2c53d66948214258a26ca9ca845d7ac0c17f8e7.png" style="height: 12px;" />: test is positive</li>
<li><object class="valign-0" data="../../images/math/0e4c77261e251cb98e8cedc2b74772ae6f14318d.svg" style="height: 15px;" type="image/svg+xml">T^C</object>: test is negative</li>
<li><object class="valign-0" data="../../images/math/e69f20e9f683920d3fb4329abd951e878b1f9372.svg" style="height: 12px;" type="image/svg+xml">F</object>: person actually sick with flu</li>
<li><object class="valign-0" data="../../images/math/9f37c126895eff99088c5545433d3e33692aa267.svg" style="height: 15px;" type="image/svg+xml">F^C</object>: person doesn't have flu</li>
</ul>
<p>Sensitivity of 0.623 means <object class="valign-m4" data="../../images/math/27fd26004577f906dcaaefbf0553b7232c432d0a.svg" style="height: 18px;" type="image/svg+xml">P(T|F)=0.623</object>; similarly, specificity is
<object class="valign-m4" data="../../images/math/72e4f07dc70098feeb50032960ebe0478451e087.svg" style="height: 19px;" type="image/svg+xml">P(T^C|F^C)=0.982</object>. We're interested in finding <object class="valign-m4" data="../../images/math/b8a3711b3dc7ec3b1a73a82447c88ce067999fed.svg" style="height: 18px;" type="image/svg+xml">P(F|T)</object>, and we can
use the Bayes theorem for that:</p>
<object class="align-center" data="../../images/math/2d2d2b1a53f1b7a76155a9abe9b7b5d35198e669.svg" style="height: 42px;" type="image/svg+xml">\[P(F|T)=\frac{P(T|F)P(F)}{P(T)}\]</object>
<p>Recall that <object class="valign-m4" data="../../images/math/ce2db3a1be8bbfefc6a7bdee94dcaca4f5426799.svg" style="height: 18px;" type="image/svg+xml">P(F)</object> is the <em>prevalence</em> of flu in the general population;
for the sake of this example let's assume it's 0.1; we'll then compute
<object class="valign-m4" data="../../images/math/9d3d6e3b10a97d19adafbea8cc72b8e3619a1d27.svg" style="height: 18px;" type="image/svg+xml">P(T)</object> by using the law of total probability as follows:</p>
<object class="align-center" data="../../images/math/7b37bf70ff6ae37f99ca38df902a48adbf14a542.svg" style="height: 21px;" type="image/svg+xml">\[P(T)=P(T|F)P(F)+P(T|F^C)P(F^C)\]</object>
<p>Obviously, <object class="valign-m4" data="../../images/math/a7828371e81491815c4498bc5dcb7407b63beeed.svg" style="height: 19px;" type="image/svg+xml">P(T|F^C)=1-P(T^C|F^C)=0.018</object>, so:</p>
<object class="align-center" data="../../images/math/9f16b641c00488170b04f5bb409a5d0d21c958c8.svg" style="height: 18px;" type="image/svg+xml">\[P(T)=0.623\ast0.1 + 0.018\ast0.9=0.0785\]</object>
<p>And then:</p>
<object class="align-center" data="../../images/math/41b1c0bec6fa21e5322dd66a756d5e9d9e7253f3.svg" style="height: 36px;" type="image/svg+xml">\[P(F|T)=\frac{0.623\ast 0.1}{0.0785}=0.79\]</object>
<p>So the probability of having flu given a positive test and a 10% flu prevalence
is 79%. The prevalence strongly affects the outcome! Let's plot <object class="valign-m4" data="../../images/math/b8a3711b3dc7ec3b1a73a82447c88ce067999fed.svg" style="height: 18px;" type="image/svg+xml">P(F|T)</object>
as a function of <object class="valign-m4" data="../../images/math/ce2db3a1be8bbfefc6a7bdee94dcaca4f5426799.svg" style="height: 18px;" type="image/svg+xml">P(F)</object> for some reasonable range of values:</p>
<img alt="P(F|T) as function of prevalence" class="align-center" src="../../images/2018/pft-prevalence-plot.png" />
<p>Note how low the value of the test becomes with low disease prevalence - we've
also observed this phenomenon in <a class="reference external" href="../conditional-probability-and-bayes-theorem/index.html">the previous post</a>;
there's a &quot;tug of war&quot; between the prevalence and the test's sensitivity and
specificity. In fact, <a class="reference external" href="https://www.cdc.gov/flu/professionals/diagnosis/rapidlab.htm">the official CDC guidelines page</a> for
interpreting RIDT results discusses this:</p>
<blockquote>
When influenza prevalence is relatively low, the positive predictive value
(PPV) is low and false-positive test results are more likely. By contrast,
when influenza prevalence is low, the negative predictive value (NPV) is high,
and negative results are more likely to be true.</blockquote>
<p>And then goes on to present a handy table for estimating PPV based on prevalence
and specificity.</p>
<p>Naturally, the rapid test is not the only tool in the doctor's toolbox. Flu has
other symptoms, and by observing them on the patient the doctor can increase
their confidence in the diagnosis. For example, if the probability
<object class="valign-m4" data="../../images/math/b8a3711b3dc7ec3b1a73a82447c88ce067999fed.svg" style="height: 18px;" type="image/svg+xml">P(F|T)</object> given 10% prevalence is 0.79 (as computed above), the doctor may
be significantly less sure of the results if flu symptoms like cough and fever
are not demonstrated, etc. The CDC discusses this in more detail with an
<a class="reference external" href="https://www.cdc.gov/flu/professionals/diagnosis/algorithm-results-not-circulating.htm">algorithm for interepreting flu results</a>.</p>
<hr class="docutils" />
<table class="docutils footnote" frame="void" id="footnote-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#footnote-reference-1">[1]</a></td><td>Slower tests like full viral cultures are also available, and they are
very accurate. The problem is that these tests take a long time to
complete - days - so they're usually not very useful in treating the
disease. Anti-viral medication is only useful in the first 48 hours after
disease onset. RIDTs provide results within hours, or even minutes.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="footnote-2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#footnote-reference-2">[2]</a></td><td>In that post we didn't distinguish between sensitivity and specificity,
but assumed they're equal at 90%. It's much more common for these
measures to be different, but it doesn't actually complicate the
computations.</td></tr>
</tbody>
</table>
</div>

            </div>
            <!-- /.entry-content -->
<hr/>
<div class="dotted-links">
<p class="align-center">
For comments, please send me
<a href="mailto:eliben@gmail.com"><i class="fa fa-envelope-o"></i> an email</a>.
</p>
</div>        </article>
    </section>

    </div>
</div>
<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">
            &copy; 2003-2025 Eli Bendersky
         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="http://code.jquery.com/jquery-2.2.4.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="../../theme/js/bootstrap.min.js"></script>

<!--
  Using goatcounter to count visitors. The count.js script is vendored in.
-->
<script data-goatcounter="https://stats.thegreenplace.net/count"
        async src="../../theme/js/count.js"></script>
</body>

<!-- Mirrored from eli.thegreenplace.net/2018/the-confusion-matrix-in-statistical-tests/ by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 16 Feb 2025 23:58:35 GMT -->
</html>