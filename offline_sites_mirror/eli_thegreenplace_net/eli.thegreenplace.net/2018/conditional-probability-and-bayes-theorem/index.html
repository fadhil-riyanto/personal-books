<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"
      xmlns:og="http://ogp.me/ns#"
      xmlns:fb="https://www.facebook.com/2008/fbml">

<!-- Mirrored from eli.thegreenplace.net/2018/conditional-probability-and-bayes-theorem/ by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 16 Feb 2025 23:58:37 GMT -->
<head>
    <title>Conditional probability and Bayes' theorem - Eli Bendersky's website</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link href="../../favicon.ico" rel="icon">

    <!-- Bootstrap -->
        <link rel="stylesheet" href="../../theme/css/bootstrap.min.css" type="text/css"/>
    <link href="../../theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="../../theme/css/pygments/vs.css" rel="stylesheet">
    <link rel="stylesheet" href="../../theme/css/style.css" type="text/css"/>

        <link href="../../feeds/all.atom.xml" type="application/atom+xml" rel="alternate"
              title="Eli Bendersky's website ATOM Feed"/>

</head>
<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="../../index.html" class="navbar-brand">
                <img src="../../images/logosmall.png" width="32" height="32"/>
Eli Bendersky's website            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="../../pages/about.html">
                        <i class="fa fa-question"></i>
                        <span class="icon-label">About</span>
                    </a>
                </li>
                <li>
                    <a href="../../pages/projects.html">
                        <i class="fa fa-github"></i>
                        <span class="icon-label">Projects</span>
                    </a>
                </li>
                <li>
                    <a href="../../archives/all.html">
                        <i class="fa fa-th-list"></i>
                        <span class="icon-label">Archives</span>
                    </a>
                </li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->

<div class="container">
    <div class="row">
    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="index.html"
                       rel="bookmark"
                       title="Permalink to Conditional probability and Bayes' theorem">
                        Conditional probability and Bayes' theorem
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="published">
        <i class="fa fa-calendar"></i>
        <time> March 13, 2018 at 05:32</time>
    </span>
<span class="label label-default">Tags</span>
    <a href="../../tag/math.html">Math</a>
</footer><!-- /.post-info -->                    </div>
                </div>
                <p>One morning, while seeing a mention of a disease on Hacker News, Bob decides on
a whim to get tested for it; there are no other symptoms, he's just curious. He
convinces his doctor to order a blood test, which is known to be 90% accurate.
For 9 out of 10 sick people it will detect the disease (but for 1 out of 10 it
won't); similarly, for 9 out of 10 healthy people it will report no disease (but
for 1 out of 10 it will).</p>
<p>Unfortunatly for Bob, his test is positive; what's the probability that Bob
actually has the disease?</p>
<p>You might be tempted to say 90%, but this is wrong. One of the most common
fallacies made in probability and statistics is mixing up conditional
probabilities. Given event D - &quot;Bob has disease&quot; and event T - &quot;test was
positive&quot;, we want to know what is <object class="valign-m4" data="../../images/math/28f810c7c292ba7faa5b47a0b4e0d470f79b19d8.svg" style="height: 18px;" type="image/svg+xml">P(D|T)</object> - the conditional probability
of D given T. But the test result is actually giving us <object class="valign-m4" data="../../images/math/7455e3a5dfb3c45f4a3b110a7906341362a50e53.svg" style="height: 18px;" type="image/svg+xml">P(T|D)</object> - which
is distinct from <object class="valign-m4" data="../../images/math/28f810c7c292ba7faa5b47a0b4e0d470f79b19d8.svg" style="height: 18px;" type="image/svg+xml">P(D|T)</object>.</p>
<p>In fact, the problem doesn't provide enough details to answer the question. An
important detail that's missing is the <em>prevalence</em> of the disease in
population; that is, the value of <object class="valign-m4" data="../../images/math/f85da048bad405b6f81778501db99b331b689d46.svg" style="height: 18px;" type="image/svg+xml">P(D)</object> without being conditioned on
anything. Let's say that it's a moderately common disease with 2% prevalence.</p>
<p>To solve this without any clever probability formulae, we can resort to the
basic technique of counting by cases. Let's assume there is a sample of 10,000
people <a class="footnote-reference" href="#footnote-1" id="footnote-reference-1">[1]</a>; test aside, how many of them have the disease? 2%, so 200.</p>
<img alt="Bayes counting disease calculation prevalence" class="align-center" src="../../images/2018/bayes-count-disease-1.png" />
<p>Of the people who have the disease, 90% will test positive and 10% will test
negative. Similarly, of the people with no disease, 90% will test negative and
10% will test positive. Graphically:</p>
<img alt="Bayes counting disease calculation prevalence and test" class="align-center" src="../../images/2018/bayes-count-disease-2.png" />
<p>Now we just have to count. There are 980 + 180 = 1160 people who tested positive
in the sample population. Of these people, 180 have the disease. In other words,
given that Bob is in the &quot;tested positive&quot; population, his chance of having
the disease is 180/1160 = 15.5%. This is <em>far</em> lower than the 90% test accuracy;
conditional probability often produces surprising results. To motivate this,
consider that the number of <em>true positives</em> (people with the disease that
tested positive) is 180, while the number of <em>false positives</em> (people w/o the
disease that tested positive) is 980. So the chance of being in the second group
is larger.</p>
<div class="section" id="conditional-probability">
<h2>Conditional probability</h2>
<p>As the examples shown above demonstrate, conditional probabilities involve
questions like &quot;what's the chance of A happening, given that B happened&quot;, and
they are far from being intuitive. Luckily, the mathematical theory of
probability gives us the precise and rigorous tools necessary to reason about
such problems with relative elegance.</p>
<p>The conditional probability <object class="valign-m4" data="../../images/math/c8937022ac4e55a642f3bd850e6e9b17dd8fc8d3.svg" style="height: 18px;" type="image/svg+xml">P(A|B)</object> means &quot;what is the probability of
event A given that we know event B occurred&quot;. Its mathematical definition is:</p>
<object class="align-center" data="../../images/math/990efadb78ac3b3145842995f70010710da00dc2.svg" style="height: 42px;" type="image/svg+xml">\[P(A|B)=\frac{P(A\cap B)}{P(B)}\]</object>
<p>Notes:</p>
<ul class="simple">
<li>Obviously, this is only defined when <object class="valign-m4" data="../../images/math/89a84f08607a9c7fe798b67b1d6f7778c6b2e366.svg" style="height: 18px;" type="image/svg+xml">P(B)&gt;0</object>.</li>
<li>Here <object class="valign-m4" data="../../images/math/766349d42cbd0bbefc0311ba2e67a3c1da93625f.svg" style="height: 18px;" type="image/svg+xml">P(A\cap B)</object> is the probability that both A and B occurred.</li>
</ul>
<p>The first time you look at it, the definition of conditional probability looks
somewhat unintuitive. Why is the connection made this way? Here's a
visualization that I found useful:</p>
<img alt="Sample space dots visualization for conditional probability" class="align-center" src="../../images/2018/samplespace.png" />
<p>The dots in the black square represent the &quot;universe&quot;, our whole sampling
space (let's call it S, and then <object class="valign-m4" data="../../images/math/2db3db98100616af986bd71ff1b3b779df968b9f.svg" style="height: 18px;" type="image/svg+xml">P(S)=1</object>). A and B are events. Here
<object class="valign-m6" data="../../images/math/3a0b4d21054323cff53c2226dfc210377dbf4588.svg" style="height: 22px;" type="image/svg+xml">P(A)=\frac{30}{64}</object> and <object class="valign-m6" data="../../images/math/424554d20e0a324069ca970290cb1f937eacb2f5.svg" style="height: 22px;" type="image/svg+xml">P(B)=\frac{18}{64}</object>. But what is
<object class="valign-m4" data="../../images/math/c8937022ac4e55a642f3bd850e6e9b17dd8fc8d3.svg" style="height: 18px;" type="image/svg+xml">P(A|B)</object>? Let's figure it out graphically. We know that the outcome is one
of the dots encircled in red. What is the chance we got a dot also encircled in
blue? It's the number of dots that are both red and blue, divided by the total
number of dots in red. Probabilities are calculated as these counts normalized
by the size of the whole sample space; all the numbers are divided by 64, so
these denominators cancel out; we'll have:</p>
<object class="align-center" data="../../images/math/4d783b6592e32a7119193d0bad39843877f398e9.svg" style="height: 42px;" type="image/svg+xml">\[P(A|B)=\frac{P(A\cap B)}{P(B)} = \frac{9}{18} = \frac{1}{2}\]</object>
<p>In words - the probability that A happened, given that B happened, is 1/2, which
makes sense when you eyeball the diagram, and assuming events are uniformly
distributed (that is, no dot is inherently more likely to be the outcome than
any other dot).</p>
<p>Another explanation that always made sense to me was to multiply both sides of
the definition of conditional probability by the denominator, to get:</p>
<object class="align-center" data="../../images/math/942d1e523c4b088a86138644ceef8512fd97e877.svg" style="height: 18px;" type="image/svg+xml">\[P(A|B)P(B)=P(A\cap B)\]</object>
<p>In words: we know the chance that A happens given B; if we multiply this by the
chance that B happens, we get the chance both A and B happened.</p>
<p>Finally, since <object class="valign-m4" data="../../images/math/526645ebc23e442dd422c3ee7956b3503578d512.svg" style="height: 18px;" type="image/svg+xml">P(A\cap B)=P(B\cap A)</object>, we can freely exchange A and B in
these definitions (they're arbitrary labels, after all), to get:</p>
<object class="align-center" data="../../images/math/d748581a273f112cf0af1add7fc7320283f0b226.svg" style="height: 18px;" type="image/svg+xml">\[\begin{equation}
P(A\cap B)=P(A|B)P(B)=P(B|A)P(A) \tag{1}
\end{equation}\]</object>
<p>This is an important equation we'll use later on.</p>
</div>
<div class="section" id="independence-of-events">
<h2>Independence of events</h2>
<p>By definition, two events A and B are <em>independent</em> if:</p>
<object class="align-center" data="../../images/math/39d4d03d68cb696d28d659e5ba0d3c7c1b474a44.svg" style="height: 18px;" type="image/svg+xml">\[P(A\cap B)=P(A)P(B)\]</object>
<p>Using conditional probability, we can provide a slightly different definition.
Since:</p>
<object class="align-center" data="../../images/math/990efadb78ac3b3145842995f70010710da00dc2.svg" style="height: 42px;" type="image/svg+xml">\[P(A|B)=\frac{P(A\cap B)}{P(B)}\]</object>
<p>And <object class="valign-m4" data="../../images/math/79ab089f069fc76a74136c5331d4655c256b1129.svg" style="height: 18px;" type="image/svg+xml">P(A\cap B)=P(A)P(B)</object>:</p>
<object class="align-center" data="../../images/math/14ce0bcf839194d2662ca7b52f59521a39c8cabc.svg" style="height: 42px;" type="image/svg+xml">\[P(A|B)=\frac{P(A)P(B)}{P(B)}=P(A)\]</object>
<p>As long as <object class="valign-m4" data="../../images/math/89a84f08607a9c7fe798b67b1d6f7778c6b2e366.svg" style="height: 18px;" type="image/svg+xml">P(B)&gt;0</object>, for independent A and B we have
<object class="valign-m4" data="../../images/math/c399868e8ef09ea7c4e694fce59aad863775bdb0.svg" style="height: 18px;" type="image/svg+xml">P(A|B)=P(A)</object>; in words - B doesn't affect the probability of A in any
way. Similarly we can show that for <object class="valign-m4" data="../../images/math/ee817c4528261210d55c260023c288b451672b8c.svg" style="height: 18px;" type="image/svg+xml">P(A)&gt;0</object> we have <object class="valign-m4" data="../../images/math/e86a7ac5a9f6584ffbc2ede7f26664b7bc9aeead.svg" style="height: 18px;" type="image/svg+xml">P(B|A)=P(B)</object>.</p>
<p>Independence also extends to the complements of events. Recall that
<object class="valign-m4" data="../../images/math/d90bd1cf9cdf80fe34935388ba98fc83fced8881.svg" style="height: 19px;" type="image/svg+xml">P(B^C)</object> is the probability that B <em>did not</em> occur, or <object class="valign-m4" data="../../images/math/ace42eb9c0d264d434a445f8efa82a392665ed7d.svg" style="height: 18px;" type="image/svg+xml">1-P(B)</object>;
since conditional probabilities obey the usual probability axioms, we
have: <object class="valign-m4" data="../../images/math/58060444dee52056dd38f0178bc90d973cb4de6e.svg" style="height: 19px;" type="image/svg+xml">P(B^C|A)=1-P(B|A)</object>. Then, if A and B are independent:</p>
<object class="align-center" data="../../images/math/2fd0e5ba3a9f72858b5289c505ee4ffa1a433047.svg" style="height: 21px;" type="image/svg+xml">\[P(B^C|A)=1-P(B)=P(B^C)\]</object>
<p>Therefore, <object class="valign-0" data="../../images/math/5ff671c7bd1273544cca53c173582f98ff8a099d.svg" style="height: 15px;" type="image/svg+xml">B^C</object> is independent of A. Similarly the complement of A is
independent of B, and the two complements are independent of each other.</p>
</div>
<div class="section" id="bayes-theorem">
<h2>Bayes' theorem</h2>
<p>Starting with equation (1) from above:</p>
<object class="align-center" data="../../images/math/4682360529fab726af4caf0827dbb6edd5f9d902.svg" style="height: 18px;" type="image/svg+xml">\[P(A\cap B)=P(A|B)P(B)=P(B|A)P(A)\]</object>
<p>And taking the right-hand-side equality and dividing it by <object class="valign-m4" data="../../images/math/d3ecb6c1c04b6ea74af4cacdcb3f1e1bead3b66e.svg" style="height: 18px;" type="image/svg+xml">P(B)</object> (which
is positive, per definition), we get Bayes's theorem:</p>
<object class="align-center" data="../../images/math/2e91b38c9f5e26500ede19152eb669f561d9c870.svg" style="height: 42px;" type="image/svg+xml">\[P(A|B)=\frac{P(B|A)P(A)}{P(B)}\]</object>
<p>This is an extremely useful result, because it links <object class="valign-m4" data="../../images/math/9aa002063e1297678f0283b9e7339a73d8a7f6f6.svg" style="height: 18px;" type="image/svg+xml">P(B|A)</object> with
<object class="valign-m4" data="../../images/math/c8937022ac4e55a642f3bd850e6e9b17dd8fc8d3.svg" style="height: 18px;" type="image/svg+xml">P(A|B)</object>. Recall the disease test example, where we're looking for
<object class="valign-m4" data="../../images/math/28f810c7c292ba7faa5b47a0b4e0d470f79b19d8.svg" style="height: 18px;" type="image/svg+xml">P(D|T)</object>. We can use Bayes theorem:</p>
<object class="align-center" data="../../images/math/7821df244a23990c03bab3a5ad8266797d2b7c4a.svg" style="height: 42px;" type="image/svg+xml">\[P(D|T)=\frac{P(T|D)P(D)}{P(T)}\]</object>
<p>We know <object class="valign-m4" data="../../images/math/7455e3a5dfb3c45f4a3b110a7906341362a50e53.svg" style="height: 18px;" type="image/svg+xml">P(T|D)</object> and <object class="valign-m4" data="../../images/math/f85da048bad405b6f81778501db99b331b689d46.svg" style="height: 18px;" type="image/svg+xml">P(D)</object>, but what is <object class="valign-m4" data="../../images/math/9d3d6e3b10a97d19adafbea8cc72b8e3619a1d27.svg" style="height: 18px;" type="image/svg+xml">P(T)</object>? You may be
tempted to say it's 1 because &quot;well, <em>we know the test is positive</em>&quot; but that
would be a mistake. To understand why, we have to dig a bit deeper into the
meanings of conditional vs. unconditional probabilities.</p>
</div>
<div class="section" id="prior-and-posterior-probabilities">
<h2>Prior and posterior probabilities</h2>
<p>Fundamentally, conditional probability helps us address the following question:</p>
<blockquote>
How do we update our beliefs in light of new data?</blockquote>
<p><em>Prior</em> probability is our beliefs (probabilities assigned to events) before we
see the new data. <em>Posterior</em> probability is our beliefs after we see the new
data. In the Bayes equation, prior probabilities are simply the un-conditioned
ones, while posterior probabilities are conditional. This leads to a key
distinction:</p>
<ul class="simple">
<li><object class="valign-m4" data="../../images/math/7455e3a5dfb3c45f4a3b110a7906341362a50e53.svg" style="height: 18px;" type="image/svg+xml">P(T|D)</object>: posterior probability of the test being positive when we have
new data about the person - they have the disease.</li>
<li><object class="valign-m4" data="../../images/math/9d3d6e3b10a97d19adafbea8cc72b8e3619a1d27.svg" style="height: 18px;" type="image/svg+xml">P(T)</object>: prior probability of the test being positive before we know
anything about the person.</li>
</ul>
<p>This should make it clearer why we can't just assign <object class="valign-m4" data="../../images/math/00c3bafd4576764728524129480194f205402208.svg" style="height: 18px;" type="image/svg+xml">P(T)=1</object>. Instead,
recall the &quot;counting by cases&quot; exercise we did in the first example, where we
produced a tree of all possibilities; let's formalize it.</p>
</div>
<div class="section" id="law-of-total-probability">
<h2>Law of Total Probability</h2>
<p>Suppose we have the sample space S and some event B. Sometimes it's easier to
find the probability of B by first partitioning the space into disjoint pieces:</p>
<img alt="Sample space dots visualization for conditional probability" class="align-center" src="../../images/2018/spacepartition.png" />
<p>Then, because the probabilities of <object class="valign-m3" data="../../images/math/5aa3f2ac5ea9b6b96e13e2bd945ab77b2cce164a.svg" style="height: 15px;" type="image/svg+xml">A_n</object> are disjoint, we get:</p>
<object class="align-center" data="../../images/math/059517fb7fbb92cfe88968642a0ef5cebcf57f70.svg" style="height: 18px;" type="image/svg+xml">\[P(B)=P(B\cap A_1)+P(B\cap A_2)+P(B\cap A_3)+P(B\cap A_4)\]</object>
<p>Or, using equation (1):</p>
<object class="align-center" data="../../images/math/615b1c4ed0b1b0e18f48953ed54e1026aaf8337a.svg" style="height: 18px;" type="image/svg+xml">\[P(B)=P(B|A_1)P(A_1)+P(B|A_2)P(A_2)+P(B|A_3)P(A_3)+P(B|A_4)P(A_4)\]</object>
</div>
<div class="section" id="bayesian-solution-to-the-disease-test-example">
<h2>Bayesian solution to the disease test example</h2>
<p>Now we have everything we need to provide a Bayesian solution to the disease
test example. Recall that we already know:</p>
<ul class="simple">
<li><object class="valign-m4" data="../../images/math/c772c4b7636ec5638c2c0058c93526d105f8b659.svg" style="height: 18px;" type="image/svg+xml">P(T|D)=0.9</object>: test accuracy</li>
<li><object class="valign-m4" data="../../images/math/6445317e3d0d9a55e4669fd041aa16e8d203ec32.svg" style="height: 18px;" type="image/svg+xml">P(D)=0.02</object>: disease prevalance in the population</li>
</ul>
<p>Now we want to compute <object class="valign-m4" data="../../images/math/9d3d6e3b10a97d19adafbea8cc72b8e3619a1d27.svg" style="height: 18px;" type="image/svg+xml">P(T)</object>. We'll use the law of total probability,
with the space partitioning of &quot;has disease&quot; / &quot;does not have disease&quot;:</p>
<object class="align-center" data="../../images/math/5474419ab67a489dc7192dce2940d5f09f25352e.svg" style="height: 21px;" type="image/svg+xml">\[P(T)=P(T|D)P(D)+P(T|D^C)P(D^C)=0.9\ast 0.02+0.1\ast 0.98=0.116\]</object>
<p>Finally, plugging everything into Bayes theorem:</p>
<object class="align-center" data="../../images/math/05d2f7a8e457de18576450dd426ee0e3d54e2e28.svg" style="height: 206px;" type="image/svg+xml">\[P(D|T)=\frac{P(T|D)P(D)}{P(T)}

\begin{align*}
P(D|T)&amp;=\frac{P(T|D)P(D)}{P(T)}\\
      &amp;=\frac{P(T|D)P(D)}{0.116}\\
      &amp;=\frac{0.9\ast 0.02}{0.116}=0.155
\end{align*}\]</object>
<p>Which is the same result we got while working through possibilities in the
example.</p>
</div>
<div class="section" id="conditioning-on-multiple-events">
<h2>Conditioning on multiple events</h2>
<p>We've just computed <object class="valign-m4" data="../../images/math/28f810c7c292ba7faa5b47a0b4e0d470f79b19d8.svg" style="height: 18px;" type="image/svg+xml">P(D|T)</object> - the conditional probability of event D
(patient has disease) on event T (patient tested positive). An important
extension of this technique is being able to reason about multiple tests, and
how they affect the conditional probability. We'll want to compute
<object class="valign-m4" data="../../images/math/6caceb5e79d179c9bc5ee1f30bc94a2cc5a43f09.svg" style="height: 18px;" type="image/svg+xml">P(D|T_1\cap T_2)</object> where <object class="valign-m4" data="../../images/math/2885fa41d340ab94bb0451308cf01996f1916011.svg" style="height: 16px;" type="image/svg+xml">T_1</object> and <object class="valign-m3" data="../../images/math/f725afdfa00dd57660feb233ef8547c9985c924e.svg" style="height: 15px;" type="image/svg+xml">T_2</object> are two events for
different tests.</p>
<p>Let's assume <object class="valign-m4" data="../../images/math/2885fa41d340ab94bb0451308cf01996f1916011.svg" style="height: 16px;" type="image/svg+xml">T_1</object> is our original test. <object class="valign-m3" data="../../images/math/f725afdfa00dd57660feb233ef8547c9985c924e.svg" style="height: 15px;" type="image/svg+xml">T_2</object> is a slightly
different test that's only 80% accurate. Importantly, the tests are
<em>independent</em> (they test completely different things) <a class="footnote-reference" href="#footnote-2" id="footnote-reference-2">[2]</a>.</p>
<p>We'll start with a naive approach that seems reasonable. For <object class="valign-m4" data="../../images/math/2885fa41d340ab94bb0451308cf01996f1916011.svg" style="height: 16px;" type="image/svg+xml">T_1</object>, we
already know that <object class="valign-m4" data="../../images/math/bf10cd55e38ac2b90c6a58763b5c7207e21112ac.svg" style="height: 18px;" type="image/svg+xml">P(D|T_1)=0.155</object>. For <object class="valign-m3" data="../../images/math/f725afdfa00dd57660feb233ef8547c9985c924e.svg" style="height: 15px;" type="image/svg+xml">T_2</object>, it's similarly simple
to compute:</p>
<object class="align-center" data="../../images/math/0adb7aa21363b77105139ba87a7a6a3b1bb18c1f.svg" style="height: 42px;" type="image/svg+xml">\[P(D|T_2)=\frac{P(T_2|D)P(D)}{P(T_2)}\]</object>
<p>The disease prevalence is still 2%, and using the law of total probability we
get:</p>
<object class="align-center" data="../../images/math/499e223575d2ca5776c3d7493ec72a7034b68ef8.svg" style="height: 21px;" type="image/svg+xml">\[P(T_2)=P(T_2|D)P(D)+P(T_2|D^C)P(D^C)=0.8\ast 0.02+0.2\ast 0.98=0.212\]</object>
<p>Therefore:</p>
<object class="align-center" data="../../images/math/5d76ab3755acc699caa4dd080dad975b020aeab9.svg" style="height: 42px;" type="image/svg+xml">\[P(D|T_2)=\frac{P(T_2|D)P(D)}{P(T_2)}=\frac{0.8\ast 0.02}{0.212}=0.075\]</object>
<p>In other words, if a person tests positive with the second test, the chance of
being sick is only 7.5%. But what if they tested positive for both tests?</p>
<p>Well, since the tests are independent we can do the usual probability trick of
combining the complements. We'll compute the probability the person is <em>not</em>
sick given positive tests, and then compute the complement of that.
<object class="valign-m4" data="../../images/math/34f3f1a1d7cf4f9bb761f5d30e30c73ae74a0d88.svg" style="height: 19px;" type="image/svg+xml">P(D^C|T_1)=1-0.155=0.845</object>, and <object class="valign-m4" data="../../images/math/bc939034f01f15365f691b44910bc5671eb66f17.svg" style="height: 19px;" type="image/svg+xml">P(D^C|T_2)=1-0.075=0.925</object>.
Therefore:</p>
<object class="align-center" data="../../images/math/4f6a0d5b400338982d6fccd353263ad6bf1129c6.svg" style="height: 21px;" type="image/svg+xml">\[P(D^C|T_1\cap T_2)=P(D^C|T_1)P(D^C|T_2)=0.845\ast 0.925=0.782\]</object>
<p>And complementing again, we get <object class="valign-m4" data="../../images/math/fc78afd8f0ce0dc8a278906a52710401645f0f55.svg" style="height: 18px;" type="image/svg+xml">P(D|T_1\cap T_2)=1-0.782=0.218</object>. The
chance of being sick, having tested positive both times is 21.8%.</p>
<p>Unfortunately, this computation is wrong, <em>very</em> wrong. Can you spot why before
reading on?</p>
<p>We've committed a fairly common blunder in conditional probabilities. Given the
independence of <object class="valign-m4" data="../../images/math/078820d4711ac1ab1b075b3b3e452a97424174c8.svg" style="height: 18px;" type="image/svg+xml">P(T_1|D)</object> and <object class="valign-m4" data="../../images/math/8934e9ba84564c2e86c8223fa4edf8ecf142349a.svg" style="height: 18px;" type="image/svg+xml">P(T_2|D)</object>, we've assumed the
independence of <object class="valign-m4" data="../../images/math/9e7f4ee884ceb05aa1e7b2dd2453698971ca6689.svg" style="height: 18px;" type="image/svg+xml">P(D|T_1)</object> and <object class="valign-m4" data="../../images/math/7e3df62da0b4a6aaf0fb78afd834a8d9842e463a.svg" style="height: 18px;" type="image/svg+xml">P(D|T_2)</object>, but this is wrong! It's
even easy to see why, given our concrete example. Both of them have <object class="valign-m4" data="../../images/math/f85da048bad405b6f81778501db99b331b689d46.svg" style="height: 18px;" type="image/svg+xml">P(D)</object>
- the disease prevalence - in the numerator. Changing the prevalence will change
both <object class="valign-m4" data="../../images/math/9e7f4ee884ceb05aa1e7b2dd2453698971ca6689.svg" style="height: 18px;" type="image/svg+xml">P(D|T_1)</object> and <object class="valign-m4" data="../../images/math/7e3df62da0b4a6aaf0fb78afd834a8d9842e463a.svg" style="height: 18px;" type="image/svg+xml">P(D|T_2)</object> in exactly the same proportion; say,
increasing the prevalence 2x will increase both probabilities 2x. They're
pretty strongly dependent!</p>
<p>The right way of finding <object class="valign-m4" data="../../images/math/6caceb5e79d179c9bc5ee1f30bc94a2cc5a43f09.svg" style="height: 18px;" type="image/svg+xml">P(D|T_1\cap T_2)</object> is working from first
principles. <object class="valign-m4" data="../../images/math/7bf9b64bece7c786508608f42ccb59b54c058a2c.svg" style="height: 16px;" type="image/svg+xml">T_1\cap T_2</object> is just another event, so treating it as such
and using Bayes theorem we get:</p>
<object class="align-center" data="../../images/math/490d067f11ad71b9824cac46864577eaeaed6e22.svg" style="height: 42px;" type="image/svg+xml">\[P(D|T_1\cap T_2)=\frac{P(T_1\cap T_2|D)P(D)}{P(T_1\cap T_2)}\]</object>
<p>Here <object class="valign-m4" data="../../images/math/f85da048bad405b6f81778501db99b331b689d46.svg" style="height: 18px;" type="image/svg+xml">P(D)</object> is still 0.02; <object class="valign-m4" data="../../images/math/234e83d1410ef9137bc8dc052b7ea2e038a81337.svg" style="height: 18px;" type="image/svg+xml">P(T_1\cap T_2|D)=0.9\ast0.8=0.72</object>. To
compute the denominator we'll use the law of total probability again:</p>
<object class="align-center" data="../../images/math/97bb82b17c9ba327a72f472114e7ffe0aa8ed6a3.svg" style="height: 21px;" type="image/svg+xml">\[P(T_1\cap T_2)=P(T_1\cap T_2|D)P(D)+P(T_1\cap T_2|D^C)P(D^C)=0.72\ast 0.02+0.1\ast 0.2\ast 0.98=0.034\]</object>
<p>Combining them all together we'll get <object class="valign-m4" data="../../images/math/f109539a4f087faa32c6c9bf4006ce9bf5318979.svg" style="height: 18px;" type="image/svg+xml">P(D|T_1\cap T_2)=0.42</object>; the chance
of being sick, given two positive tests, is 42%, which is twice higher than our
erroneous estimate <a class="footnote-reference" href="#footnote-3" id="footnote-reference-3">[3]</a>.</p>
</div>
<div class="section" id="bayes-theorem-with-conditioning">
<h2>Bayes theorem with conditioning</h2>
<p>Since conditional probabilities satistfy all probability axioms, many theorems
remain true when adding a condition. Here's Bayes theorem with extra
conditioning on event C:</p>
<object class="align-center" data="../../images/math/66add8a0c5c81776826cb9a58662e30e118c71b9.svg" style="height: 42px;" type="image/svg+xml">\[P(A|B\cap C)=\frac{P(B|A\cap C)P(A|C)}{P(B|C)}\]</object>
<p>In other words, the connection between <object class="valign-m4" data="../../images/math/c8937022ac4e55a642f3bd850e6e9b17dd8fc8d3.svg" style="height: 18px;" type="image/svg+xml">P(A|B)</object> and <object class="valign-m4" data="../../images/math/9aa002063e1297678f0283b9e7339a73d8a7f6f6.svg" style="height: 18px;" type="image/svg+xml">P(B|A)</object> is true
even when everything is conditioned on some event C. To prove it, we can take
both sides and expand the definitions of conditional probability until we reach
something trivially true:</p>
<object class="align-center" data="../../images/math/28d63e34558ac9a513785738a4eb2c0ce82668c2.svg" style="height: 138px;" type="image/svg+xml">\[\begin{align*}
P(A|B\cap C)&amp;=\frac{P(B|A\cap C)P(A|C)}{P(B|C)}\\
\frac{P(A\cap B\cap C)}{P(B\cap C)}&amp;=\frac{P(A\cap B\cap C)P(A|C)}{P(A\cap C)P(B|C)}\\
\frac{P(A\cap B\cap C)}{P(B\cap C)}&amp;=\frac{P(A\cap B\cap C)P(A\cap C)}{P(A\cap C)P(B|C)P(C)}\\
\end{align*}\]</object>
<p>Assuming that <object class="valign-m4" data="../../images/math/7784945e846c26d7c35f5a323dfd18c8d359a001.svg" style="height: 18px;" type="image/svg+xml">P(A\cap C)&gt;0</object>, it cancels out (similarly for <object class="valign-m4" data="../../images/math/fd0e822b920e5f9312922a7136ac99a01db7d44e.svg" style="height: 18px;" type="image/svg+xml">P(C)&gt;0</object>
in a later step):</p>
<object class="align-center" data="../../images/math/4d007d49999b1286d02810151a6ca8cf8e945bdf.svg" style="height: 138px;" type="image/svg+xml">\[\begin{align*}
\frac{P(A\cap B\cap C)}{P(B\cap C)}&amp;=\frac{P(A\cap B\cap C)}{P(B|C)P(C)}\\
\frac{P(A\cap B\cap C)}{P(B\cap C)}&amp;=\frac{P(A\cap B\cap C)P(C)}{P(B\cap C)P(C)}\\
\frac{P(A\cap B\cap C)}{P(B\cap C)}&amp;=\frac{P(A\cap B\cap C)}{P(B\cap C)}
\end{align*}\]</object>
<p><em>Q.E.D.</em></p>
<p>Using this new result, we can compute our two-test disease exercise in another
way. Let's say that <object class="valign-m4" data="../../images/math/2885fa41d340ab94bb0451308cf01996f1916011.svg" style="height: 16px;" type="image/svg+xml">T_1</object> happens first, and we've already computed
<object class="valign-m4" data="../../images/math/9e7f4ee884ceb05aa1e7b2dd2453698971ca6689.svg" style="height: 18px;" type="image/svg+xml">P(D|T_1)</object>. We can now treat this as the new <em>prior</em> data, and find
<object class="valign-m4" data="../../images/math/6caceb5e79d179c9bc5ee1f30bc94a2cc5a43f09.svg" style="height: 18px;" type="image/svg+xml">P(D|T_1\cap T_2)</object> based on the new evidence that <object class="valign-m3" data="../../images/math/f725afdfa00dd57660feb233ef8547c9985c924e.svg" style="height: 15px;" type="image/svg+xml">T_2</object> happened.
We'll use the conditioned Bayes formulation with <object class="valign-m4" data="../../images/math/2885fa41d340ab94bb0451308cf01996f1916011.svg" style="height: 16px;" type="image/svg+xml">T_1</object> being C.</p>
<object class="align-center" data="../../images/math/a06ff1feb6ddc4f774eeab3db36f24bc6f8ebfb1.svg" style="height: 42px;" type="image/svg+xml">\[P(D|T_2\cap T_1)=\frac{P(T_2|D\cap T_1)P(D|T_1)}{P(T_2|T_1)}\]</object>
<p>We already know that <object class="valign-m4" data="../../images/math/9e7f4ee884ceb05aa1e7b2dd2453698971ca6689.svg" style="height: 18px;" type="image/svg+xml">P(D|T_1)</object> is 0.155; What about
<object class="valign-m4" data="../../images/math/55700383bdf6e67d7fc2a7e98d9615982e36e546.svg" style="height: 18px;" type="image/svg+xml">P(T_2|D\cap T_1)</object>? Since the tests are independent,
this is actually equivalent to <object class="valign-m4" data="../../images/math/8934e9ba84564c2e86c8223fa4edf8ecf142349a.svg" style="height: 18px;" type="image/svg+xml">P(T_2|D)</object>, which is 0.8. The denominator
requires a bit more careful computation:</p>
<object class="align-center" data="../../images/math/34ba42765c1ab9f7ffd49867707bd9cc3091f1cd.svg" style="height: 42px;" type="image/svg+xml">\[P(T_2|T_1)=\frac{P(T_1\cap T_2)}{P(T_1)}\]</object>
<p>We've already found <object class="valign-m4" data="../../images/math/a0674ed54736ae0ea920485197320e0e23abd85a.svg" style="height: 18px;" type="image/svg+xml">P(T_1)=0.116</object> previously, using the law of total
probability. Using the same law:</p>
<object class="align-center" data="../../images/math/8347d5e40753c64fbc86668b7b53321fa00bab65.svg" style="height: 21px;" type="image/svg+xml">\[P(T_1\cap T_2)=P(T_1\cap T_2|D)P(D)+P(T_2\cap T_2|D^C)P(D^C)=0.9\ast 0.9\ast 0.02+0.1\ast 0.2\ast 0.98=0.034\]</object>
<p>Therefore, <object class="valign-m7" data="../../images/math/8853f1766ae90cf8da81a56ab3fcc173baa21878.svg" style="height: 23px;" type="image/svg+xml">P(T_2|T_1)=\frac{0.034}{0.116}=0.293</object> and we now have all the
ingredients:</p>
<object class="align-center" data="../../images/math/7bd0854b518fca8ea6c42551abd0b032ce5e1708.svg" style="height: 37px;" type="image/svg+xml">\[P(D|T_2\cap T_1)=\frac{0.8\ast 0.155}{0.293}=0.42\]</object>
<p>We've reached the same result using two different approaches, which is
reassuring. Computing with both tests taken together is a bit quicker, but
taking one test at a time is also useful because it lets us <em>update our beliefs</em>
over time, given new data.</p>
<p>Computing conditional probabilities w.r.t. multiple parameters is very useful
in machine learning - this would be a good topic for a separate article.</p>
<hr class="docutils" />
<table class="docutils footnote" frame="void" id="footnote-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#footnote-reference-1">[1]</a></td><td>This actual number of people is arbitrary, and it could be anything else;
in formulae it cancels out anyway. I picked 10,000 because it's a nice
number ending with a bunch of zeros and won't produce fractional people
for this particular example.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="footnote-2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#footnote-reference-2">[2]</a></td><td><p class="first">You may be suspicious of this assumption - how can two tests for the
same disease be independent? Being suspicious about probability
independence assumptions is a good idea in general, but here the
assumption is reasonable.</p>
<p>Note that we assume independence given D; in other words, that
<object class="valign-m4" data="../../images/math/078820d4711ac1ab1b075b3b3e452a97424174c8.svg" style="height: 18px;" type="image/svg+xml">P(T_1|D)</object> and <object class="valign-m4" data="../../images/math/8934e9ba84564c2e86c8223fa4edf8ecf142349a.svg" style="height: 18px;" type="image/svg+xml">P(T_2|D)</object> are independent. We know the person
is sick, and we know that <object class="valign-m4" data="../../images/math/2885fa41d340ab94bb0451308cf01996f1916011.svg" style="height: 16px;" type="image/svg+xml">T_1</object> turned positive - does this affect
<object class="valign-m3" data="../../images/math/f725afdfa00dd57660feb233ef8547c9985c924e.svg" style="height: 15px;" type="image/svg+xml">T_2</object>? Depends on the test; some tests definitely test related
things, but some may test unrelated things (say the first looks for a
particular by-product of sick cells while the second looks for a gene
that is known to be correlated with disease prevalence). It's possible
to find plausible connections between almost anything though, so all
independence assumptions are &quot;best-effort&quot;.</p>
<p class="last">It's also important to state that <object class="valign-m4" data="../../images/math/2885fa41d340ab94bb0451308cf01996f1916011.svg" style="height: 16px;" type="image/svg+xml">T_1</object> and <object class="valign-m3" data="../../images/math/f725afdfa00dd57660feb233ef8547c9985c924e.svg" style="height: 15px;" type="image/svg+xml">T_2</object> are not
independent unconditionally. If we don't know whether the person has the
disease yet, a positive <object class="valign-m4" data="../../images/math/2885fa41d340ab94bb0451308cf01996f1916011.svg" style="height: 16px;" type="image/svg+xml">T_1</object> result will certainly affect our
estimate of how likely <object class="valign-m3" data="../../images/math/f725afdfa00dd57660feb233ef8547c9985c924e.svg" style="height: 15px;" type="image/svg+xml">T_2</object> is to turn out positive as well.</p>
</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="footnote-3" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#footnote-reference-3">[3]</a></td><td>My intuition for understanding why it's higher is that there's a tug of
war between the test accuracy and the prevalence (the lower the
prevalence, the higher the test accuracy has to be to produce reasonable
predivtive value). But when we recompute with two tests, we still use
prevalence just once in the formula, so the two tests combine forces
against it.</td></tr>
</tbody>
</table>
</div>

            </div>
            <!-- /.entry-content -->
<hr/>
<div class="dotted-links">
<p class="align-center">
For comments, please send me
<a href="mailto:eliben@gmail.com"><i class="fa fa-envelope-o"></i> an email</a>.
</p>
</div>        </article>
    </section>

    </div>
</div>
<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">
            &copy; 2003-2025 Eli Bendersky
         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="http://code.jquery.com/jquery-2.2.4.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="../../theme/js/bootstrap.min.js"></script>

<!--
  Using goatcounter to count visitors. The count.js script is vendored in.
-->
<script data-goatcounter="https://stats.thegreenplace.net/count"
        async src="../../theme/js/count.js"></script>
</body>

<!-- Mirrored from eli.thegreenplace.net/2018/conditional-probability-and-bayes-theorem/ by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 16 Feb 2025 23:58:37 GMT -->
</html>