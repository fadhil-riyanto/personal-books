<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"
      xmlns:og="http://ogp.me/ns#"
      xmlns:fb="https://www.facebook.com/2008/fbml">

<!-- Mirrored from eli.thegreenplace.net/2016/understanding-gradient-descent/ by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 16 Feb 2025 23:59:23 GMT -->
<head>
    <title>Understanding gradient descent - Eli Bendersky's website</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link href="../../favicon.ico" rel="icon">

    <!-- Bootstrap -->
        <link rel="stylesheet" href="../../theme/css/bootstrap.min.css" type="text/css"/>
    <link href="../../theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="../../theme/css/pygments/vs.css" rel="stylesheet">
    <link rel="stylesheet" href="../../theme/css/style.css" type="text/css"/>

        <link href="../../feeds/all.atom.xml" type="application/atom+xml" rel="alternate"
              title="Eli Bendersky's website ATOM Feed"/>

</head>
<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="../../index.html" class="navbar-brand">
                <img src="../../images/logosmall.png" width="32" height="32"/>
Eli Bendersky's website            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="../../pages/about.html">
                        <i class="fa fa-question"></i>
                        <span class="icon-label">About</span>
                    </a>
                </li>
                <li>
                    <a href="../../pages/projects.html">
                        <i class="fa fa-github"></i>
                        <span class="icon-label">Projects</span>
                    </a>
                </li>
                <li>
                    <a href="../../archives/all.html">
                        <i class="fa fa-th-list"></i>
                        <span class="icon-label">Archives</span>
                    </a>
                </li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->

<div class="container">
    <div class="row">
    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="index.html"
                       rel="bookmark"
                       title="Permalink to Understanding gradient descent">
                        Understanding gradient descent
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="published">
        <i class="fa fa-calendar"></i>
        <time> August 05, 2016 at 05:38</time>
    </span>
<span class="label label-default">Tags</span>
    <a href="../../tag/math.html">Math</a>
        ,
    <a href="../../tag/machine-learning.html">Machine Learning</a>
</footer><!-- /.post-info -->                    </div>
                </div>
                <p>Gradient descent is a standard tool for optimizing complex functions iteratively
within a computer program. Its goal is: given some arbitrary function, find a
minumum. For some small subset of functions - those that are <em>convex</em> - there's
just a single minumum which also happens to be global. For most realistic
functions, there may be many minima, so most minima are local. Making sure the
optimization finds the &quot;best&quot; minumum and doesn't get stuck in sub-optimial
minima is out of the scope of this article. Here we'll just be dealing with the
core gradient descent algorithm for finding <em>some</em> minumum from a given starting
point.</p>
<p>The main premise of gradient descent is: given some current location <em>x</em> in the
search space (the domain of the optimized function) we ought to update <em>x</em> for
the next step in the direction opposite to the gradient of the function computed
at <em>x</em>. But <em>why</em> is this the case? The aim of this article is to explain why,
mathematically.</p>
<p>This is also the place for a disclaimer: the examples used throughout the
article are trivial, low-dimensional, convex functions. We don't really <em>need</em>
an algorithmic procedure to find their global minumum - a quick computation
would do, or really just eyeballing the function's plot. In reality we will be
dealing with non-linear, 1000-dimensional functions where it's utterly
impossible to visualize anything, or solve anything analytically. The approach
works just the same there, however.</p>
<div class="section" id="building-intuition-with-single-variable-functions">
<h2>Building intuition with single-variable functions</h2>
<p>The gradient is formally defined for <em>multivariate</em> functions. However, to start
building intuition, it's useful to begin with the two-dimensional case, a
single-variable function <img alt="f(x)" class="valign-m4" src="../../images/math/3e03f4706048fbc6c5a252a85d066adf107fcc1f.png" style="height: 18px;" />.</p>
<p>In single-variable functions, the simple derivative plays the role of a
gradient. So &quot;gradient descent&quot; would really be &quot;derivative descent&quot;; let's see
what that means.</p>
<p>As an example, let's take the function <img alt="f(x)=(x-1)^2" class="valign-m4" src="../../images/math/b898d66867ea1e832ab5cda94453ab3a69bae865.png" style="height: 19px;" />. Here's its plot, in
red:</p>
<img alt="Plot of parabola with tangent lines" class="align-center" src="../../images/2016/plot-parabola-with-tangents.png" />
<p>I marked a couple of points on the plot, in blue, and drew the tangents to the
function at these points. Remember, our goal is to find the minimum of the
function. To do that, we'll start with a guess for an <em>x</em>, and continously
update it to improve our guess based on some computation. How do we know how to
update <em>x</em>? The update has only two possible directions: increase <em>x</em> or
decrease <em>x</em>. We have to decide which of the two directions to take.</p>
<p>We do that based on the derivative of <img alt="f(x)" class="valign-m4" src="../../images/math/3e03f4706048fbc6c5a252a85d066adf107fcc1f.png" style="height: 18px;" />. The derivative at some point
<img alt="x_0" class="valign-m3" src="../../images/math/efbda784ad565c1c5201fdc948a570d0426bc6e6.png" style="height: 11px;" /> is defined as the limit <a class="footnote-reference" href="#footnote-1" id="footnote-reference-1">[1]</a>:</p>
<img alt="\[\frac{d}{dx}f(x_0)=\lim_{h \to 0}\frac{f(x_0+h)-f(x_0)}{h}\]" class="align-center" src="../../images/math/bfd7f38f59e2ff0d548c19f8f780605b099ecaf7.png" style="height: 39px;" />
<p>Intuitively, this tells us what happens to <img alt="f(x)" class="valign-m4" src="../../images/math/3e03f4706048fbc6c5a252a85d066adf107fcc1f.png" style="height: 18px;" /> when we add a very small
value to <em>x</em>. For example in the plot above, at <img alt="x_0=3" class="valign-m3" src="../../images/math/5fa44ff4e2c914452bf56041b4ef99ceb61592f9.png" style="height: 15px;" /> we have:</p>
<img alt="\[\begin{align*} \frac{d}{dx}f(3)&amp;amp;=\lim_{h \to 0}\frac{f(3+h)-f(3)}{h} \\                 &amp;amp;=\lim_{h \to 0}\frac{(3+h-1)^2-(3-1)^2}{h} \\                 &amp;amp;=\lim_{h \to 0}\frac{h^2+4h}{h} \\                 &amp;amp;=\lim_{h \to 0}h+4=4 \end{align*}\]" class="align-center" src="../../images/math/e572beffc8415b4ba4c8c9419105863e3ce2082f.png" style="height: 168px;" />
<p>This means that the <em>slope</em> of <img alt="\frac{df}{dx}" class="valign-m6" src="../../images/math/45e7d07281bf1883224069f5b8d98a4bd6b21693.png" style="height: 23px;" /> at <img alt="x_0=3" class="valign-m3" src="../../images/math/5fa44ff4e2c914452bf56041b4ef99ceb61592f9.png" style="height: 15px;" /> is 4; for
a very small positive change <em>h</em> to <em>x</em> at that point, the value of <img alt="f(x)" class="valign-m4" src="../../images/math/3e03f4706048fbc6c5a252a85d066adf107fcc1f.png" style="height: 18px;" />
will increase by <em>4h</em>. Therefore, to get closer to the minimum of
<img alt="f(x)" class="valign-m4" src="../../images/math/3e03f4706048fbc6c5a252a85d066adf107fcc1f.png" style="height: 18px;" /> we should rather <em>decrease</em> <img alt="x_0" class="valign-m3" src="../../images/math/efbda784ad565c1c5201fdc948a570d0426bc6e6.png" style="height: 11px;" /> a bit.</p>
<p>Let's take another example point, <img alt="x_0=-1" class="valign-m3" src="../../images/math/c84eef20ea61cf41b13fd1a157968eba20823c8e.png" style="height: 15px;" />. At that point, if we add a
little bit to <img alt="x_0" class="valign-m3" src="../../images/math/efbda784ad565c1c5201fdc948a570d0426bc6e6.png" style="height: 11px;" />, <img alt="f(x)" class="valign-m4" src="../../images/math/3e03f4706048fbc6c5a252a85d066adf107fcc1f.png" style="height: 18px;" /> will <em>decrease</em> by 4x that little
bit. So that's exactly what we should do to get closer to the minimum.</p>
<p>It turns out that in both cases, we should nudge <img alt="x_0" class="valign-m3" src="../../images/math/efbda784ad565c1c5201fdc948a570d0426bc6e6.png" style="height: 11px;" /> in the direction
opposite to the derivative at <img alt="x_0" class="valign-m3" src="../../images/math/efbda784ad565c1c5201fdc948a570d0426bc6e6.png" style="height: 11px;" />. That's the most basic idea behind
gradient descent - the derivative shows us the way to the minimum; or rather,
it shows us the way to the maximum and we then go in the opposite direction.
Given some initial guess <img alt="x_0" class="valign-m3" src="../../images/math/efbda784ad565c1c5201fdc948a570d0426bc6e6.png" style="height: 11px;" />, the next guess will be:</p>
<img alt="\[x_1=x_0-\eta\frac{d}{dx}f(x_0)\]" class="align-center" src="../../images/math/d8666c1e2cf8740af45a228730f7c632fc00ed14.png" style="height: 37px;" />
<p>Where <img alt="\eta" class="valign-m4" src="../../images/math/2899aeb886ad0fa72652bffd5511e452aaf084ab.png" style="height: 12px;" /> is what we call a &quot;learning rate&quot;, and is constant for each
given update. It's the reason why we don't care much about the magnitude of the
derivative at <img alt="x_0" class="valign-m3" src="../../images/math/efbda784ad565c1c5201fdc948a570d0426bc6e6.png" style="height: 11px;" />, only its direction. In general, it makes sense to
keep the learning rate fairly small so we only make a tiny step at at time. This
makes sense mathematically, because the derivative at a point is defined as the
rate of change of <img alt="f(x)" class="valign-m4" src="../../images/math/3e03f4706048fbc6c5a252a85d066adf107fcc1f.png" style="height: 18px;" /> assuming an infinitesimal change in <em>x</em>. For
some large change <em>x</em> who knows where we will get. It's easy to imagine cases
where we'll entirely overshoot the minimum by making too large a step <a class="footnote-reference" href="#footnote-2" id="footnote-reference-2">[2]</a>.</p>
</div>
<div class="section" id="multivariate-functions-and-directional-derivatives">
<h2>Multivariate functions and directional derivatives</h2>
<p>With functions of multiple variables, derivatives become more interesting. We
can't just say &quot;the derivative points to where the function is increasing&quot;,
because... which derivative?</p>
<p>Recall the formal definition of the derivative as the limit for a small step
<em>h</em>. When our function has many variables, which one should have the step added?
One at a time? All at once? In multivariate calculus, we use partial derivatives
as building blocks. Let's use a function of two variables - <img alt="f(x,y)" class="valign-m4" src="../../images/math/720aabe593c880dc58881240e567ecda2b89bdf4.png" style="height: 18px;" /> as an
example throughout this section, and define the partial derivatives w.r.t. <em>x</em>
and <em>y</em> at some point <img alt="(x_0,y_0)" class="valign-m4" src="../../images/math/f8b63792829adeff8314a72fa87be1a770dfca85.png" style="height: 18px;" />:</p>
<img alt="\[\begin{align*} \frac{\partial }{\partial x}f(x_0,y_0)&amp;amp;=\lim_{h \to 0}\frac{f(x_0+h,y_0)-f(x_0,y_0)}{h} \\ \frac{\partial }{\partial y}f(x_0,y_0)&amp;amp;=\lim_{h \to 0}\frac{f(x_0,y_0+h)-f(x_0,y_0)}{h} \end{align*}\]" class="align-center" src="../../images/math/b58dd3cada7292828cf79f3ca8653a99fd94c1f9.png" style="height: 87px;" />
<p>When we have a single-variable function <img alt="f(x)" class="valign-m4" src="../../images/math/3e03f4706048fbc6c5a252a85d066adf107fcc1f.png" style="height: 18px;" />, there's really only two
directions in which we can move from a given point <img alt="x_0" class="valign-m3" src="../../images/math/efbda784ad565c1c5201fdc948a570d0426bc6e6.png" style="height: 11px;" /> - left (decrease
<em>x</em>) or right (increase <em>x</em>). With two variables, the number of possible
directions is <em>infinite</em>, becase we pick a direction to move on a 2D plane.
Hopefully this immediately pops ups &quot;vectors&quot; in your head, since vectors are
the perfect tool to deal with such problems. We can represent the change from
the point <img alt="(x_0,y_0)" class="valign-m4" src="../../images/math/f8b63792829adeff8314a72fa87be1a770dfca85.png" style="height: 18px;" /> as the vector <img alt="\vec{v}=\langle a,b \rangle" class="valign-m5" src="../../images/math/4ef7c8a835491ba5ec6dc5f2b94ebff879938a21.png" style="height: 19px;" />
<a class="footnote-reference" href="#footnote-3" id="footnote-reference-3">[3]</a>.
The <em>directional derivative</em> of <img alt="f(x,y)" class="valign-m4" src="../../images/math/720aabe593c880dc58881240e567ecda2b89bdf4.png" style="height: 18px;" /> along <img alt="\vec{v}" class="valign-0" src="../../images/math/39a3a59a8f524cf72620db07b9ba7cdce9fc9391.png" style="height: 13px;" /> at
<img alt="(x_0,y_0)" class="valign-m4" src="../../images/math/f8b63792829adeff8314a72fa87be1a770dfca85.png" style="height: 18px;" /> is defined as its rate of change in the direction of the
vector at that point. Mathematically, it's defined as:</p>
<img alt="\[\begin{equation} D_{\vec{v}}f(x_0,y_0)=\lim_{h \to 0}\frac{f(x_0+ah,y_0+bh)-f(x_0,y_0)}{h} \tag{1} \end{equation}\]" class="align-center" src="../../images/math/1af5afd7427f744daa0c75b05697b32f21b2f40c.png" style="height: 39px;" />
<p>The partial derivatives w.r.t. <em>x</em> and <em>y</em> can be seen as special cases of this
definition. The partial derivative <img alt="\frac{\partial f}{\partial x}" class="valign-m7" src="../../images/math/75a2ab078215106a1084cf5e262e98f32c1cc3b9.png" style="height: 25px;" /> is just
the directional direvative in the direction of the <em>x</em> axis. In vector-speak,
this is the directional derivative for
<img alt="\vec{v}=\langle a,b \rangle=\widehat{e_x}=\langle 1,0 \rangle" class="valign-m5" src="../../images/math/36b4fd6cf884fd12b36c605cb6ec7a7c9b4ee65f.png" style="height: 19px;" />, the
standard basis vector for <em>x</em>. Just plug <img alt="a=1,b=0" class="valign-m4" src="../../images/math/7feadfc4043894ed6a3de2cced949a91bea9e5b2.png" style="height: 17px;" /> into (1) to see why.
Similarly, the partial derivative <img alt="\frac{\partial f}{\partial y}" class="valign-m9" src="../../images/math/5bc3d10d9714f8f7a95791fe29e497cf0ecbe3b0.png" style="height: 27px;" /> is the
directional derivative in the direction of the standard basis vector
<img alt="\widehat{e_y}=\langle 0,1 \rangle" class="valign-m6" src="../../images/math/3ce4793144c7bfd02d245b81f8bd44a595721196.png" style="height: 20px;" />.</p>
</div>
<div class="section" id="a-visual-interlude">
<h2>A visual interlude</h2>
<p>Functions of two variables <img alt="f(x,y)" class="valign-m4" src="../../images/math/720aabe593c880dc58881240e567ecda2b89bdf4.png" style="height: 18px;" /> are the last frontier for meaningful
visualizations, for which we need 3D to plot the value of <img alt="f" class="valign-m4" src="../../images/math/4a0a19218e082a343a1b17e5333409af9d98f0f5.png" style="height: 16px;" /> for each
given <em>x</em> and <em>y</em>. Even in 3D, visualizing gradients is significantly harder
than in 2D, and yet we have to try since for anything above two variables all
hopes of visualization are lost.</p>
<p>Here's the function <img alt="f(x,y)=x^2+y^2" class="valign-m4" src="../../images/math/d3eb0fc536d00e84cd63bb5af98b7e2bc01bde4f.png" style="height: 19px;" /> plotted in a small range around zero.
I drew the standard basis vectors <img alt="\widehat{x}=\widehat{e_x}" class="valign-m3" src="../../images/math/0ea0752aa73540ee1e464a42d5d1b2b9741d3eab.png" style="height: 17px;" /> and
<img alt="\widehat{y}=\widehat{e_y}" class="valign-m6" src="../../images/math/c0bf47cb98b1f01e6b47992929694ec9da20f8f7.png" style="height: 20px;" /> <a class="footnote-reference" href="#footnote-4" id="footnote-reference-4">[4]</a> and some combination of them
<img alt="\vec{v}" class="valign-0" src="../../images/math/39a3a59a8f524cf72620db07b9ba7cdce9fc9391.png" style="height: 13px;" />.</p>
<img alt="3D parabola with direction vector markers" class="align-center" src="../../images/2016/plot-3d-parabola.png" />
<p>I also marked the point on <img alt="f(x,y)" class="valign-m4" src="../../images/math/720aabe593c880dc58881240e567ecda2b89bdf4.png" style="height: 18px;" /> where the vectors are based. The goal
is to help us keep in mind how the independent variables <em>x</em> and <em>y</em> change, and
how that affects <img alt="f(x,y)" class="valign-m4" src="../../images/math/720aabe593c880dc58881240e567ecda2b89bdf4.png" style="height: 18px;" />. We change <em>x</em> and <em>y</em> by adding some small
vector <img alt="\vec{v}" class="valign-0" src="../../images/math/39a3a59a8f524cf72620db07b9ba7cdce9fc9391.png" style="height: 13px;" /> to their current value. The result is &quot;nudging&quot;
<img alt="f(x,y)" class="valign-m4" src="../../images/math/720aabe593c880dc58881240e567ecda2b89bdf4.png" style="height: 18px;" /> in the direction of <img alt="\vec{v}" class="valign-0" src="../../images/math/39a3a59a8f524cf72620db07b9ba7cdce9fc9391.png" style="height: 13px;" />. Remember our goal for this
article - find <img alt="\vec{v}" class="valign-0" src="../../images/math/39a3a59a8f524cf72620db07b9ba7cdce9fc9391.png" style="height: 13px;" /> such that this &quot;nudge&quot; gets us closer to a
minimum.</p>
</div>
<div class="section" id="finding-directional-derivatives-using-the-gradient">
<h2>Finding directional derivatives using the gradient</h2>
<p>As we've seen, the derivative of <img alt="f(x,y)" class="valign-m4" src="../../images/math/720aabe593c880dc58881240e567ecda2b89bdf4.png" style="height: 18px;" /> in the direction of
<img alt="\vec{v}" class="valign-0" src="../../images/math/39a3a59a8f524cf72620db07b9ba7cdce9fc9391.png" style="height: 13px;" /> is defined as:</p>
<img alt="\[D_{\vec{v}}f(x_0,y_0)=\lim_{h \to 0}\frac{f(x_0+ah,y_0+bh)-f(x_0,y_0)}{h}\]" class="align-center" src="../../images/math/9f2c62d64f016bd77712873294a0f5e64537b1ab.png" style="height: 39px;" />
<p>Looking at the 3D plot above, this is how much the value of <img alt="f(x,y)" class="valign-m4" src="../../images/math/720aabe593c880dc58881240e567ecda2b89bdf4.png" style="height: 18px;" />
changes when we add <img alt="\vec{v}" class="valign-0" src="../../images/math/39a3a59a8f524cf72620db07b9ba7cdce9fc9391.png" style="height: 13px;" /> to the vector <img alt="\langle x_0,y_0 \rangle" class="valign-m5" src="../../images/math/f74aa2c6fda35535931fad69ec339eaef3693913.png" style="height: 19px;" />. But how do we do that? This limit definition doesn't look like
something friendly for analytical analysis for arbitrary functions. Sure, we
could plug <img alt="(x_0,y_0)" class="valign-m4" src="../../images/math/f8b63792829adeff8314a72fa87be1a770dfca85.png" style="height: 18px;" /> and <img alt="\vec{v}" class="valign-0" src="../../images/math/39a3a59a8f524cf72620db07b9ba7cdce9fc9391.png" style="height: 13px;" /> in there and do the
computation, but it would be nice to have an easier-to-use formula. Luckily,
with the help of the gradient of <img alt="f(x,y)" class="valign-m4" src="../../images/math/720aabe593c880dc58881240e567ecda2b89bdf4.png" style="height: 18px;" /> it becomes much easier.</p>
<p>The gradient is a vector value we compute from a scalar function. It's defined
as:</p>
<img alt="\[\nabla f=\left \langle \frac{\partial f}{\partial x},\frac{\partial f}{\partial y} \right \rangle\]" class="align-center" src="../../images/math/03eab64984be412b6db132c2534bbecc006af47c.png" style="height: 43px;" />
<p>It turns out that given a vector <img alt="\vec{v}" class="valign-0" src="../../images/math/39a3a59a8f524cf72620db07b9ba7cdce9fc9391.png" style="height: 13px;" />, the directional derivative
<img alt="D_{\vec{v}}f" class="valign-m4" src="../../images/math/03a3931c968b3b6f26e82958785539d74db94293.png" style="height: 16px;" /> can be expressed as the following dot product:</p>
<img alt="\[D_{\vec{v}}f=(\nabla f) \cdot \vec{v}\]" class="align-center" src="../../images/math/49933775272512c4c8686d9f9692c8ea01e1c97d.png" style="height: 18px;" />
<p>If this looks like a mental leap too big to trust, please read the Appendix
section at the bottom. Otherwise, feel free to verify that the two are
equivalent with a couple of examples. For instance, try to find the derivative
in the direction of <img alt="\vec{v}=\langle \frac{1}{\sqrt{2}},\frac{1}{\sqrt{2}} \rangle" class="valign-m11" src="../../images/math/d614069c5beaf6fb858de40fa492a7b523a683d9.png" style="height: 27px;" />
at <img alt="(x_0,y_0)=(-1.5,0.25)" class="valign-m4" src="../../images/math/61355565f13944faf85baec62c5fc1a682b0b5d5.png" style="height: 18px;" />. You should get <img alt="\frac{-2.5}{\sqrt{2}}" class="valign-m11" src="../../images/math/0c22fc563236a48f94882876c68f6edc0c3fb4da.png" style="height: 27px;" /> using
both methods.</p>
</div>
<div class="section" id="direction-of-maximal-change">
<h2>Direction of maximal change</h2>
<p>We're almost there! Now that we have a relatively simple way of computing any
directional derivative from the partial derivatives of a function, we can
figure out which direction to take to get the maximal change in the value of
<img alt="f(x,y)" class="valign-m4" src="../../images/math/720aabe593c880dc58881240e567ecda2b89bdf4.png" style="height: 18px;" />.</p>
<p>We can rewrite:</p>
<img alt="\[D_{\vec{v}}f=(\nabla f) \cdot \vec{v}\]" class="align-center" src="../../images/math/49933775272512c4c8686d9f9692c8ea01e1c97d.png" style="height: 18px;" />
<p>As:</p>
<img alt="\[D_{\vec{v}}f=\left \| \nabla f \right \| \left \| \vec{v} \right \| cos(\theta)\]" class="align-center" src="../../images/math/8227de3117c60690ced3153cdc38d9bccd960fba.png" style="height: 19px;" />
<p>Where <img alt="\theta" class="valign-0" src="../../images/math/cb005d76f9f2e394a770c2562c2e150a413b3216.png" style="height: 12px;" /> is the angle between the two vectors. Now, recall that
<img alt="\vec{v}" class="valign-0" src="../../images/math/39a3a59a8f524cf72620db07b9ba7cdce9fc9391.png" style="height: 13px;" /> is normalized so its magnitude is 1. Therefore, we only care
about the <em>direction</em> of <img alt="\vec{v}" class="valign-0" src="../../images/math/39a3a59a8f524cf72620db07b9ba7cdce9fc9391.png" style="height: 13px;" /> w.r.t. the gradient. When is this
equation maximized? When <img alt="\theta=0" class="valign-0" src="../../images/math/a1dffbe89f1ec5a919198de979fca459eb7fdf84.png" style="height: 12px;" />, because then <img alt="cos(\theta)=1" class="valign-m4" src="../../images/math/66a6eb87ec7f340e2e24bd46cdf02ab050013aac.png" style="height: 18px;" />.
Since a cosine can never be larger than 1, that's the best we can have.</p>
<p>So <img alt="\theta=0" class="valign-0" src="../../images/math/a1dffbe89f1ec5a919198de979fca459eb7fdf84.png" style="height: 12px;" /> gives us the largest positive change in <img alt="f(x,y)" class="valign-m4" src="../../images/math/720aabe593c880dc58881240e567ecda2b89bdf4.png" style="height: 18px;" />. To
get <img alt="\theta=0" class="valign-0" src="../../images/math/a1dffbe89f1ec5a919198de979fca459eb7fdf84.png" style="height: 12px;" />, <img alt="\vec{v}" class="valign-0" src="../../images/math/39a3a59a8f524cf72620db07b9ba7cdce9fc9391.png" style="height: 13px;" /> has to point in the same direction as the
gradient. Similarly, for <img alt="\theta=180^{\circ}" class="valign-m1" src="../../images/math/f35bd3cc416e154fddabe833458147c566028a8c.png" style="height: 13px;" /> we get
<img alt="cos(\theta)=-1" class="valign-m4" src="../../images/math/65b96d5ab442e325098894e80d655263a24b14d6.png" style="height: 18px;" /> and therefore the largest <em>negative</em> change in
<img alt="f(x,y)" class="valign-m4" src="../../images/math/720aabe593c880dc58881240e567ecda2b89bdf4.png" style="height: 18px;" />. So if we want to decrease <img alt="f(x,y)" class="valign-m4" src="../../images/math/720aabe593c880dc58881240e567ecda2b89bdf4.png" style="height: 18px;" /> the most,
<img alt="\vec{v}" class="valign-0" src="../../images/math/39a3a59a8f524cf72620db07b9ba7cdce9fc9391.png" style="height: 13px;" /> has to point in the opposite direction of the gradient.</p>
</div>
<div class="section" id="gradient-descent-update-for-multivariate-functions">
<h2>Gradient descent update for multivariate functions</h2>
<p>To sum up, given some starting point <img alt="(x_0,y_0)" class="valign-m4" src="../../images/math/f8b63792829adeff8314a72fa87be1a770dfca85.png" style="height: 18px;" />, to nudge it in the
direction of the minimum of <img alt="f(x,y)" class="valign-m4" src="../../images/math/720aabe593c880dc58881240e567ecda2b89bdf4.png" style="height: 18px;" />, we first compute the gradient of
<img alt="f(x,y)" class="valign-m4" src="../../images/math/720aabe593c880dc58881240e567ecda2b89bdf4.png" style="height: 18px;" /> at <img alt="(x_0,y_0)" class="valign-m4" src="../../images/math/f8b63792829adeff8314a72fa87be1a770dfca85.png" style="height: 18px;" />. Then, we update (using vector notation):</p>
<img alt="\[\langle x_1,y_1 \rangle=\langle x_0,y_0 \rangle-\eta \nabla{f(x_0,y_0)}\]" class="align-center" src="../../images/math/66a0a92b6ff9a4c0d2162a41484ab17115f57bd7.png" style="height: 19px;" />
<p>Generalizing to multiple dimensions, let's say we have the function
<img alt="f:\mathbb{R}^n\rightarrow \mathbb{R}" class="valign-m4" src="../../images/math/5b4aba3ea35b9daec583b61ecb5a556ae28103e3.png" style="height: 16px;" /> taking the n-dimensional vector
<img alt="\vec{x}=(x_1,x_2 \dots ,x_n)" class="valign-m4" src="../../images/math/e8ece11f27b7cf7726e6ea055cfb0718761733e0.png" style="height: 18px;" />. We define the gradient update at step <em>k</em>
to be:</p>
<img alt="\[\vec{x}_{(k)}=\vec{x}_{(k-1)} - \eta \nabla{f(\vec{x}_{(k-1)})}\]" class="align-center" src="../../images/math/265d53b7832258e30f00049a1772e9f213140628.png" style="height: 20px;" />
<p>Previously, for the single-variate case we said that the derivatve points us
to the way to the minimum. Now we can say that while there are many ways to
get to the minimum (eventually), the gradient points us to the <em>fastest</em> way
from any given point.</p>
</div>
<div class="section" id="appendix-directional-derivative-definition-and-gradient">
<h2>Appendix: directional derivative definition and gradient</h2>
<p>This is an optional section for those who don't like taking mathematical
statements for granted. Now it's time to prove the equation shown earlier in
the article, and on which its main result is based:</p>
<img alt="\[D_{\vec{v}}f=(\nabla f) \cdot \vec{v}\]" class="align-center" src="../../images/math/49933775272512c4c8686d9f9692c8ea01e1c97d.png" style="height: 18px;" />
<p>As usual with proofs, it really helps to start by working through an example or
two to build up some intuition into why the equation works. Feel free to do that
if you'd like, using any function, starting point and direction vector
<img alt="\vec{v}" class="valign-0" src="../../images/math/39a3a59a8f524cf72620db07b9ba7cdce9fc9391.png" style="height: 13px;" />.</p>
<p>Suppose we define a function <img alt="w(t)" class="valign-m4" src="../../images/math/0382ffc90ae7b4c24238f68a32bebd14bc53c8d7.png" style="height: 18px;" /> as follows:</p>
<img alt="\[w(t)=f(x,y)\]" class="align-center" src="../../images/math/dc37eb3cf47966d7338e561faffeffbb291085c5.png" style="height: 18px;" />
<p>Where <img alt="x=x(t)" class="valign-m4" src="../../images/math/97aeb925cf8f501cc8836794ee06fb357b9d9a83.png" style="height: 18px;" /> and <img alt="y=y(t)" class="valign-m4" src="../../images/math/ebacc26a97fccf1aa96e1b59f21fcb2ca66c8924.png" style="height: 18px;" /> defined as:</p>
<img alt="\[\begin{align*} x(t)&amp;amp;=x_0+at \\ y(t)&amp;amp;=y_0+bt \end{align*}\]" class="align-center" src="../../images/math/27988a5772de0fe761873494e88f7cad887ede85.png" style="height: 45px;" />
<p>In these definitions, <img alt="x_0" class="valign-m3" src="../../images/math/efbda784ad565c1c5201fdc948a570d0426bc6e6.png" style="height: 11px;" />, <img alt="y_0" class="valign-m4" src="../../images/math/2bb5817d0f3bf8490a8c7b1343f84f9635e683a3.png" style="height: 12px;" />, <em>a</em> and <em>b</em> are constants, so
both <img alt="x(t)" class="valign-m4" src="../../images/math/62b10cd9e1396c7ea33fd211e67de2fb29019cfc.png" style="height: 18px;" /> and <img alt="y(t)" class="valign-m4" src="../../images/math/ed8576b7227103b62d3648e7d1bbdff4052b27ff.png" style="height: 18px;" /> are truly functions of a single variable.
Using <a class="reference external" href="../the-chain-rule-of-calculus.html">the chain rule</a>), we know that:</p>
<img alt="\[\frac{dw}{dt}=\frac{\partial f}{\partial x}\frac{dx}{dt}+\frac{\partial f}{\partial y}\frac{dy}{dt}\]" class="align-center" src="../../images/math/d5f4f13aeba35328cd2bea9b247842acb7524724.png" style="height: 41px;" />
<p>Substituting the derivatives of <img alt="x(t)" class="valign-m4" src="../../images/math/62b10cd9e1396c7ea33fd211e67de2fb29019cfc.png" style="height: 18px;" /> and <img alt="y(t)" class="valign-m4" src="../../images/math/ed8576b7227103b62d3648e7d1bbdff4052b27ff.png" style="height: 18px;" />, we get:</p>
<img alt="\[\frac{dw}{dt}=a\frac{\partial f}{\partial x}+b\frac{\partial f}{\partial y}\]" class="align-center" src="../../images/math/829069469d88717c9d95e3f788ed9e0c6cbeebc6.png" style="height: 41px;" />
<p>One more step, the significance of which will become clear shortly. Specifically,
the derivative of <img alt="w(t)" class="valign-m4" src="../../images/math/0382ffc90ae7b4c24238f68a32bebd14bc53c8d7.png" style="height: 18px;" /> at <img alt="t=0" class="valign-0" src="../../images/math/31056375cdff6a052261f18ceb3afe466731302a.png" style="height: 12px;" /> is:</p>
<img alt="\[\begin{equation} \frac{d}{dt}w(0)=a\frac{\partial}{\partial x}f(x_0,y_0)+b\frac{\partial}{\partial y}f(x_0,y_0) \tag{2} \end{equation}\]" class="align-center" src="../../images/math/ea579cad8f6c62a817f2253e1d596178ea673d37.png" style="height: 41px;" />
<p>Now let's see how to compute the derivative of <img alt="w(t)" class="valign-m4" src="../../images/math/0382ffc90ae7b4c24238f68a32bebd14bc53c8d7.png" style="height: 18px;" /> at <img alt="t=0" class="valign-0" src="../../images/math/31056375cdff6a052261f18ceb3afe466731302a.png" style="height: 12px;" /> using
the formal limit definition:</p>
<img alt="\[\begin{align*} \frac{d}{dt}w(0)&amp;amp;=\lim_{h \to 0}\frac{w(h)-w(0)}{h} \\                 &amp;amp;=\lim_{h \to 0}\frac{f(x_0+ah,b_0+bh)-f(x_0,y_0)}{h} \end{align*}\]" class="align-center" src="../../images/math/10a224da7b7ab2424b9f88edcbfe17f273f3bd8b.png" style="height: 84px;" />
<p>But the latter is precisely the definition of the directional derivative in
equation (1). Therefore, we can say that:</p>
<img alt="\[\frac{d}{dt}w(0)=D_{\vec{v}}f(x_0,y_0)\]" class="align-center" src="../../images/math/4f377110022c468e46cbdb32bfb11a072d11b330.png" style="height: 37px;" />
<p>From this and (2), we get:</p>
<img alt="\[\frac{d}{dt}w(0)=D_{\vec{v}}f(x_0,y_0)=a\frac{\partial}{\partial x}f(x_0,y_0)+b\frac{\partial}{\partial y}f(x_0,y_0)\]" class="align-center" src="../../images/math/d259ebf3697f480823a40247ce7191f9e954a584.png" style="height: 41px;" />
<p>This derivation is not special to the point <img alt="(x_0,y_0)" class="valign-m4" src="../../images/math/f8b63792829adeff8314a72fa87be1a770dfca85.png" style="height: 18px;" /> - it works just as
well for any point where <img alt="f(x,y)" class="valign-m4" src="../../images/math/720aabe593c880dc58881240e567ecda2b89bdf4.png" style="height: 18px;" /> has partial derivatives w.r.t. <em>x</em> and
<em>y</em>; therefore, for any point <img alt="(x,y)" class="valign-m4" src="../../images/math/d330d6e65470cb03e76e092ee47971f9e931f759.png" style="height: 18px;" /> where <img alt="f(x,y)" class="valign-m4" src="../../images/math/720aabe593c880dc58881240e567ecda2b89bdf4.png" style="height: 18px;" /> is
differentiable:</p>
<img alt="\[\begin{align*} D_{\vec{v}}f(x,y)&amp;amp;=a\frac{\partial}{\partial x}f(x,y)+b\frac{\partial}{\partial y}f(x,y) \\                      &amp;amp;=\left \langle \frac{\partial f}{\partial x},\frac{\partial f}{\partial y} \right \rangle \cdot \langle a,b \rangle \\                      &amp;amp;=(\nabla f) \cdot \vec{v} \qedhere \end{align*}\]" class="align-center" src="../../images/math/7c306dfedd474d99a62894e6258cea186d8be428.png" style="height: 115px;" />
<hr class="docutils" />
<table class="docutils footnote" frame="void" id="footnote-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#footnote-reference-1">[1]</a></td><td>The notation <img alt="\frac{d}{dx}f(x_0)" class="valign-m6" src="../../images/math/b0d6f765abf215972d5dbb982f77f1a83c233066.png" style="height: 22px;" /> means: the value of the
derivative of <img alt="f" class="valign-m4" src="../../images/math/4a0a19218e082a343a1b17e5333409af9d98f0f5.png" style="height: 16px;" /> w.r.t. <em>x</em>, evaluated at <img alt="x_0" class="valign-m3" src="../../images/math/efbda784ad565c1c5201fdc948a570d0426bc6e6.png" style="height: 11px;" />. Another
way to say the same would be <img alt="f{}&amp;#x27;(x_0)" class="valign-m4" src="../../images/math/e11c4ee90d42c3261aec6ef9c71893411b11cf34.png" style="height: 18px;" />.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="footnote-2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#footnote-reference-2">[2]</a></td><td>That said, in some advanced variations of gradient descent we actually
want to probe different areas of the function early on in the process,
so a larger step makes sense (remember, realistic functions have many
local minima and we want to find the best one). Further along in the
optimization process, when we've settled on a general area of the
function we want the learning rate to be small so we actually get to the
minimum. This approach is called <em>annealing</em> and I'll leave it for some
future article.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="footnote-3" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#footnote-reference-3">[3]</a></td><td>To avoid tracking vector magnitudes, from now on in the article we'll
be dealing with <em>normalized</em> direction vectors. That is, we always assume
that <img alt="\left \| \vec{v}  \right \|=1" class="valign-m5" src="../../images/math/d68cb9ca8e7b5fd7fe4a7c4548ed5d98b63292eb.png" style="height: 19px;" />.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="footnote-4" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#footnote-reference-4">[4]</a></td><td>Yes, <img alt="\widehat{y}" class="valign-m4" src="../../images/math/8cf4f01720ca8008752c182a8d3443aa2b174442.png" style="height: 18px;" /> is actually going in the opposite direction so
it's <img alt="-\widehat{e_y}" class="valign-m6" src="../../images/math/160a7a02c9645a3948812151b7a0cf38eb29c562.png" style="height: 20px;" />, but that really doesn't change anything.
It was easier to draw :)</td></tr>
</tbody>
</table>
</div>

            </div>
            <!-- /.entry-content -->
<hr/>
<div class="dotted-links">
<p class="align-center">
For comments, please send me
<a href="mailto:eliben@gmail.com"><i class="fa fa-envelope-o"></i> an email</a>.
</p>
</div>        </article>
    </section>

    </div>
</div>
<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">
            &copy; 2003-2025 Eli Bendersky
         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="http://code.jquery.com/jquery-2.2.4.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="../../theme/js/bootstrap.min.js"></script>

<!--
  Using goatcounter to count visitors. The count.js script is vendored in.
-->
<script data-goatcounter="https://stats.thegreenplace.net/count"
        async src="../../theme/js/count.js"></script>
</body>

<!-- Mirrored from eli.thegreenplace.net/2016/understanding-gradient-descent/ by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 16 Feb 2025 23:59:23 GMT -->
</html>