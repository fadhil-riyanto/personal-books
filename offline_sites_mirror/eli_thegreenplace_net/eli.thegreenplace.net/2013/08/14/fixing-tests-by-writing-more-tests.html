<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"
      xmlns:og="http://ogp.me/ns#"
      xmlns:fb="https://www.facebook.com/2008/fbml">

<!-- Mirrored from eli.thegreenplace.net/2013/08/14/fixing-tests-by-writing-more-tests by HTTrack Website Copier/3.x [XR&CO'2014], Mon, 17 Feb 2025 00:01:45 GMT -->
<head>
    <title>Fixing tests by writing more tests - Eli Bendersky's website</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link href="../../../favicon.ico" rel="icon">

    <!-- Bootstrap -->
        <link rel="stylesheet" href="../../../theme/css/bootstrap.min.css" type="text/css"/>
    <link href="../../../theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="../../../theme/css/pygments/vs.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../theme/css/style.css" type="text/css"/>

        <link href="../../../feeds/all.atom.xml" type="application/atom+xml" rel="alternate"
              title="Eli Bendersky's website ATOM Feed"/>

</head>
<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="../../../index.html" class="navbar-brand">
                <img src="../../../images/logosmall.png" width="32" height="32"/>
Eli Bendersky's website            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="../../../pages/about.html">
                        <i class="fa fa-question"></i>
                        <span class="icon-label">About</span>
                    </a>
                </li>
                <li>
                    <a href="../../../pages/projects.html">
                        <i class="fa fa-github"></i>
                        <span class="icon-label">Projects</span>
                    </a>
                </li>
                <li>
                    <a href="../../../archives/all.html">
                        <i class="fa fa-th-list"></i>
                        <span class="icon-label">Archives</span>
                    </a>
                </li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->

<div class="container">
    <div class="row">
    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="fixing-tests-by-writing-more-tests.html"
                       rel="bookmark"
                       title="Permalink to Fixing tests by writing more tests">
                        Fixing tests by writing more tests
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="published">
        <i class="fa fa-calendar"></i>
        <time> August 14, 2013 at 06:01</time>
    </span>
<span class="label label-default">Tags</span>
    <a href="../../../tag/programming.html">Programming</a>
        ,
    <a href="../../../tag/testing.html">Testing</a>
</footer><!-- /.post-info -->                    </div>
                </div>
                
        <p>When a test fails, the first instinct is usually to dive right in - go through the code, sprinkle printouts and logging statements all around, fire up the debugger, and so on. But often, the correct approach is to write additional tests. Does this sound crazy? Well, it isn't. It's one of those true and tried techniques used by many experienced programmers.</p>
<p>Allow me to elaborate. Tests for software fall broadly into the following categories. This taxonomy is a blunt generalization and varies considerably with software size and other characteristics. But it's not important in itself - I just use it to illustrate my point. So starting with the most specific and ending with the most general, these are:</p>
<ul class="simple">
<li>Unit tests</li>
<li>Module-level tests</li>
<li>Whole program tests</li>
<li>Integration tests (with other software)</li>
</ul>
<p>From the first item (highly specific, targeted tests) on the list to the last (very general tests), coverage grows, as well as the complexity of debugging a failure. Debugging a unit test failure is usually quite easy. Integration tests can be devilishly difficult to debug, or even isolate and analyze. An unrelated component of the system may start failing intermittently when some other component (which passed all of its own tests) is changed. A compiler may start generating wrong code, but only when bootstrapped by compiling itself. It's those cases that send programmers crying to their therapist's couch.</p>
<p>So back to my original point. I posit that a great way to debug general tests is to write additional specific tests. Your module-level tests are failing? Write more unit tests. Your integration tests are failing? Write additional whole program tests, module tests or unit tests. The more specific the new tests are, the better. Remember that the most specific tests are the easiest to debug.</p>
<p>Debugging is all about the scientific method - you make assumptions and test them. Based on the results you make additional assumptions. Rinse. Repeat. While pondering about why something doesn't work - fortify your assumptions by writing tests for them. Facing a failing high-level test, try to write a more specific test that also fails. The benefits of this are two-fold. First, this will help you find the bug. Bugs are usually results of bad assumptions. This is especially true on the high generality level when pieces of software get integrated with others. More specific tests help verify those assumptions and are easier to debug. Second, you'll have more tests in the system when this bug-hunt ends, and that's always a good thing.</p>

    
            </div>
            <!-- /.entry-content -->
<hr/>
<div class="dotted-links">
<p class="align-center">
For comments, please send me
<a href="mailto:eliben@gmail.com"><i class="fa fa-envelope-o"></i> an email</a>.
</p>
</div>        </article>
    </section>

    </div>
</div>
<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">
            &copy; 2003-2025 Eli Bendersky
         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="http://code.jquery.com/jquery-2.2.4.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="../../../theme/js/bootstrap.min.js"></script>

<!--
  Using goatcounter to count visitors. The count.js script is vendored in.
-->
<script data-goatcounter="https://stats.thegreenplace.net/count"
        async src="../../../theme/js/count.js"></script>
</body>

<!-- Mirrored from eli.thegreenplace.net/2013/08/14/fixing-tests-by-writing-more-tests by HTTrack Website Copier/3.x [XR&CO'2014], Mon, 17 Feb 2025 00:01:45 GMT -->
</html>