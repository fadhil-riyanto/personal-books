<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"
      xmlns:og="http://ogp.me/ns#"
      xmlns:fb="https://www.facebook.com/2008/fbml">

<!-- Mirrored from eli.thegreenplace.net/2022/some-clues-to-understanding-benfords-law/ by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 16 Feb 2025 23:56:46 GMT -->
<head>
    <title>Some clues to understanding Benford's law - Eli Bendersky's website</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link href="../../favicon.ico" rel="icon">

    <!-- Bootstrap -->
        <link rel="stylesheet" href="../../theme/css/bootstrap.min.css" type="text/css"/>
    <link href="../../theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="../../theme/css/pygments/vs.css" rel="stylesheet">
    <link rel="stylesheet" href="../../theme/css/style.css" type="text/css"/>

        <link href="../../feeds/all.atom.xml" type="application/atom+xml" rel="alternate"
              title="Eli Bendersky's website ATOM Feed"/>

</head>
<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="../../index.html" class="navbar-brand">
                <img src="../../images/logosmall.png" width="32" height="32"/>
Eli Bendersky's website            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="../../pages/about.html">
                        <i class="fa fa-question"></i>
                        <span class="icon-label">About</span>
                    </a>
                </li>
                <li>
                    <a href="../../pages/projects.html">
                        <i class="fa fa-github"></i>
                        <span class="icon-label">Projects</span>
                    </a>
                </li>
                <li>
                    <a href="../../archives/all.html">
                        <i class="fa fa-th-list"></i>
                        <span class="icon-label">Archives</span>
                    </a>
                </li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->

<div class="container">
    <div class="row">
    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="index.html"
                       rel="bookmark"
                       title="Permalink to Some clues to understanding Benford's law">
                        Some clues to understanding Benford's law
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="published">
        <i class="fa fa-calendar"></i>
        <time> March 12, 2022 at 06:03</time>
    </span>
<span class="label label-default">Tags</span>
    <a href="../../tag/math.html">Math</a>
</footer><!-- /.post-info -->                    </div>
                </div>
                <p><a class="reference external" href="https://en.wikipedia.org/wiki/Benford%27s_law">Benford's law</a> is a really
fascinating observation that in many real-life sets of numerical data, the
first digit is most likely to be 1, and every digit <tt class="docutils literal">d</tt> is more common than
<tt class="docutils literal">d+1</tt>. Here's a table of the probability distribution, from Wikipedia:</p>
<img alt="Benford's law table from wikipedia" class="align-center" src="../../images/2022/wikipedia-benford-table.png" />
<p>Now, the caveat &quot;<em>real-life</em> data sets&quot; is really important. Specifically, this
only applies when the data spans several orders of magnitude. Clearly, if we're
measuring the height in inches of some large group of adults, the
overwhelming majority of data will lie between 50 and 85 inches, and won't
follow Benford's law. Another aspect of real-life data is that it's non random;
if we take a bunch of truly random numbers spanning several orders of magnitude,
their leading digit won't follow Benford's law either.</p>
<p>In this short post I'll try to explain how I understand Benford's law, and why
it intuitively makes sense. During the post I'll collect a set of <strong>clues</strong>,
which will help get the intuition in place eventually. By the way, we've already
encountered our first clues:</p>
<ul class="simple">
<li><strong>Clue 1</strong>: Benford's law only works on real-life data.</li>
<li><strong>Clue 2</strong>: Benford's law isn't just about the digit 1; 2 is more common than
3, 3 is more common than 4 etc.</li>
</ul>
<div class="section" id="real-world-example">
<h2>Real-world example</h2>
<p>First, let's start with a real-world demonstration of the law in action. I
found a data table of the populations of California's ~480 largest cities, and
ran an analysis of the
population number's leading digit <a class="footnote-reference" href="#footnote-1" id="footnote-reference-1">[1]</a>. Clearly, this is real-life data, and it
also spans many orders of magnitude (from LA at 3.9 mln to Amador with 153
inhabitants). Indeed, Benford's law applies beautifully on this data:</p>
<img alt="Distribution of first digit in population of California cities" class="align-center" src="../../images/2022/benford-ca-cities.png" />
<p>Eyeballing the city population data, we'll notice something important but also
totally intuitive: most cities are small. There are many more small cities than
large ones. Out of the 480 cities in our data set, only 74 have population over
100k, for example.</p>
<p>The same is true of other real-world data sets; for example, if we take a
snapshot of stock prices of S&amp;P 500 companies at some historic point, the prices
range from $1806 to $2, though 90% are under $182 and 65% are under $100.</p>
<ul class="simple">
<li><strong>Clue 3</strong>: in real-world data distributed along many orders of magnitude,
smaller data points are more common than larger data points.</li>
</ul>
<p>Statistically, this is akin to saying that the data follows the <a class="reference external" href="https://en.wikipedia.org/wiki/Pareto_distribution">Pareto
distribution</a>, of which the
&quot;80-20 rule&quot; - known as the <a class="reference external" href="https://en.wikipedia.org/wiki/Pareto_principle">Pareto principle</a> - is a special case.
Another similar mathematical description (applied to discrete probability
distributions) is <a class="reference external" href="https://en.wikipedia.org/wiki/Zipf%27s_law">Zipf's law</a>.</p>
</div>
<div class="section" id="logarithmic-scale">
<h2>Logarithmic scale</h2>
<p>To reiterate, a lot of real-world data isn't really uniformly distributed.
Rather, it follows a Pareto distribution where smaller numbers are more common.
Here's a useful logarithmic scale borrowed from Wikipedia - this could be the
X axis of any logarithmic plot:</p>
<img alt="Logarithmic scale bar from wikipedia" class="align-center" src="../../images/2022/logscale-wikipedia.png" />
<p>In this image, smaller values get more &quot;real estate&quot; on the X axis, which is
fair for our distribution if smaller numbers are more common than larger
numbers. It should not be hard to convince yourself that every time we &quot;drop a
pin&quot; on this scale, the chance of the leading digit being 1 is the highest.
Another (related) way to look at it is - when smaller numbers are more common it
takes a 100% percent increase to go from leading digit being 1 to it being 2,
but only a 50% increase to go from 2 to 3, etc.</p>
<ul class="simple">
<li><strong>Clue 4</strong>: on a logarithmic scale, the distance between numbers starting
with 1s and numbers starting with 2s is bigger than the distance between
numbers starting with 2s and numbers starting with 3s, and so on.</li>
</ul>
<p>We can visualize this in another way; let's plot the ratio of numbers starting
with 1 among all numbers up to some point. On the X axis we'll place N which
means &quot;in all numbers up to N&quot;, and on the Y axis we'll place the ratio of
numbers <tt class="docutils literal">i</tt> between 0 and N that start with 1:</p>
<img alt="Jagged graph of P(digit=1) for all numbers up to N" class="align-center" src="../../images/2022/digit1p.png" />
<p>Note that whenever some new order of magnitude is reached, the ratio starts to
climb steadily until it reaches ~0.5 (because there are just as many numbers
with D digits as numbers starting with 1 and followed by another D digits);
it then starts falling until it reaches ~0.1 just before we flip to the next
order of magnitude (because in all D-digit numbers, numbers starting with each
digit are one tenth of the population). If we calculate the smoothed average of
this graph over time, it ends up at about 0.3, which corresponds to Benford's
law.</p>
</div>
<div class="section" id="summary">
<h2>Summary</h2>
<p>When I'm thinking of Benford's law, the observation that really brings it home
for me is that &quot;smaller numbers are more common than larger numbers&quot; (this is
clue 3). This property of many realistic data sets, along with an understanding
of the logarithmic scale (the penultimate image above) is really all you need
to intuitively grok Benford's law.</p>
<p>Benford's law is also famous for being scale-invariant (by typically applying
regardless of the unit of measurement) and base-invariant (works in bases other
than 10). Hopefully, this post makes it clear why these properties are expected
to be true.</p>
<hr class="docutils" />
<table class="docutils footnote" frame="void" id="footnote-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#footnote-reference-1">[1]</a></td><td>All the (hacky Go) code and data required to generate the plots in this
post is available <a class="reference external" href="https://github.com/eliben/code-for-blog/tree/main/2022/benford">on GitHub</a>.</td></tr>
</tbody>
</table>
</div>

            </div>
            <!-- /.entry-content -->
<hr/>
<div class="dotted-links">
<p class="align-center">
For comments, please send me
<a href="mailto:eliben@gmail.com"><i class="fa fa-envelope-o"></i> an email</a>.
</p>
</div>        </article>
    </section>

    </div>
</div>
<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">
            &copy; 2003-2025 Eli Bendersky
         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="http://code.jquery.com/jquery-2.2.4.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="../../theme/js/bootstrap.min.js"></script>

<!--
  Using goatcounter to count visitors. The count.js script is vendored in.
-->
<script data-goatcounter="https://stats.thegreenplace.net/count"
        async src="../../theme/js/count.js"></script>
</body>

<!-- Mirrored from eli.thegreenplace.net/2022/some-clues-to-understanding-benfords-law/ by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 16 Feb 2025 23:56:46 GMT -->
</html>