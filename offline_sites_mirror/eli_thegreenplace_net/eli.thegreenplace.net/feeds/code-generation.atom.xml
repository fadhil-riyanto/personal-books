<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Eli Bendersky's website - Code generation</title><link href="https://eli.thegreenplace.net/" rel="alternate"></link><link href="https://eli.thegreenplace.net/feeds/code-generation.atom.xml" rel="self"></link><id>https://eli.thegreenplace.net/</id><updated>2024-05-04T19:46:23-07:00</updated><entry><title>Adventures in JIT compilation: Part 4 - in Python</title><link href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-4-in-python/" rel="alternate"></link><published>2017-05-10T05:31:00-07:00</published><updated>2024-05-04T19:46:23-07:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2017-05-10:/2017/adventures-in-jit-compilation-part-4-in-python/</id><summary type="html">&lt;p&gt;This is part 4 in a series of posts on writing JIT compilers for BF.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-1-an-interpreter/"&gt;Part 1 - an interpreter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-2-an-x64-jit/"&gt;Part 2 - an x64 JIT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-3-llvm/"&gt;Part 3 - LLVM&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Even though, for performance considerations, most JIT compilers are written in
down-to-metal languages like C and C++, in some scenarios it could be â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is part 4 in a series of posts on writing JIT compilers for BF.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-1-an-interpreter/"&gt;Part 1 - an interpreter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-2-an-x64-jit/"&gt;Part 2 - an x64 JIT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-3-llvm/"&gt;Part 3 - LLVM&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Even though, for performance considerations, most JIT compilers are written in
down-to-metal languages like C and C++, in some scenarios it could be useful
to write them in higher-level languages as well &lt;a class="footnote-reference" href="#footnote-1" id="footnote-reference-1"&gt;[1]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This post intends to do just that, by presenting yet another JIT for BF - this
time written in Python. It presents both a low-level approach to JITing native
machine code, and using a higher-level library to perform instruction encoding.
The JIT implemented here is not optimized (equivalent to the &amp;quot;simple&amp;quot; JIT from
part 2), so I'm not going to discuss any performance results. The idea is just
to show how JITing in Python works.&lt;/p&gt;
&lt;div class="section" id="how-to-jit-from-python"&gt;
&lt;h2&gt;How to JIT from Python&lt;/h2&gt;
&lt;p&gt;To be able to JIT-compile BF, we should first be capable of JITing any code at
all. It's worth showing how to do this in plain Python without any third-party
libraries. In &lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-2-an-x64-jit/"&gt;part 2 of the series&lt;/a&gt;
we've used the same approach as presented in my older &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/11/05/how-to-jit-an-introduction"&gt;How to JIT&lt;/a&gt; post for
basic JITing by copying machine code into an executable memory segment and
jumping to it.&lt;/p&gt;
&lt;p&gt;That was done in C and C++, but it turns out it's not much harder in Python due
to the magic of &lt;tt class="docutils literal"&gt;ctypes&lt;/tt&gt;. I've written about &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/03/09/python-ffi-with-ctypes-and-cffi"&gt;doing runtime calls to C code
via ctypes before&lt;/a&gt;, and
if you're not familiar with this wonderful tool, I encourage you to read more
about it. What follows is a complete code sample that implements the JITing
presented in the &amp;quot;How to JIT&amp;quot; post; it's heavily commented, so it should be
reasonably clear what's going on:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;ctypes&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;mmap&lt;/span&gt;

&lt;span class="c1"&gt;# Equivalent to dlopen(NULL) to open the main process; this means the Python&lt;/span&gt;
&lt;span class="c1"&gt;# interpreter, which links the C library in. Alternatively, we could open&lt;/span&gt;
&lt;span class="c1"&gt;# libc.so.6 directly (for Linux).&lt;/span&gt;
&lt;span class="n"&gt;libc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ctypes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cdll&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LoadLibrary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Grab the mmap foreign function from libc, setting its signature to:&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;#     void *mmap(void *addr, size_t length, int prot, int flags,&lt;/span&gt;
&lt;span class="c1"&gt;#                int fd, off_t offset)&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# Per the mmap(2) man page.&lt;/span&gt;
&lt;span class="n"&gt;mmap_function&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;libc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mmap&lt;/span&gt;
&lt;span class="n"&gt;mmap_function&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;restype&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ctypes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c_void_p&lt;/span&gt;
&lt;span class="n"&gt;mmap_function&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argtypes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctypes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c_void_p&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ctypes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c_size_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                          &lt;span class="n"&gt;ctypes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c_int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ctypes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c_int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                          &lt;span class="n"&gt;ctypes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c_int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ctypes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c_size_t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;CODE_SIZE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt;

&lt;span class="c1"&gt;# Allocate RWX memory with mmap. Using mmap from libc directly rather than&lt;/span&gt;
&lt;span class="c1"&gt;# Python&amp;#39;s mmap module here because the latter returns a special &amp;quot;mmap object&amp;quot;&lt;/span&gt;
&lt;span class="c1"&gt;# and we just need the raw address of the mapping. However, we will use the&lt;/span&gt;
&lt;span class="c1"&gt;# PROT_* and MAP_* constants from the mmap module rather than duplicating them.&lt;/span&gt;
&lt;span class="n"&gt;code_address&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mmap_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;CODE_SIZE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                             &lt;span class="n"&gt;mmap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PROT_READ&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;mmap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PROT_WRITE&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;mmap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PROT_EXEC&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                             &lt;span class="n"&gt;mmap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MAP_PRIVATE&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;mmap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MAP_ANONYMOUS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                             &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;code_address&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;OSError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;mmap failed to allocate memory&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Emit code into the allocated address. This sequence of x86-64 machine code&lt;/span&gt;
&lt;span class="c1"&gt;# encodes:&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;#  mov %rdi, %rax&lt;/span&gt;
&lt;span class="c1"&gt;#  add $4, %rax&lt;/span&gt;
&lt;span class="c1"&gt;#  ret&lt;/span&gt;
&lt;span class="n"&gt;code&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;b&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\x48\x89\xf8\x48\x83\xc0\x04\xc3&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;
&lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;CODE_SIZE&lt;/span&gt;
&lt;span class="n"&gt;ctypes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;memmove&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;code_address&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;code&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# Declare the type for our JITed function: long (*JitFuncType)(long), and cast&lt;/span&gt;
&lt;span class="c1"&gt;# code_address (which is a void*) to this type so we could just call it.&lt;/span&gt;
&lt;span class="n"&gt;JitFuncType&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ctypes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CFUNCTYPE&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctypes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c_long&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ctypes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c_long&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;function&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ctypes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;code_address&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;JitFuncType&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you execute this code it will print -96, since the JITed function adds 4 to
its argument.&lt;/p&gt;
&lt;p&gt;From this point on, it should be easy to implement a full JIT-compiler for BF
using hand-rolled instruction encoding, just like in &lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-2-an-x64-jit/"&gt;part 2&lt;/a&gt;.
Feel free to do it as an exercise :) You'll face the same issue discussed in
that post - manually encoding instructions and resolving labels/branches is
tedious, and it would be nice if a library could do it for us.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="peachpy"&gt;
&lt;h2&gt;PeachPy&lt;/h2&gt;
&lt;p&gt;Enter &lt;a class="reference external" href="https://github.com/Maratyszcza/PeachPy"&gt;PeachPy&lt;/a&gt; - an x86-64 assembler
embedded in Python. It's a relatively new project mostly aimed at writing
highly-optimized assembly kernels for numerical computations without leaving the
domain of Python. It even has a cute logo:&lt;/p&gt;
&lt;img alt="PeachPy logo" class="align-center" src="https://eli.thegreenplace.net/images/2017/peachpy.png" /&gt;
&lt;p&gt;PeachPy has some examples strewn around the web, and my code for this post can
serve as another example. Let's start by replicating the simple JIT
functionality shown above. PeachPy takes care of all the memory mapping behind
the scenes &lt;a class="footnote-reference" href="#footnote-2" id="footnote-reference-2"&gt;[2]&lt;/a&gt;, so the full code we need to write is just this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;peachpy&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;peachpy.x86_64&lt;/span&gt;

&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int64_t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Add4&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int64_t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;asm_function&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LOAD&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ARGUMENT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ADD&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RETURN&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rax&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;abi&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;abi&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;detect&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;encoded_function&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;asm_function&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;finalize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;abi&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;python_function&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;encoded_function&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;# The JIT call&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;python_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;PeachPy lets us write our code in &lt;em&gt;assembly&lt;/em&gt; rather than directly in machine
code, and it also handles the loading for us. As we'll see soon, it lets us use
symbolic labels (just like &lt;tt class="docutils literal"&gt;asmjit&lt;/tt&gt;) and takes care of jump target resolution
automatically. In other words, it's just the tool we need to focus on our domain
- compiling BF - without worrying too much about the low level details.&lt;/p&gt;
&lt;p&gt;Note how PeachPy uses Python's context managers (a very common approach for DSLs
embedded in Python). The &lt;tt class="docutils literal"&gt;with peachpy.x86_64.Function&lt;/tt&gt; statement creates a
context manager within which all assembly instructions (like &lt;tt class="docutils literal"&gt;ADD&lt;/tt&gt; and
&lt;tt class="docutils literal"&gt;RETURN&lt;/tt&gt;) are appended to the function.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="jit-compiling-bf-via-peachpy"&gt;
&lt;h2&gt;JIT-compiling BF via PeachPy&lt;/h2&gt;
&lt;p&gt;With the &lt;tt class="docutils literal"&gt;Add4&lt;/tt&gt; sample above, we actually already have most of the building
blocks we need to JIT-compile BF. What remains is just a matter of digging in
PeachPy's source and examples (sadly there's very little documentation) to
figure out how to invoke and properly use its assembly primitives. The following
is very similar to how &lt;tt class="docutils literal"&gt;simpleasmjit&lt;/tt&gt; is implemented in part 2. The full code
sample is &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/blob/main/2017/bfjit/peachpyjit.py"&gt;available here&lt;/a&gt;;
I'll just highlight the important snippets of code. First the function
&amp;quot;declaration&amp;quot;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Create a JITed function named &amp;quot;ppjit&amp;quot;, with the C-style signature:&lt;/span&gt;
&lt;span class="c1"&gt;#   void ppjit(uint8_t* memptr)&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="n"&gt;memptr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ptr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uint8_t&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;ppjit&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                             &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;memptr&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                             &lt;span class="n"&gt;result_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;asm_function&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;# Use r13 as our data pointer; initially it points at the memory buffer&lt;/span&gt;
    &lt;span class="c1"&gt;# passed into the JITed function.&lt;/span&gt;
    &lt;span class="n"&gt;dataptr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;r13&lt;/span&gt;
    &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LOAD&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ARGUMENT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;memptr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this code we'll be passing &lt;tt class="docutils literal"&gt;memory&lt;/tt&gt; from the host side (from Python, in
this case), so the function signature is &lt;tt class="docutils literal"&gt;void &lt;span class="pre"&gt;(*ppjit)(uint8_t*)&lt;/span&gt;&lt;/tt&gt;. We then
give &lt;tt class="docutils literal"&gt;r13&lt;/tt&gt; the symbolic name &lt;tt class="docutils literal"&gt;dataptr&lt;/tt&gt;. The usual instruction-by-instruction
BF compilation loop follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;instr&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;parse_bf_program&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bf_file&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;instr&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ADD&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;instr&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;lt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SUB&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;instr&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;+&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ADD&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;instr&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;-&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SUB&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;PeachPy dresses Python in assembly-like flavor. Registers placed in brackets
like &lt;tt class="docutils literal"&gt;[dataptr]&lt;/tt&gt; imply dereferencing. While &lt;tt class="docutils literal"&gt;dataptr&lt;/tt&gt; refers to the value of
the &lt;tt class="docutils literal"&gt;r13&lt;/tt&gt; register itself, &lt;tt class="docutils literal"&gt;[dataptr]&lt;/tt&gt; refers to the value of the memory
word whose address is held in &lt;tt class="docutils literal"&gt;dataptr&lt;/tt&gt; - this is similar to the syntax of
many assembly languages.&lt;/p&gt;
&lt;p&gt;For emitting I/O operations, we resort to syscalls again &lt;a class="footnote-reference" href="#footnote-3" id="footnote-reference-3"&gt;[3]&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;instr&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;# Invoke the WRITE syscall (rax=1) with stdout (rdi=1).&lt;/span&gt;
    &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MOV&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MOV&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rdi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MOV&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rsi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MOV&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rdx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SYSCALL&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;instr&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;# Invoke the READ syscall (rax=0) with stdin (rdi=0).&lt;/span&gt;
    &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MOV&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MOV&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rdi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MOV&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rsi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MOV&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rdx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SYSCALL&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For emitting the loops, we use a stack of PeachPy &lt;tt class="docutils literal"&gt;Label&lt;/tt&gt; objects with one
label for the loop and another for the &amp;quot;after loop&amp;quot;. Again, this is &lt;em&gt;very&lt;/em&gt;
similar to how it was done with &lt;tt class="docutils literal"&gt;asmjit&lt;/tt&gt; in &lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-2-an-x64-jit/"&gt;part 2&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;instr&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;[&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;# Create labels for the loop start and after-loop.&lt;/span&gt;
    &lt;span class="n"&gt;loop_start_label&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Label&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;loop_end_label&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Label&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="c1"&gt;# Jump to after the loop if the current cell is 0.&lt;/span&gt;
    &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CMP&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;JZ&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loop_end_label&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# Bind the &amp;quot;start loop&amp;quot; label here.&lt;/span&gt;
    &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LABEL&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loop_start_label&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;open_bracket_stack&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;BracketLabels&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loop_start_label&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;loop_end_label&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;instr&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;]&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;open_bracket_stack&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;die&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;unmatched closing &amp;quot;]&amp;quot; at pc=&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;open_bracket_stack&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="c1"&gt;# Jump back to loop if the current cell is not 0.&lt;/span&gt;
    &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CMP&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;JNZ&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open_label&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# Bind the &amp;quot;after-loop&amp;quot; label here.&lt;/span&gt;
    &lt;span class="n"&gt;peachpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LABEL&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close_label&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, this is how the JITed function is invoked:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Allocate memory as a ctypes array and initialize it to 0s. Then perform&lt;/span&gt;
&lt;span class="c1"&gt;# the JIT call.&lt;/span&gt;
&lt;span class="n"&gt;memsize&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;30000&lt;/span&gt;
&lt;span class="n"&gt;MemoryArrayType&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ctypes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c_uint8&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;memsize&lt;/span&gt;
&lt;span class="n"&gt;memory&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MemoryArrayType&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;memsize&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;There's just a little bit of trickiness here in our usage of &lt;tt class="docutils literal"&gt;ctypes&lt;/tt&gt;. Since
we have to pass arguments to C functions, &lt;tt class="docutils literal"&gt;ctypes&lt;/tt&gt; lets us declare C-like
types like &lt;tt class="docutils literal"&gt;MemoryArrayType&lt;/tt&gt; which is a &lt;tt class="docutils literal"&gt;uint8_t[30000]&lt;/tt&gt;. The funky syntax
on the following line is nothing more than Python's &lt;tt class="docutils literal"&gt;*args&lt;/tt&gt; destructuring of a
list of 30000 zeros. So &lt;tt class="docutils literal"&gt;memory&lt;/tt&gt; is now an object we can safely pass to our
JITed function which expects a &lt;tt class="docutils literal"&gt;uint8_t*&lt;/tt&gt; argument:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;python_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This calls the JITed function, the result of which is I/O and modified memory
cells in &lt;tt class="docutils literal"&gt;memory&lt;/tt&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="peachpy-more-features-and-some-limitations"&gt;
&lt;h2&gt;PeachPy - more features and some limitations&lt;/h2&gt;
&lt;p&gt;My usage of PeachPy in this post has been fairly limited, and the library has
many more features. For example:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Since PeachPy was mainly developed to write fast mathematical kernels, it
has fairly good support for the newest vector extensions like AVX512.&lt;/li&gt;
&lt;li&gt;There's some support for automatic register allocation. In the BF JIT, the
&lt;tt class="docutils literal"&gt;r13&lt;/tt&gt; register is used directly, but we don't &lt;em&gt;really&lt;/em&gt; care which register
it is. We could ask PeachPy for a &amp;quot;general purpose 64-bit register&amp;quot; and it
would allocate one for us. When writing a much more complicated piece of
assembly code, this can be very useful.&lt;/li&gt;
&lt;li&gt;There's also some support for generating ARM code, though I don't know how
mature it is.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;However, PeachPy is also a fairly new library which means there are still
limitations and rough edges. When developing the JIT I ran into a bug and sent
&lt;a class="reference external" href="https://github.com/Maratyszcza/PeachPy/pull/72"&gt;a PR&lt;/a&gt; - which was promptly
accepted. PeachPy also doesn't do well with a large number of assembly
instructions. It has some recursive analysis logic that &lt;a class="reference external" href="https://github.com/Maratyszcza/PeachPy/issues/74"&gt;blows up the Python
stack when run on large code&lt;/a&gt;. In the BF JIT, I'm setting
the stack to a higher limit artificially; with that, PeachPy doesn't crash but
takes quite a while to assemble large programs like Mandelbrot.&lt;/p&gt;
&lt;p&gt;According to PeachPy's maintainer, this is due to the design of PeachPy being
aimed towards writing assembly code manually rather than generating it from some
other language. Fair enough - but definitely something to keep in mind. All in
all, the maintainer is responsive and the library seems to be improving quickly
- so these limitations may go away in the future.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="python-jit-alternative-llvmlite"&gt;
&lt;h2&gt;Python JIT alternative - llvmlite&lt;/h2&gt;
&lt;p&gt;A somewhat higher-level alternative to JITing from Python is using &lt;tt class="docutils literal"&gt;llvmlite&lt;/tt&gt;,
the new Python binding to LLVM. I wrote &lt;a class="reference external" href="https://eli.thegreenplace.net/2015/building-and-using-llvmlite-a-basic-example/"&gt;about llvmlite before&lt;/a&gt;
and also ported the LLVM official tutorial &lt;a class="reference external" href="https://eli.thegreenplace.net/2015/python-version-of-the-llvm-tutorial/"&gt;to Python using it&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;llvmlite&lt;/tt&gt; would definitely do the job here (and most likely not have the
limitations of PeachPy), but I wanted to go with something different in this
part. After all, a BF JIT with LLVM was already covered &lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-3-llvm/"&gt;in part 3&lt;/a&gt;,
and &lt;tt class="docutils literal"&gt;llvmlite&lt;/tt&gt; is a binding to the same library, just in Python. PeachPy
offers an altenative approach for machine code generation from Python - with
more direct control of the emitted instructions, though none of the optimizations
LLVM provides automatically.&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-1" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;For example &lt;a class="reference external" href="http://numba.pydata.org/"&gt;Numba&lt;/a&gt; - a JIT compiler for
numeric code written in Python; it takes Python code that uses Numpy and
JIT-compiles it to optimized native code.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-2" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-2"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;No magic is involved here - in fact PeachPy uses precisely the same
approach as I've shown to invoke &lt;tt class="docutils literal"&gt;mmap&lt;/tt&gt; from Python via &lt;tt class="docutils literal"&gt;ctypes&lt;/tt&gt;.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-3" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-3"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;As an exercise, modify this code to invoke &lt;tt class="docutils literal"&gt;putchar&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;getchar&lt;/tt&gt;.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</content><category term="misc"></category><category term="Python"></category><category term="Compilation"></category><category term="Code generation"></category></entry><entry><title>Adventures in JIT compilation: Part 3 - LLVM</title><link href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-3-llvm/" rel="alternate"></link><published>2017-05-01T05:51:00-07:00</published><updated>2024-05-04T19:46:23-07:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2017-05-01:/2017/adventures-in-jit-compilation-part-3-llvm/</id><summary type="html">&lt;p&gt;This is part 3 of my &amp;quot;Adventures in JIT compilation&amp;quot; series.
&lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-1-an-interpreter/"&gt;Part 1&lt;/a&gt;
introduced the BF input language and presented a few interpreters in increasing
degree of optimization. In &lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-2-an-x64-jit/"&gt;part 2&lt;/a&gt;
we've seen how to roll a JIT compiler for BF from scratch, by emitting x64
machine code into executable â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is part 3 of my &amp;quot;Adventures in JIT compilation&amp;quot; series.
&lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-1-an-interpreter/"&gt;Part 1&lt;/a&gt;
introduced the BF input language and presented a few interpreters in increasing
degree of optimization. In &lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-2-an-x64-jit/"&gt;part 2&lt;/a&gt;
we've seen how to roll a JIT compiler for BF from scratch, by emitting x64
machine code into executable memory and jumping to it for execution.&lt;/p&gt;
&lt;p&gt;In this part, I'm going to present another JIT compiler for BF. This time,
however, rather than rolling everything from scratch, I'll be using the &lt;a class="reference external" href="http://llvm.org/"&gt;LLVM&lt;/a&gt; framework.&lt;/p&gt;
&lt;div class="section" id="llvm-as-a-programming-language-backend"&gt;
&lt;h2&gt;LLVM as a programming language backend&lt;/h2&gt;
&lt;p&gt;I'll start by saying this post is not meant to be a full tutorial for LLVM. LLVM
has &lt;a class="reference external" href="http://llvm.org/docs/tutorial/"&gt;a pretty good tutorial&lt;/a&gt; already (see also
&lt;a class="reference external" href="https://eli.thegreenplace.net/2015/python-version-of-the-llvm-tutorial/"&gt;my Python port of it&lt;/a&gt;).
I've also written &lt;a class="reference external" href="https://eli.thegreenplace.net/tag/llvm-clang"&gt;more in-depth pieces about LLVM&lt;/a&gt; in the past; see for example
&lt;a class="reference external" href="https://eli.thegreenplace.net/2012/11/24/life-of-an-instruction-in-llvm"&gt;Life of an instruction in LLVM&lt;/a&gt;. That
said, I do hope that seeing how to apply LLVM to develop a complete JIT compiler
for BF can be useful, and the &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/blob/main/2017/bfjit/llvmjit.cpp"&gt;complete code sample&lt;/a&gt;
can serve as a starting point for programming language enthusiasts to develop
their own backends with a fairly modern version of LLVM. If you have a bit more
time, look for exercise and experiment suggestions in the footnotes.&lt;/p&gt;
&lt;p&gt;Speaking of LLVM versions... LLVM's C++ API is notoriously volatile, and code
working today has little chance of working in just a few months without any
changes. However, LLVM &lt;em&gt;does&lt;/em&gt; have &lt;a class="reference external" href="http://releases.llvm.org/"&gt;numbered releases&lt;/a&gt; that can be used to maintain some sort of sanity
since they are extensively tested. The code for this post was developed with the
LLVM 4.0 release. Even if you're reading this in the year 2022, hopefully you
should be able to download LLVM 4.0 and compile &amp;amp; link the sample code.&lt;/p&gt;
&lt;p&gt;As opposed to the use of asmjit in &lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-2-an-x64-jit/"&gt;part 2&lt;/a&gt;,
LLVM offers several distinct advantages:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Since LLVM comes with many state-of-the-art optimizations on the IR level, we
can generate fairly straightforward LLVM IR from our source language, without
worrying too much about its efficiency. I'll demonstrate this shortly.&lt;/li&gt;
&lt;li&gt;LLVM is multi-target. In this post I'm showing a JIT compiler that emits
code for the machine it runs on (x64 in my case), but one can easily reuse
the same code to compile BF to ARM, PowerPC, MIPS or a bunch of other
backends supported by LLVM.&lt;/li&gt;
&lt;li&gt;LLVM comes with a large set of tools useful to visualize and manipulate IR
and other stages of compilation. I mention a couple uses of the &lt;tt class="docutils literal"&gt;opt&lt;/tt&gt; tool
throughout the post, and &lt;a class="reference external" href="http://llvm.org/docs/CommandGuide/"&gt;there are others&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="generating-llvm-ir-from-bf"&gt;
&lt;h2&gt;Generating LLVM IR from BF&lt;/h2&gt;
&lt;p&gt;The core of the code generation code in this sample is fairly short - only ~130
lines of C++ in &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/blob/main/2017/bfjit/llvmjit.cpp"&gt;emit_jit_function&lt;/a&gt;.
I'll walk through it, leaving some details out. Feel free to check the LLVM
documentation or API headers for more information, if needed.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;FunctionType&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;jit_func_type&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;FunctionType&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;void_type&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{},&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;false&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Function&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;jit_func&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Function&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Create&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;jit_func_type&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Function&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;ExternalLinkage&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;JIT_FUNC_NAME&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;module&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;BasicBlock&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;entry_bb&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;BasicBlock&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Create&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;entry&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;jit_func&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;IRBuilder&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entry_bb&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We begin by creating a LLVM function to hold the emitted code. The function is
named &lt;tt class="docutils literal"&gt;__llvmjit&lt;/tt&gt; (which is what the constant &lt;tt class="docutils literal"&gt;JIT_FUNC_NAME&lt;/tt&gt; contains) and
its linkage is external so that we could call it from outside the LLVM module
where it resides. We also create the entry basic block in the function where the
initial code will go, as well as an &lt;em&gt;IR builder&lt;/em&gt; that makes the job of emitting
LLVM IR a bit easier than using raw APIs.&lt;/p&gt;
&lt;p&gt;More setup follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;AllocaInst&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateAlloca&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;int8_type&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getInt32&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MEMORY_SIZE&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;memory&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateMemSet&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getInt8&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;MEMORY_SIZE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;AllocaInst&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dataptr_addr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateAlloca&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;int32_type&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;nullptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;dataptr_addr&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateStore&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getInt32&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dataptr_addr&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this version of the BF JIT, I decided to keep the data memory on the stack of
the JITed function. This makes it easier for LLVM to optimize accesses to the
memory (as we'll see), because the memory is private - it can't be aliased from
outside the function and can't have side effects, which frees the optimizer to
be more aggressive &lt;a class="footnote-reference" href="#footnote-1" id="footnote-reference-1"&gt;[1]&lt;/a&gt;. The data pointer itself is kept on the stack too
(created with an &lt;tt class="docutils literal"&gt;alloca&lt;/tt&gt; instruction) - more on this very shortly. The
data pointer is initialized to 0, per BF semantics &lt;a class="footnote-reference" href="#footnote-2" id="footnote-reference-2"&gt;[2]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Finally, as usual for one-pass code emission from BF, we have to keep a stack of
open brackets (in the &lt;tt class="docutils literal"&gt;asmjit&lt;/tt&gt; version the type was called &lt;tt class="docutils literal"&gt;BracketLabels&lt;/tt&gt;):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;BracketBlocks&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;open_bracket_stack&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now we're ready for the compilation loop that takes the next BF instruction and
emits the LLVM IR for it. First, pointer movement:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;program&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;instructions&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;instruction&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;program&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;instructions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;switch&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;instruction&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;&amp;gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateLoad&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr_addr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;dataptr&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;inc_dataptr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateAdd&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getInt32&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;inc_dataptr&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateStore&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inc_dataptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dataptr_addr&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;&amp;lt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateLoad&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr_addr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;dataptr&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dec_dataptr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateSub&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getInt32&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;dec_dataptr&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateStore&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dec_dataptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dataptr_addr&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To move the data pointer, we load its value from its storage on the stack,
update it (by either incrementing or decrementing) and store it back. If this
seems inefficient, read on! Later on, the post describes why this style of LLVM
IR emission is not only acceptable, but desirable.&lt;/p&gt;
&lt;p&gt;For data memory updates, the code is not much more complicated:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;+&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateLoad&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr_addr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;dataptr&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;element_addr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateInBoundsGEP&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;element_addr&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;element&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateLoad&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;element_addr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;element&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;inc_element&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateAdd&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;element&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getInt8&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;inc_element&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateStore&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inc_element&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;element_addr&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;-&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateLoad&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr_addr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;dataptr&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;element_addr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateInBoundsGEP&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;element_addr&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;element&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateLoad&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;element_addr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;element&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dec_element&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateSub&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;element&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getInt8&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;sub_element&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateStore&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dec_element&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;element_addr&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We similarly load the data pointer, this time using it to compute an offset into
the memory (using LLVM's &lt;tt class="docutils literal"&gt;getelementptr&lt;/tt&gt; instruction). We then load the
element from memory, update it and store it back. Note how we use the
&lt;tt class="docutils literal"&gt;inbounds&lt;/tt&gt; variant of &lt;tt class="docutils literal"&gt;getelementptr&lt;/tt&gt;; BF doesn't define the behavior of
stepping outside the bounds of memory - we leverage this fact to let LLVM
produce more optimized code.&lt;/p&gt;
&lt;p&gt;For I/O, we use a technique similar to the one employed with &lt;tt class="docutils literal"&gt;asmjit&lt;/tt&gt; in part
2: call the &lt;tt class="docutils literal"&gt;getchar/putchar&lt;/tt&gt; functions from the host. If you look at the
signature of &lt;tt class="docutils literal"&gt;emit_jit_function&lt;/tt&gt;, it takes a &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;llvm::Function*&lt;/span&gt;&lt;/tt&gt; for each of
&lt;tt class="docutils literal"&gt;getchar&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;putchar&lt;/tt&gt;; these are declared in the caller by adding their
declaration to the module. Later, in the section dealing with the JIT we'll see
how these get resolved at run-time.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateLoad&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr_addr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;dataptr&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;element_addr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateInBoundsGEP&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;element_addr&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;element&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateLoad&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;element_addr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;element&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;element_i32&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateIntCast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;element&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;int32_type&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;false&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;element_i32_&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateCall&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;putchar_func&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;element_i32&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;user_input&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateCall&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;getchar_func&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{},&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;user_input&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;user_input_i8&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateIntCast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;int8_type&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;false&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;user_input_i8_&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateLoad&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr_addr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;dataptr&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;element_addr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateInBoundsGEP&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;element_addr&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateStore&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_input_i8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;element_addr&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As usual, the trickiest part of generating code for BF is handling the loops,
which could be nested. LLVM makes this fairly easy by having &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Basic_block"&gt;basic blocks&lt;/a&gt; as first-class citizens. Every
loop body gets its basic block, and the original block gets split to two - the
first part jumping into the loop, the last part happening after the loop (since
we can skip directly to it). Here's how the control-flow graph within a function
with just a single loop looks &lt;a class="footnote-reference" href="#footnote-3" id="footnote-reference-3"&gt;[3]&lt;/a&gt;:&lt;/p&gt;
&lt;img alt="CFG for function with one loop" class="align-center" src="https://eli.thegreenplace.net/images/2017/llvmjit-oneloop-cfg.png" /&gt;
&lt;p&gt;Note how the jumps between basic blocks happen on a condition and have &lt;tt class="docutils literal"&gt;T&lt;/tt&gt;
(true) or &lt;tt class="docutils literal"&gt;F&lt;/tt&gt; (false) clauses. These just encode the usual BF semantics:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;For a &lt;tt class="docutils literal"&gt;[&lt;/tt&gt;, we compare the current memory cell with 0; if it's 0, we skip the
loop (the &lt;tt class="docutils literal"&gt;T&lt;/tt&gt; clause); if it's not 0, we enter the loop (the &lt;tt class="docutils literal"&gt;F&lt;/tt&gt; clause).&lt;/li&gt;
&lt;li&gt;For a &lt;tt class="docutils literal"&gt;]&lt;/tt&gt;, we compare the current memory cell with 0; if it's 0, we jump
back to the loop start; otherwise we end the loop.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here's the code generating LLVM IR from &lt;tt class="docutils literal"&gt;[&lt;/tt&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;[&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateLoad&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr_addr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;dataptr&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;element_addr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateInBoundsGEP&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;element_addr&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;element&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateLoad&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;element_addr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;element&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;cmp&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateICmpEQ&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;element&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getInt8&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;compare_zero&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;BasicBlock&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loop_body_block&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;BasicBlock&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Create&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;loop_body&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;jit_func&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;BasicBlock&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;post_loop_block&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;BasicBlock&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Create&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;post_loop&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;jit_func&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateCondBr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cmp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;post_loop_block&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loop_body_block&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;open_bracket_stack&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;push&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BracketBlocks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loop_body_block&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;post_loop_block&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SetInsertPoint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loop_body_block&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;With the overview and control-flow graph above, I hope it's clear. The most
interesting part is using the basic blocks to represent parts of the loop. When
&lt;tt class="docutils literal"&gt;[&lt;/tt&gt; is encountered, we create both the loop and &amp;quot;post loop&amp;quot; blocks, since the
branch instruction has to refer to them. We also save these blocks on the open
bracket stack to refer to them when the matching &lt;tt class="docutils literal"&gt;]&lt;/tt&gt; is encountered. Finally,
we set our IR builder to insert all subsequent instructions into the loop block.&lt;/p&gt;
&lt;p&gt;This is how &lt;tt class="docutils literal"&gt;]&lt;/tt&gt; is handled:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;]&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;open_bracket_stack&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;DIE&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;unmatched closing &amp;#39;]&amp;#39; at pc=&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;BracketBlocks&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;blocks&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;open_bracket_stack&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;top&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;open_bracket_stack&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateLoad&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr_addr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;dataptr&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;element_addr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateInBoundsGEP&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;element_addr&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;element&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateLoad&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;element_addr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;element&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;cmp&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateICmpNE&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;element&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getInt8&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;compare_zero&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreateCondBr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cmp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;blocks&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loop_body_block&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;blocks&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;post_loop_block&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SetInsertPoint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;blocks&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;post_loop_block&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Pretty much as we'd expect: the relevant blocks are popped from the stack and
used as targets for another conditional branch &lt;a class="footnote-reference" href="#footnote-4" id="footnote-reference-4"&gt;[4]&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="ir-sample-for-a-simple-bf-program"&gt;
&lt;h2&gt;IR sample for a simple BF program&lt;/h2&gt;
&lt;p&gt;Let's see what LLVM IR our code emits for the simple &lt;tt class="docutils literal"&gt;count1to5.bf&lt;/tt&gt; program:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;++++++++ ++++++++ ++++++++ ++++++++ ++++++++ ++++++++

&amp;gt;+++++
[&amp;lt;+.&amp;gt;-]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The full LLVM-based JIT is available in &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/blob/main/2017/bfjit/llvmjit.cpp"&gt;llvmjit.cpp&lt;/a&gt;.
When invoked in verbose mode, it will dump LLVM IR for the translated program
before and after LLVM optimization. Let's start by looking at the
pre-optimization IR. I've added comments on lines starting with &lt;tt class="docutils literal"&gt;###&lt;/tt&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;define void @__llvmjit() {
entry:

  ### The entry BB starts by declaring the memory and data pointer, and
  ### initializing the data pointer to 0.

  %memory = alloca i8, i32 30000
  call void @llvm.memset.p0i8.i64(i8* %memory, i8 0, i64 30000, i32 1, i1 false)
  %dataptr_addr = alloca i32
  store i32 0, i32* %dataptr_addr

  ### The following 5 instructions increment memory[dataptr] (with dataptr
  ### remaining at 0, as initialized), and they are repeated 48 times...

  %dataptr = load i32, i32* %dataptr_addr
  %element_addr = getelementptr inbounds i8, i8* %memory, i32 %dataptr
  %element = load i8, i8* %element_addr
  %inc_element = add i8 %element, 1
  store i8 %inc_element, i8* %element_addr

  ### ... 47 more times skipped ...

  store i8 %inc_element184, i8* %element_addr182
  %dataptr185 = load i32, i32* %dataptr_addr
  %element_addr186 = getelementptr inbounds i8, i8* %memory, i32 %dataptr185
  %element187 = load i8, i8* %element_addr186
  %inc_element188 = add i8 %element187, 1
  store i8 %inc_element188, i8* %element_addr186

  ### Now incrementing dataptr and 5 more data increments.

  %dataptr189 = load i32, i32* %dataptr_addr
  %inc_dataptr = add i32 %dataptr189, 1
  store i32 %inc_dataptr, i32* %dataptr_addr

  %dataptr190 = load i32, i32* %dataptr_addr
  %element_addr191 = getelementptr inbounds i8, i8* %memory, i32 %dataptr190
  %element192 = load i8, i8* %element_addr191
  %inc_element193 = add i8 %element192, 1
  store i8 %inc_element193, i8* %element_addr191

  ### ... 4 more increments skipped

  ### Load memory[dataptr] and compare it to 0; on true, jump to %post_loop;
  ### on false jump to %loop_body.

  %dataptr210 = load i32, i32* %dataptr_addr
  %element_addr211 = getelementptr inbounds i8, i8* %memory, i32 %dataptr210
  %element212 = load i8, i8* %element_addr211
  %compare_zero = icmp eq i8 %element212, 0
  br i1 %compare_zero, label %post_loop, label %loop_body

loop_body:

  ### Decrement dataptr

  %dataptr213 = load i32, i32* %dataptr_addr
  %dec_dataptr = sub i32 %dataptr213, 1
  store i32 %dec_dataptr, i32* %dataptr_addr

  ### Increment memory[dataptr]

  %dataptr214 = load i32, i32* %dataptr_addr
  %element_addr215 = getelementptr inbounds i8, i8* %memory, i32 %dataptr214
  %element216 = load i8, i8* %element_addr215
  %inc_element217 = add i8 %element216, 1
  store i8 %inc_element217, i8* %element_addr215

  ### Invoke putchar on memory[dataptr]

  %dataptr218 = load i32, i32* %dataptr_addr
  %element_addr219 = getelementptr inbounds i8, i8* %memory, i32 %dataptr218
  %element220 = load i8, i8* %element_addr219
  %element_i32_ = zext i8 %element220 to i32
  %0 = call i32 @putchar(i32 %element_i32_)

  ### Increment dataptr

  %dataptr221 = load i32, i32* %dataptr_addr
  %inc_dataptr222 = add i32 %dataptr221, 1
  store i32 %inc_dataptr222, i32* %dataptr_addr

  ### Decrement memory[dataptr]

  %dataptr223 = load i32, i32* %dataptr_addr
  %element_addr224 = getelementptr inbounds i8, i8* %memory, i32 %dataptr223
  %element225 = load i8, i8* %element_addr224
  %sub_element = sub i8 %element225, 1
  store i8 %sub_element, i8* %element_addr224

  ### Load memory[dataptr] and compare it to 0; on true, jump back to
  ### %loop_body; on false jump to %post_loop.

  %dataptr226 = load i32, i32* %dataptr_addr
  %element_addr227 = getelementptr inbounds i8, i8* %memory, i32 %dataptr226
  %element228 = load i8, i8* %element_addr227
  %compare_zero229 = icmp ne i8 %element228, 0
  br i1 %compare_zero229, label %loop_body, label %post_loop

post_loop
  call void @dump_memory(i8* %memory)
  ret void
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As discussed before, this code is doing a huge amount of repetetive and mostly
unnecessary work. It keeps storing and reloading values it should already have.
But this is precisely what the LLVM optimizer is designed to fix. Let's see the
post-optimization code LLVM produces:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;define void @__llvmjit() local_unnamed_addr {
loop_body.preheader:
  %memory290 = alloca [30000 x i8], align 1
  %memory290.sub = getelementptr inbounds [30000 x i8], [30000 x i8]* %memory290, i64 0, i64 0
  %0 = getelementptr inbounds [30000 x i8], [30000 x i8]* %memory290, i64 0, i64 2
  call void @llvm.memset.p0i8.i64(i8* nonnull %0, i8 0, i64 29998, i32 1, i1 false)
  store i8 48, i8* %memory290.sub, align 1
  %element_addr191 = getelementptr inbounds [30000 x i8], [30000 x i8]* %memory290, i64 0, i64 1
  store i8 5, i8* %element_addr191, align 1
  br label %loop_body

loop_body:
  %1 = tail call i32 @putchar(i32 49)
  %2 = tail call i32 @putchar(i32 50)
  %3 = tail call i32 @putchar(i32 51)
  %4 = tail call i32 @putchar(i32 52)
  %5 = tail call i32 @putchar(i32 53)
  store i8 53, i8* %memory290.sub, align 1
  store i8 0, i8* %element_addr191, align 1
  call void @dump_memory(i8* nonnull %memory290.sub)
  ret void
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The LLVM optimizer is extremely aggressive! Not only all the repetition is gone,
but there isn't even a loop any more because LLVM statically computed it will
just run 5 times and unrolled it completely. &lt;tt class="docutils literal"&gt;putchar&lt;/tt&gt; is invoked 5 times
with the values the loop would have produced, and that's all. The reason LLVM
kept &lt;tt class="docutils literal"&gt;memory&lt;/tt&gt; around was only so the call to &lt;tt class="docutils literal"&gt;dump_memory&lt;/tt&gt; would have data.
If we remove this debugging call, the function turns into:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;define void @__llvmjit() local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @putchar(i32 49)
  %1 = tail call i32 @putchar(i32 50)
  %2 = tail call i32 @putchar(i32 51)
  %3 = tail call i32 @putchar(i32 52)
  %4 = tail call i32 @putchar(i32 53)
  ret void
}
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="observing-how-llvm-handles-our-loops"&gt;
&lt;h2&gt;Observing how LLVM handles our loops&lt;/h2&gt;
&lt;p&gt;So the &lt;tt class="docutils literal"&gt;count1to5&lt;/tt&gt; sample was a bit too simple for the LLVM optimizer. To see
our loops actually being emitted, we'll have to resort to more tricks - by
placing &amp;quot;input&amp;quot; instructions (&lt;tt class="docutils literal"&gt;,&lt;/tt&gt; in BF) in stratetic locations so that LLVM
can't just infer their value statically. Take for example the
(slightly-nonsensical) BF program:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;gt;,

[&amp;lt;+.&amp;gt;,]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It places user input into cell 1, and then repeatedly:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Increments cell 0, printing its value out&lt;/li&gt;
&lt;li&gt;Places new user input in cell 1&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It will terminate when the user input is 0. Not very useful, but it does the
job. Here's the &lt;em&gt;optimized&lt;/em&gt; IR LLVM emits for it:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;define void @__llvmjit() local_unnamed_addr {
entry:
  %memory29 = alloca [30000 x i8], align 1
  %memory29.sub = getelementptr inbounds [30000 x i8], [30000 x i8]* %memory29, i64 0, i64 0
  call void @llvm.memset.p0i8.i64(i8* nonnull %memory29.sub, i8 0, i64 30000, i32 1, i1 false)
  %user_input = tail call i32 @getchar()
  %user_input_i8_ = trunc i32 %user_input to i8
  %element_addr = getelementptr inbounds [30000 x i8], [30000 x i8]* %memory29, i64 0, i64 1
  store i8 %user_input_i8_, i8* %element_addr, align 1
  %compare_zero = icmp eq i8 %user_input_i8_, 0
  br i1 %compare_zero, label %post_loop, label %loop_body.preheader

loop_body.preheader:
  br label %loop_body

loop_body:
  %element730 = phi i8 [ %inc_element, %loop_body ], [ 0, %loop_body.preheader ]
  %inc_element = add i8 %element730, 1
  %element_i32_ = zext i8 %inc_element to i32
  %0 = tail call i32 @putchar(i32 %element_i32_)
  %user_input13 = tail call i32 @getchar()
  %user_input_i8_14 = trunc i32 %user_input13 to i8
  %compare_zero20 = icmp eq i8 %user_input_i8_14, 0
  br i1 %compare_zero20, label %post_loop.loopexit, label %loop_body

post_loop.loopexit:
  store i8 %inc_element, i8* %memory29.sub, align 1
  store i8 0, i8* %element_addr, align 1
  br label %post_loop

post_loop:
  call void @dump_memory(i8* nonnull %memory29.sub)
  ret void
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The two most important points to note are:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;There's no extra stack movement; like, &lt;em&gt;at all&lt;/em&gt;. LLVM statically computed what
happens at address 0 and address 1 and just juggles virtual registers with
these values, &lt;em&gt;actually storing to memory only outside the loop&lt;/em&gt;!&lt;/li&gt;
&lt;li&gt;To be able to do that, it generated a &lt;tt class="docutils literal"&gt;phi&lt;/tt&gt; instruction at the loop body
start.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The latter is especially important: this is LLVM converting the IR to &lt;em&gt;SSA
form&lt;/em&gt;, where every value is assigned only once and special &lt;tt class="docutils literal"&gt;phi&lt;/tt&gt; nodes are
required to merge multiple possible values. SSA is well outside the scope of
this humble post, but I suggest reading about it. LLVM's &lt;tt class="docutils literal"&gt;mem2reg&lt;/tt&gt; pass
converts our naive stack-using code to SSA with virtual registers, and SSA form
makes it much easier for the compiler to analyze the IR and optimize it
aggressively.&lt;/p&gt;
&lt;p&gt;On the other hand, &lt;em&gt;emitters&lt;/em&gt; of LLVM IR don't have to worry about efficient
usage of virtual registers and can just assign stack slots for all &amp;quot;variables&amp;quot;,
leaving the optimization to LLVM. For our simple use case of BF this may not
matter too much, but think about a classical programming language where a
function may have dozens of variables to track &lt;a class="footnote-reference" href="#footnote-5" id="footnote-reference-5"&gt;[5]&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="jiting-llvm-ir-to-executable-machine-code"&gt;
&lt;h2&gt;JITing LLVM IR to executable machine code&lt;/h2&gt;
&lt;p&gt;Being able to optimize LLVM IR is just one of the strengths of LLVM &lt;tt class="docutils literal"&gt;llvmjit&lt;/tt&gt;
is using. The other is the ability to efficiently execute this IR at run-time
by JITing it into an excutable in-memory chunk of machine code.&lt;/p&gt;
&lt;p&gt;In &lt;tt class="docutils literal"&gt;llvmjit&lt;/tt&gt;, the part doing this is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;SimpleOrcJIT&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;jit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="cm"&gt;/*verbose=*/&lt;/span&gt;&lt;span class="n"&gt;verbose&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;module&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;setDataLayout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;jit&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_target_machine&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;createDataLayout&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;jit&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_module&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;move&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;module&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;JITSymbol&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;jit_func_sym&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;jit&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find_symbol&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;JIT_FUNC_NAME&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="n"&gt;jit_func_sym&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;DIE&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Unable to find symbol &amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;JIT_FUNC_NAME&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot; in module&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="k"&gt;using&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;JitFuncType&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)(&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;JitFuncType&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;jit_func_ptr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;reinterpret_cast&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;JitFuncType&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;jit_func_sym&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getAddress&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;jit_func_ptr&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Which, of course, leaves the question - what is &lt;tt class="docutils literal"&gt;SimpleOrcJit&lt;/tt&gt;? It's a
simplified instantiation of LLVM's &lt;a class="reference external" href="http://llvm.org/docs/tutorial/BuildingAJIT2.html"&gt;newest JIT engine - ORC&lt;/a&gt;. For the full code see
&lt;a class="reference external" href="https://github.com/eliben/code-for-blog/blob/main/2017/bfjit/llvm_jit_utils.h"&gt;this header&lt;/a&gt;
and its accompanying source file. My implementation of the JIT is very similar
to the one in the LLVM tutorial, with the addition of dumping the JITed machine
code to a binary file prior to returning an executable pointer to it.&lt;/p&gt;
&lt;p&gt;LLVM's ORC JIT looks formidable, but there's no magic to it. In its essence,
it's just doing the thing &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/11/05/how-to-jit-an-introduction"&gt;my introduction to JITing&lt;/a&gt;
describes, with with many (many!) more layers on top. One interesting thing I
&lt;em&gt;would&lt;/em&gt; like to mention, though, is how the JIT finds host functions to call,
since it's designed differently from the previous JITs I showed.&lt;/p&gt;
&lt;p&gt;For &lt;tt class="docutils literal"&gt;llvmjit&lt;/tt&gt;, all we do is &lt;em&gt;declare&lt;/em&gt; (without defining) the host functions in
the module, so that we can insert a &lt;tt class="docutils literal"&gt;call&lt;/tt&gt; instruction to these functions. For
example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;declare i32 @putchar(i32) local_unnamed_addr #0
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Unlike the approach with &lt;tt class="docutils literal"&gt;asmjit&lt;/tt&gt;-based JITs, we don't encode the address of
the host function in the JITed code. Rather we let the JIT resolve it
automatically. This is done by adding the following &lt;em&gt;resolver&lt;/em&gt; to the JIT:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;auto&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;resolver&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;orc&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;createLambdaResolver&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="p"&gt;](&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;auto&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sym&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;find_mangled_symbol&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sym&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;JITSymbol&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;nullptr&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;[](&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;auto&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sym_addr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;              &lt;/span&gt;&lt;span class="n"&gt;RTDyldMemoryManager&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;getSymbolAddressInProcess&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;JITSymbol&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sym_addr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;JITSymbolFlags&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Exported&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;JITSymbol&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;nullptr&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The second lambda function passed to the resolver is invoked when the LLVM IR
being compiled contains a &lt;tt class="docutils literal"&gt;call&lt;/tt&gt; to a symbol that wasn't defined in the
module. In this case, what we do amounts to a call to &lt;tt class="docutils literal"&gt;dlsym&lt;/tt&gt; with the symbol
name. The constructor of &lt;tt class="docutils literal"&gt;SimpleOrcJIT&lt;/tt&gt; calls
&lt;tt class="docutils literal"&gt;LoadLibraryPermanently(nullptr)&lt;/tt&gt; which translates to &lt;tt class="docutils literal"&gt;dlopen(nullptr,
&lt;span class="pre"&gt;...)&lt;/span&gt;&lt;/tt&gt;, meaning that all symbols contained in the host executable are
visible to the JIT. To accomplish this, &lt;tt class="docutils literal"&gt;llvmjit&lt;/tt&gt; is compiled with the
&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-rdynamic&lt;/span&gt;&lt;/tt&gt; linker flag. This way the JITed code can call any function found
in the host code, including standard C library functions like &lt;tt class="docutils literal"&gt;putchar&lt;/tt&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="how-fast-does-it-run"&gt;
&lt;h2&gt;How fast does it run?&lt;/h2&gt;
&lt;p&gt;Let's see how &lt;tt class="docutils literal"&gt;llvmjit&lt;/tt&gt; compares to the JITs developed in &lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-2-an-x64-jit/"&gt;part 2&lt;/a&gt;.
To make this measurement fair, I'm instrumenting the program to report &lt;em&gt;execution&lt;/em&gt;
time separately from &lt;em&gt;compilation&lt;/em&gt; time, since LLVM may take a while optimizing
a large IR program.&lt;/p&gt;
&lt;p&gt;With this instrumentation, &lt;tt class="docutils literal"&gt;llvmjit&lt;/tt&gt; takes 0.92 seconds to run &lt;tt class="docutils literal"&gt;mandelbrot&lt;/tt&gt;,
which is virtually the same time &lt;tt class="docutils literal"&gt;optasmjit&lt;/tt&gt; took; it takes 0.14 seconds to
run &lt;tt class="docutils literal"&gt;factor&lt;/tt&gt;, half of the time of &lt;tt class="docutils literal"&gt;optasmjit&lt;/tt&gt;. That said, for these programs
LLVM optimizations took roughly the same amount of time as execution, so if you
include everything in - &lt;tt class="docutils literal"&gt;llvmjit&lt;/tt&gt; is equal on &lt;tt class="docutils literal"&gt;factor&lt;/tt&gt; and loses by ~2x on
&lt;tt class="docutils literal"&gt;mandelbrot&lt;/tt&gt; &lt;a class="footnote-reference" href="#footnote-6" id="footnote-reference-6"&gt;[6]&lt;/a&gt;. So, as often is the case with JITs, it all depends on the
use case - if we care about run-time of long programs, it makes sense to spend
more time optimizing; it we mostly care about short programs, it doesn't. This
is why many modern JITs (think JavaScript) are multi-stage - starting with a
fast interpreter or &lt;em&gt;baseline&lt;/em&gt; (very light on optimization) JIT, and switching
to a more optimizing JIT if the program turns out to be longer-running than
initially expected.&lt;/p&gt;
&lt;img alt="BF opt3 vs. part 2 jits vs. llvmjit" class="align-center" src="https://eli.thegreenplace.net/images/2017/bf-runtime-vs-llvmjit.png" /&gt;
&lt;p&gt;Optimization-time aside, it's quite amazing that LLVM is managing to reach the
speed of &lt;tt class="docutils literal"&gt;optasmjit&lt;/tt&gt;, which emits tight machine code and uses domain-specific
optimizations to convert whole loops from the BF code to simple O(1) sequences.
This is due to the power of LLVM's optimizer; it is able, on its own, to infer
that some of these loops are really accomplishing trivial computations. I
suggest taking this as an exercise: write simple BF programs and run them
through &lt;tt class="docutils literal"&gt;llvmjit &lt;span class="pre"&gt;--verbose&lt;/span&gt;&lt;/tt&gt; to observe the post-optimization IR. You'll see
that LLVM is able to remove loops like &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;[-]&lt;/span&gt;&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;[&amp;lt;-&amp;gt;+]&lt;/span&gt;&lt;/tt&gt;, replacing them by
simple data initialization &amp;amp; movement. Bonus points for uncovering other
optimizations that LLVM did but our &lt;tt class="docutils literal"&gt;optasmjit&lt;/tt&gt; didn't - after all, LLVM does
run the &lt;tt class="docutils literal"&gt;factor&lt;/tt&gt; benchmark much faster, so there must be something interesting
there.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;After playing with manual code-generation in part 2, this post demonstrates
using an industrial-strength compiler backend to create a JIT for BF. LLVM is a
large and complex library with a steep learning curve, but once you're past
the initial ramp-up stage it's an extremely powerful tool. LLVM lets you emit
very straightforward code without worrying about things like registers and
recomputing the same values over and over again. Its state-of-the art optimizer
removes all these inefficiencies, producing extremely tight IR. Moreover, LLVM
lets us target multiple architectures very easily from the same code - just
choose which targets you want when configuring &amp;amp; compiling LLVM itself, and you
have a multi-target compiler.&lt;/p&gt;
&lt;p&gt;However, LLVM has downsides as well - it's large, and its compile time is
considerable. This sometimes makes it less desirable in situations where a small
footprint and fast compilation are required. For an interesting account of how
the WebKit developers replaced LLVM with a custom backend for their &amp;quot;last-tier&amp;quot;
optimized JIT, read &lt;a class="reference external" href="https://webkit.org/blog/5852/introducing-the-b3-jit-compiler/"&gt;Introducing the B3 JIT compiler&lt;/a&gt;.&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;Links to all posts in this series:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-1-an-interpreter/"&gt;Part 1 - an interpreter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-2-an-x64-jit/"&gt;Part 2 - an x64 JIT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-3-llvm/"&gt;Part 3 - LLVM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-4-in-python/"&gt;Part 4 - Python&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr class="docutils" /&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-1" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;As an exercise, move this memory outside the function - by allocating it
on the host and passing a pointer to the JITed code, similarly to how it
was done in &lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-2-an-x64-jit/"&gt;part 2&lt;/a&gt;.
Observe how this affects LLVM's optimization, if at all. Read on LLVM's
concepts of &lt;em&gt;volatile&lt;/em&gt; and &lt;em&gt;aliasing&lt;/em&gt; and think about how they may affect
optimizations.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-2" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-2"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;A fun experiment is to remove this initialization and observe what LLVM
does with the code. I had this bug initially, and it's a brilliant
demonstration of LLVM's capability of optimizing code that has undefined
behavior (in this case using uninitialized values).&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-3" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-3"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;This CFG is produced automatically by LLVM and is a good example of the
tools provided by default with this framework. To generate it, I took
the LLVM IR file dumped by &lt;tt class="docutils literal"&gt;llvmjit&lt;/tt&gt; in verbose mode, and ran LLVM's
&lt;tt class="docutils literal"&gt;opt&lt;/tt&gt; tool on it with the &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-view-cfg-only&lt;/span&gt;&lt;/tt&gt; flag. This makes &lt;tt class="docutils literal"&gt;opt&lt;/tt&gt;
dump a Graphviz &lt;tt class="docutils literal"&gt;.dot&lt;/tt&gt; file which can then be converted to an image.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-4" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-4"&gt;[4]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Exercise: why do we need to save &lt;tt class="docutils literal"&gt;loop_body_block&lt;/tt&gt; at all? When a &lt;tt class="docutils literal"&gt;]&lt;/tt&gt;
is encountered, shouldn't the matching &lt;tt class="docutils literal"&gt;loop_body_block&lt;/tt&gt; be the same
one as the currently populated block?&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-5" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-5"&gt;[5]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;A cool experiment to try is compile some C function to LLVM IR with
the Clang front-end and observe stack usage in unoptimized code, followed
by running &lt;tt class="docutils literal"&gt;opt &lt;span class="pre"&gt;-O3&lt;/span&gt;&lt;/tt&gt; to see what the optimizer turned it into.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-6" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-6"&gt;[6]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;For &lt;tt class="docutils literal"&gt;mandelbrot&lt;/tt&gt;, the textual representation of LLVM IR generated for
the BF program runs to ~42,000 lines, which takes LLVM 0.8 seconds to
fully optimize.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</content><category term="misc"></category><category term="LLVM &amp; Clang"></category><category term="Compilation"></category><category term="Code generation"></category></entry><entry><title>Adventures in JIT compilation: Part 2 - an x64 JIT</title><link href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-2-an-x64-jit/" rel="alternate"></link><published>2017-03-22T06:32:00-07:00</published><updated>2024-05-04T19:46:23-07:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2017-03-22:/2017/adventures-in-jit-compilation-part-2-an-x64-jit/</id><summary type="html">&lt;p&gt;In the &lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-1-an-interpreter/"&gt;first part of the series&lt;/a&gt;
I've briefly introduced the BF source language and went on to present four
interpreters with increasing degree of optimization. That post should serve as a
good backgroud before diving into actual JIT-ing.&lt;/p&gt;
&lt;p&gt;Another important part of the background puzzle is my &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/11/05/how-to-jit-an-introduction"&gt;How to â€¦&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;In the &lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-1-an-interpreter/"&gt;first part of the series&lt;/a&gt;
I've briefly introduced the BF source language and went on to present four
interpreters with increasing degree of optimization. That post should serve as a
good backgroud before diving into actual JIT-ing.&lt;/p&gt;
&lt;p&gt;Another important part of the background puzzle is my &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/11/05/how-to-jit-an-introduction"&gt;How to JIT - an
introduction&lt;/a&gt; post from
2013; there, I discuss some of the basic tools needed to emit executable x64
machine code at run-time and actually run it on Linux. Please go through it
quickly if these things are new to you.&lt;/p&gt;
&lt;div class="section" id="the-two-phases-of-jit"&gt;
&lt;h2&gt;The two phases of JIT&lt;/h2&gt;
&lt;p&gt;As I wrote &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/11/05/how-to-jit-an-introduction"&gt;previously&lt;/a&gt;, the JIT
technique is easier to understand when divided into two distinct phases:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Create machine code at program run-time.&lt;/li&gt;
&lt;li&gt;Execute that machine code, also at program run-time.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Phase 2 for our BF JIT is exactly identical to the method described in that
introductory post. Take a look at the &lt;tt class="docutils literal"&gt;JitProgram&lt;/tt&gt; class in
&lt;a class="reference external" href="https://github.com/eliben/code-for-blog/blob/main/2017/bfjit/jit_utils.h"&gt;jit_utils&lt;/a&gt;
for details. We'll be more focused on phase 1, which will be translating
BF to x64 machine code; per the definition quoted in part 1 of the
series, we're going to develop an actual BF compiler (compiling from BF source
to x64 machine code).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="compilers-assemblers-and-instruction-encoding"&gt;
&lt;h2&gt;Compilers, assemblers and instruction encoding&lt;/h2&gt;
&lt;p&gt;Traditionally, compilation was divided into several stages. The actual source
language compiler would translate some higher-level language to target-specific
assembly; then, an assembler would translate assembly to actual machine code
&lt;a class="footnote-reference" href="#footnote-1" id="footnote-reference-1"&gt;[1]&lt;/a&gt;. There's a number of important benefits assembly language provides over raw
machine code. Salient examples include:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Instruction encoding: it's certainly nicer to write &lt;tt class="docutils literal"&gt;inc %r13&lt;/tt&gt; to increment
the contents of register &lt;tt class="docutils literal"&gt;r13&lt;/tt&gt; than to write &lt;tt class="docutils literal"&gt;0x49, 0xFF, 0xC5&lt;/tt&gt;.
Instruction encoding for the popular architectures is &lt;a class="reference external" href="http://ref.x86asm.net/"&gt;notoriously complicated&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Naming labels and procedures for jumps/calls: it's easier to write &lt;tt class="docutils literal"&gt;jl loop&lt;/tt&gt;
than to figure out the encoding for the instruction, along with the relative
position of the &lt;tt class="docutils literal"&gt;loop&lt;/tt&gt; label and encoding the delta to it (not to mention
this delta changes every time we add instructions in between and needs to be
recomputed). Similarly for functions, &lt;tt class="docutils literal"&gt;call foo&lt;/tt&gt; instead of doing it by
address.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;One of my guiding principles through the field of programming is that before
diving into the possible solutions for a problem (for example, some library for
doing X) it's worth working through the problem manually first (doing X by hand,
without libraries). Grinding your teeth over issues for a while is the best way
to appreciate what the shrinkwrapped solution/library does for you.&lt;/p&gt;
&lt;p&gt;In this spirit, our first JIT is going to be completely hand-written.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="simple-jit-hand-rolling-x64-instruction-encoding"&gt;
&lt;h2&gt;Simple JIT - hand-rolling x64 instruction encoding&lt;/h2&gt;
&lt;p&gt;Out first JIT for this post is &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/blob/main/2017/bfjit/simplejit.cpp"&gt;simplejit.cpp&lt;/a&gt;. Similarly to the
interpreters of part 1, all the action happens in a single function (here called
&lt;tt class="docutils literal"&gt;simplejit&lt;/tt&gt;) invoked from &lt;tt class="docutils literal"&gt;main&lt;/tt&gt;. &lt;tt class="docutils literal"&gt;simplejit&lt;/tt&gt; goes through the BF source
and emits x64 machine code into a memory buffer; in the end, it jumps to this
machine code to run the BF program.&lt;/p&gt;
&lt;p&gt;Here's its beginning:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;vector&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;uint8_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MEMORY_SIZE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="c1"&gt;// Registers used in the program:&lt;/span&gt;
&lt;span class="c1"&gt;//&lt;/span&gt;
&lt;span class="c1"&gt;// r13: the data pointer -- contains the address of memory.data()&lt;/span&gt;
&lt;span class="c1"&gt;//&lt;/span&gt;
&lt;span class="c1"&gt;// rax, rdi, rsi, rdx: used for making system calls, per the ABI.&lt;/span&gt;

&lt;span class="n"&gt;CodeEmitter&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="c1"&gt;// Throughout the translation loop, this stack contains offsets (in the&lt;/span&gt;
&lt;span class="c1"&gt;// emitter code vector) of locations for fixup.&lt;/span&gt;
&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;open_bracket_stack&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="c1"&gt;// movabs &amp;lt;address of memory.data&amp;gt;, %r13&lt;/span&gt;
&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmitBytes&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="mh"&gt;0x49&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0xBD&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmitUint64&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="kt"&gt;uint64_t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As usual, we have our BF memory buffer in a &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;std::vector&lt;/span&gt;&lt;/tt&gt;. The comments reveal
some of the conventions used througout the emitted program: our &amp;quot;data pointer&amp;quot;
will be in &lt;tt class="docutils literal"&gt;r13&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;CodeEmitter&lt;/tt&gt; is a very simple utility to append bytes and words to a vector
of bytes. Its full code &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/blob/main/2017/bfjit/jit_utils.cpp"&gt;is here&lt;/a&gt;.
It's platform independent except the assumption of little-endian (for
&lt;tt class="docutils literal"&gt;EmitUint64&lt;/tt&gt; it will write the lowest byte of the 64-bit word first, then the
second lowest byte, etc.)&lt;/p&gt;
&lt;p&gt;Our first bit of actual machine code emission follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;// movabs &amp;lt;address of memory.data&amp;gt;, %r13&lt;/span&gt;
&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmitBytes&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="mh"&gt;0x49&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0xBD&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmitUint64&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="kt"&gt;uint64_t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And it's a cool one, mixing elements from the host (the C++ program doing the
emission) and the JITed code. First note the usage of &lt;tt class="docutils literal"&gt;movabs&lt;/tt&gt;, a x64
instruction useful for placing 64-bit immediates in a register. This is exactly
what we're doing here - placing the address of the data buffer of &lt;tt class="docutils literal"&gt;memory&lt;/tt&gt;
in &lt;tt class="docutils literal"&gt;r13&lt;/tt&gt;. The call to &lt;tt class="docutils literal"&gt;EmitBytes&lt;/tt&gt; with a cryptic sequence of hex values is
preceded by a snippet of assembly in a comment - the assembly conveys the
meaning for human readers, the hex values are the actual encoding the machine
will understand.&lt;/p&gt;
&lt;p&gt;Then comes the BF compilation loop, which looks at the next BF instruction and
emits the appropriate machine code for it. Our compiler works in a single pass;
this means that there's a bit of trickiness in handling the jumps, as we will
soon see.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;instructions&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;instruction&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;instructions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;switch&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;instruction&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;&amp;gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;// inc %r13&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmitBytes&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="mh"&gt;0x49&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0xFF&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0xC5&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;&amp;lt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;// dec %r13&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmitBytes&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="mh"&gt;0x49&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0xFF&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0xCD&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;+&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;// Our memory is byte-addressable, so using addb/subb for modifying it.&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;// addb $1, 0(%r13)&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmitBytes&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="mh"&gt;0x41&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x45&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x01&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;-&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;// subb $1, 0(%r13)&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmitBytes&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="mh"&gt;0x41&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x6D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x01&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;These are pretty straightforward; since &lt;tt class="docutils literal"&gt;r13&lt;/tt&gt; is the data pointer, &lt;tt class="docutils literal"&gt;&amp;gt;&lt;/tt&gt; and
&lt;tt class="docutils literal"&gt;&amp;lt;&lt;/tt&gt; increment and decrement it, while &lt;tt class="docutils literal"&gt;+&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;-&lt;/tt&gt; increment and decrement
what it's pointing to. One slightly subtle aspect is that I chose a byte-value
memory for our BF implementations; this means we have to be careful when reading
or writing to memory and do byte-addressing (the &lt;tt class="docutils literal"&gt;b&lt;/tt&gt; suffixes on &lt;tt class="docutils literal"&gt;add&lt;/tt&gt; and
&lt;tt class="docutils literal"&gt;sub&lt;/tt&gt; above) rather than the default 64-bit-addressing.&lt;/p&gt;
&lt;p&gt;The code emitted for &lt;tt class="docutils literal"&gt;.&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;,&lt;/tt&gt; is a bit more exciting; in the effort of
avoiding any external dependencies, we're going to invoke
&lt;a class="reference external" href="http://man7.org/linux/man-pages/man2/syscalls.2.html"&gt;Linux system calls&lt;/a&gt;
directly. &lt;tt class="docutils literal"&gt;WRITE&lt;/tt&gt; for &lt;tt class="docutils literal"&gt;.&lt;/tt&gt;; &lt;tt class="docutils literal"&gt;READ&lt;/tt&gt; for &lt;tt class="docutils literal"&gt;,&lt;/tt&gt;. We're using the x64 ABI
here with the syscall identifier in &lt;tt class="docutils literal"&gt;rax&lt;/tt&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// To emit one byte to stdout, call the write syscall with fd=1 (for&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// stdout), buf=address of byte, count=1.&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;//&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// mov $1, %rax&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// mov $1, %rdi&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// mov %r13, %rsi&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// mov $1, %rdx&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// syscall&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmitBytes&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="mh"&gt;0x48&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0xC7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0xC0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x01&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmitBytes&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="mh"&gt;0x48&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0xC7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0xC7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x01&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmitBytes&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="mh"&gt;0x4C&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x89&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0xEE&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmitBytes&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="mh"&gt;0x48&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0xC7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0xC2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x01&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmitBytes&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="mh"&gt;0x0F&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x05&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// To read one byte from stdin, call the read syscall with fd=0 (for&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// stdin),&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// buf=address of byte, count=1.&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmitBytes&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="mh"&gt;0x48&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0xC7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0xC0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmitBytes&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="mh"&gt;0x48&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0xC7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0xC7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmitBytes&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="mh"&gt;0x4C&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x89&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0xEE&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmitBytes&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="mh"&gt;0x48&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0xC7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0xC2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x01&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmitBytes&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="mh"&gt;0x0F&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x05&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The comments certainly help, don't they? I hope these snippets are a great
motivation for using assembly language rather than encoding instructions
manually :-)&lt;/p&gt;
&lt;p&gt;The jump instructions are always the most interesting in BF. For &lt;tt class="docutils literal"&gt;[&lt;/tt&gt; we do:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;[&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// For the jumps we always emit the instruciton for 32-bit pc-relative&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// jump, without worrying about potentially short jumps and relaxation.&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// cmpb $0, 0(%r13)&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmitBytes&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="mh"&gt;0x41&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x7d&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// Save the location in the stack, and emit JZ (with 32-bit relative&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// offset) with 4 placeholder zeroes that will be fixed up later.&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;open_bracket_stack&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;push&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmitBytes&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="mh"&gt;0x0F&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x84&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmitUint32&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that we don't know where this jump leads at this point - it will go to the
matching &lt;tt class="docutils literal"&gt;]&lt;/tt&gt;, which we haven't encountered yet! Therefore, to keep our
compilation in a single pass &lt;a class="footnote-reference" href="#footnote-2" id="footnote-reference-2"&gt;[2]&lt;/a&gt; we use the time-honored technique of
&lt;em&gt;backpatching&lt;/em&gt; by emitting a placeholder value for the jump and fixing it up
once we encounter the matching label. Another thing to note is always using a
32-bit pc-relative jump, for simplicity; we could save a couple of bytes with a
short jump in most cases (see &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/01/03/assembler-relaxation"&gt;my article on assembler relaxation&lt;/a&gt; for the full
scoop), but I don't think it's worth the effort here.&lt;/p&gt;
&lt;p&gt;Compiling the matching &lt;tt class="docutils literal"&gt;]&lt;/tt&gt; is a bit trickier; I hope the comments do a good
job explaining what's going on, and the code itself is optimized for readability
rather than cleverness:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;]&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;open_bracket_stack&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;DIE&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;unmatched closing &amp;#39;]&amp;#39; at pc=&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;open_bracket_offset&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;open_bracket_stack&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;top&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;open_bracket_stack&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// cmpb $0, 0(%r13)&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmitBytes&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="mh"&gt;0x41&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x7d&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x00&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// open_bracket_offset points to the JZ that jumps to this closing&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// bracket. We&amp;#39;ll need to fix up the offset for that JZ, as well as emit a&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// JNZ with a correct offset back. Note that both [ and ] jump to the&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// instruction *after* the matching bracket if their condition is&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// fulfilled.&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// Compute the offset for this jump. The jump start is computed from after&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// the jump instruction, and the target is the instruction after the one&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// saved on the stack.&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;jump_back_from&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;jump_back_to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;open_bracket_offset&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="kt"&gt;uint32_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pcrel_offset_back&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;compute_relative_32bit_offset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;jump_back_from&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;jump_back_to&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// jnz &amp;lt;open_bracket_location&amp;gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmitBytes&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="mh"&gt;0x0F&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0x85&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmitUint32&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pcrel_offset_back&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// Also fix up the forward jump at the matching [. Note that here we don&amp;#39;t&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// need to add the size of this jmp to the &amp;quot;jump to&amp;quot; offset, since the jmp&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// was already emitted and the emitter size was bumped forward.&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;jump_forward_from&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;open_bracket_offset&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;jump_forward_to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="kt"&gt;uint32_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pcrel_offset_forward&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;compute_relative_32bit_offset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;jump_forward_from&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;jump_forward_to&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ReplaceUint32AtOffset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;open_bracket_offset&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;                                &lt;/span&gt;&lt;span class="n"&gt;pcrel_offset_forward&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This concludes the compiler loop; we end up with a bunch of potentially
executable machine code in &lt;tt class="docutils literal"&gt;vector&lt;/tt&gt;. This code refers to the host program (the
address of &lt;tt class="docutils literal"&gt;memory.data()&lt;/tt&gt;), but that's OK since the host program's lifetime
wraps the lifetime of the JITed code. What's remaining is to actually invoke
this machine code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;// ... after the compilation loop&lt;/span&gt;

&lt;span class="c1"&gt;// The emitted code will be called as a function from C++; therefore it has to&lt;/span&gt;
&lt;span class="c1"&gt;// use the proper calling convention. Emit a &amp;#39;ret&amp;#39; for orderly return to the&lt;/span&gt;
&lt;span class="c1"&gt;// caller.&lt;/span&gt;
&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmitByte&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0xC3&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="c1"&gt;// Load the emitted code to executable memory and run it.&lt;/span&gt;
&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;vector&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;uint8_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;emitted_code&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;JitProgram&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;jit_program&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;emitted_code&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="c1"&gt;// JittedFunc is the C++ type for the JIT function emitted here. The emitted&lt;/span&gt;
&lt;span class="c1"&gt;// function is callable from C++ and follows the x64 System V ABI.&lt;/span&gt;
&lt;span class="k"&gt;using&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;JittedFunc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)(&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="n"&gt;JittedFunc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;JittedFunc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;jit_program&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;program_memory&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The call should be familiar from reading the &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/11/05/how-to-jit-an-introduction"&gt;How to JIT&lt;/a&gt; post.
Note that here we opted for the simplest function possible - no arguments, no
return value; in future sections we'll spice it up a bit.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="taking-our-jit-for-a-spin"&gt;
&lt;h2&gt;Taking our JIT for a spin&lt;/h2&gt;
&lt;p&gt;In &lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-1-an-interpreter/"&gt;part 1&lt;/a&gt;,
I presented a trivial BF program that prints the numbers 1 to 5 to the screen:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;++++++++ ++++++++ ++++++++ ++++++++ ++++++++ ++++++++
&amp;gt;+++++
[&amp;lt;+.&amp;gt;-]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Let's see what our compiler translates it to. Even though the code vector inside
&lt;tt class="docutils literal"&gt;simplejit&lt;/tt&gt; is ephemeral (lives only temporarily in memory), we can serialize
it to a binary file which we can then disassemble (with &lt;tt class="docutils literal"&gt;objdump &lt;span class="pre"&gt;-D&lt;/span&gt; &lt;span class="pre"&gt;-b&lt;/span&gt; binary
&lt;span class="pre"&gt;-mi386:x86-64&lt;/span&gt;&lt;/tt&gt;). The following is the disassembly listing with comments I
embedded to explain what's going on:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; # The runtime address of memory.data() goes into r13; note that this will
 # likely be a different value in every invocation of the JIT.

  0:   49 bd f0 54 e3 00 00    movabs $0xe354f0,%r13
  7:   00 00 00

 # A sequence of 48 instructions that all do the same, for the initial sequence
 # of +s; this makes me miss our optimizing interpreter, by worry not - we&amp;#39;ll
 # make this go away later in the post.

  a:   41 80 45 00 01          addb   $0x1,0x0(%r13)
  f:   41 80 45 00 01          addb   $0x1,0x0(%r13)

 # [...] 46 more &amp;#39;addb&amp;#39;

 # &amp;gt;+++++

 fa:   49 ff c5                inc    %r13
 fd:   41 80 45 00 01          addb   $0x1,0x0(%r13)
102:   41 80 45 00 01          addb   $0x1,0x0(%r13)
107:   41 80 45 00 01          addb   $0x1,0x0(%r13)
10c:   41 80 45 00 01          addb   $0x1,0x0(%r13)
111:   41 80 45 00 01          addb   $0x1,0x0(%r13)

 # Here comes the loop! Note that the relative jump offset is already inserted
 # into the &amp;#39;je&amp;#39; instruction by the backpatching process.

116:   41 80 7d 00 00          cmpb   $0x0,0x0(%r13)
11b:   0f 84 35 00 00 00       je     0x156
121:   49 ff cd                dec    %r13
124:   41 80 45 00 01          addb   $0x1,0x0(%r13)

 # The &amp;#39;.&amp;#39; is translated into a syscall to WRITE

129:   48 c7 c0 01 00 00 00    mov    $0x1,%rax
130:   48 c7 c7 01 00 00 00    mov    $0x1,%rdi
137:   4c 89 ee                mov    %r13,%rsi
13a:   48 c7 c2 01 00 00 00    mov    $0x1,%rdx
141:   0f 05                   syscall
143:   49 ff c5                inc    %r13
146:   41 80 6d 00 01          subb   $0x1,0x0(%r13)
14b:   41 80 7d 00 00          cmpb   $0x0,0x0(%r13)

 # Jump back to beginning of loop

150:   0f 85 cb ff ff ff       jne    0x121

 # We&amp;#39;re done

156:   c3                      retq
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="how-does-it-perform"&gt;
&lt;h2&gt;How does it perform?&lt;/h2&gt;
&lt;p&gt;It's time to measure the performance of our JIT against the interpreters from
part 1. &lt;tt class="docutils literal"&gt;optinterp3&lt;/tt&gt; was about 10x faster than the naive interpreter - how
will this JIT measure up? Note that it has no optimizations (except not having
to recompute the jump destination for every loop iteration as the naive
interpreter did). Can you guess? The results may surprise you...&lt;/p&gt;
&lt;p&gt;The simple JIT runs &lt;tt class="docutils literal"&gt;mandelbrot&lt;/tt&gt; in 2.89 seconds, and &lt;tt class="docutils literal"&gt;factor&lt;/tt&gt; in 0.94
seconds - much faster still than &lt;tt class="docutils literal"&gt;opt3interp&lt;/tt&gt;; here's the comparison plot
(omitting the slower interpreters since they skew the scale):&lt;/p&gt;
&lt;img alt="BF opt3 vs simplejit" class="align-center" src="https://eli.thegreenplace.net/images/2017/bf-runtime-vs-simplejit.png" /&gt;
&lt;p&gt;Why is this so? &lt;tt class="docutils literal"&gt;opt3interp&lt;/tt&gt; is heavily optimized - it folds entire loops into
a single operation; &lt;tt class="docutils literal"&gt;simplejit&lt;/tt&gt; does none of this - we've just seen the
embarrassing sequence of &lt;tt class="docutils literal"&gt;addb&lt;/tt&gt;s it emits for a long sequence of &lt;tt class="docutils literal"&gt;+&lt;/tt&gt;s.&lt;/p&gt;
&lt;p&gt;The reason is that the &lt;em&gt;baseline&lt;/em&gt; performance of the JIT is vastly better. I've
mentioned this briefly in part 1 - imagine what's needed to interpret a
single instruction in the fastest interpreter.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Advance &lt;tt class="docutils literal"&gt;pc&lt;/tt&gt; and compare it to program size.&lt;/li&gt;
&lt;li&gt;Grab the instruction at &lt;tt class="docutils literal"&gt;pc&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;Switch on the value of the instruction to the right &lt;tt class="docutils literal"&gt;case&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;Execute the &lt;tt class="docutils literal"&gt;case&lt;/tt&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This requires a whole sequence of machine instructions, with at least two
branches (one for the loop, one for the &lt;tt class="docutils literal"&gt;switch&lt;/tt&gt;). On the other hand, the JIT
just emits a &lt;em&gt;single instruction&lt;/em&gt; - no branches. I would say that - depending on
what the compiler did while compiling the interpreter - the JIT is between 4 and
8 times faster at running any given BF operation. It has to run many more BF
operations because it doesn't optimize, but this difference is insufficient to
close the huge baseline gap. Later in this post we're going to see an optimized
JIT which performs even better.&lt;/p&gt;
&lt;p&gt;But first, let's talk about this painful instruction encoding business.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="manually-encoding-instructions"&gt;
&lt;h2&gt;Manually encoding instructions&lt;/h2&gt;
&lt;p&gt;As promised, &lt;tt class="docutils literal"&gt;simplejit&lt;/tt&gt; is completely self-contained. It doesn't use any
external libraries, and encodes all the instructions by hand. It's not hard to
see how painful that process is, and the code is absolutely unreadable unless
accompanied by detailed comments; moreover, changing the code is a pain, and
changes happen in unexpected ways. For example, if we want to use some other
register in an instruction, the change to emitted code won't be intuitive.
&lt;tt class="docutils literal"&gt;add %r8, %r9&lt;/tt&gt; is encoded as &lt;tt class="docutils literal"&gt;0x4C, 0x01, 0xC8&lt;/tt&gt;, but &lt;tt class="docutils literal"&gt;add %r8, %r10&lt;/tt&gt; is
&lt;tt class="docutils literal"&gt;0x4C, 0x01, 0xD0&lt;/tt&gt;; since registers are specified in sub-byte nibbles,
one needs very good memory and tons of experience to predict what goes where.&lt;/p&gt;
&lt;p&gt;Would you expect related instructions to look somewhat similar?
They don't. &lt;tt class="docutils literal"&gt;inc %r13&lt;/tt&gt; is encoded as &lt;tt class="docutils literal"&gt;0x49, 0xFF, 0xC0&lt;/tt&gt;, for example.
To put it bluntly - unless you're &lt;a class="reference external" href="http://www.catb.org/jargon/html/story-of-mel.html"&gt;Mel&lt;/a&gt;, you're going to have a
hard time. Now imagine that you have to support emitting code for multiple
architectures!&lt;/p&gt;
&lt;p&gt;This is why all compilers, VMs and related projects have their own layers to
help with this encoding task, along with related tasks like labels and jump
computations. Most are not exposed for easy usage outside their project; others,
like &lt;a class="reference external" href="http://luajit.org/dynasm.html"&gt;DynASM&lt;/a&gt; (developed as part of the LuaJIT
project) are packaged for separate usage. DynASM is an example of a low-level
framework - providing instruction encoding and not much else; some frameworks
are higher-level, doing more compiler-y things like register allocation. One
example is &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/10/17/getting-started-with-libjit-part-1"&gt;libjit&lt;/a&gt;;
another is LLVM.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="asmjit"&gt;
&lt;h2&gt;asmjit&lt;/h2&gt;
&lt;p&gt;While looking for a library to help me encode instructions, I initially tried
DynASM. It's an interesting approach - and you can see &lt;a class="reference external" href="http://blog.reverberate.org/2012/12/hello-jit-world-joy-of-simple-jits.html"&gt;Josh Haberman's post&lt;/a&gt;
about using it for a simple BF JIT, but I found it to be a bit too
abandonware-ish for my taste. Besides, I don't like the funky preprocessor
approach with a dependency on Lua.&lt;/p&gt;
&lt;p&gt;So I found another project that seemed to fit the bill - &lt;a class="reference external" href="https://github.com/asmjit/asmjit"&gt;asmjit&lt;/a&gt; - a pure C++ library without any
preprocessing. &lt;tt class="docutils literal"&gt;asmjit&lt;/tt&gt; began about 3 years ago to ease its author's
development of fast kernels for graphics code. Its documentation isn't much
better than &lt;tt class="docutils literal"&gt;dynasm&lt;/tt&gt;'s, but being just a C++ library I found it easier to dive
into the source when questions arose the docs couldn't answer. Besides, the
author is very active and quick in answering questions on GitHub and adding
missing featuers. Therefore, the rest of this post shows BF JITs that use
&lt;tt class="docutils literal"&gt;asmjit&lt;/tt&gt; - these can also serve as a non-trivial tutorial for the library.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="simpleasmjit-jit-with-sane-instruction-encoding"&gt;
&lt;h2&gt;simpleasmjit - JIT with sane instruction encoding&lt;/h2&gt;
&lt;p&gt;Enter &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/blob/main/2017/bfjit/simpleasmjit.cpp"&gt;simpleasmjit.cpp&lt;/a&gt; -
the same simple JIT (no optimizations) as &lt;tt class="docutils literal"&gt;simplejit&lt;/tt&gt;, but using &lt;tt class="docutils literal"&gt;asmjit&lt;/tt&gt;
for the instruction encoding, labels and so on. Just for fun, we'll mix things
up a bit. First, we'll change the JITed function signature from &lt;tt class="docutils literal"&gt;void
&lt;span class="pre"&gt;(*)(void)&lt;/span&gt;&lt;/tt&gt; to &lt;tt class="docutils literal"&gt;void &lt;span class="pre"&gt;(*)(uint64_t)&lt;/span&gt;&lt;/tt&gt;; the address of the BF memory buffer will
be passed as argument into the JITed function rather than hard-coded into it.&lt;/p&gt;
&lt;p&gt;Second, we'll use actual C functions to emit / input characters, rather than
system calls. Moreover, since &lt;tt class="docutils literal"&gt;putchar&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;getchar&lt;/tt&gt; may be macros on some
systems, taking their address can be unsafe. So we'll wrap them in actual C++
functions, whose address it &lt;em&gt;is&lt;/em&gt; safe to take in emitted code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;myputchar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;uint8_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;putchar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="kt"&gt;uint8_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;mygetchar&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;getchar&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;simpleasmjit&lt;/tt&gt; starts by initializing an &lt;tt class="docutils literal"&gt;asmjit&lt;/tt&gt; runtime, code holder and
assembler &lt;a class="footnote-reference" href="#footnote-3" id="footnote-reference-3"&gt;[3]&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;JitRuntime&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;jit_runtime&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;CodeHolder&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;code&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;jit_runtime&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getCodeInfo&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;X86Assembler&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Next, we'll give a mnemonic name to our data pointer, and emit a copy of the
address of the memory buffer into it (it's in &lt;tt class="docutils literal"&gt;rdi&lt;/tt&gt; initially, as the first
function argument in the x64 ABI):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;// We pass the data pointer as an argument to the JITed function, so it&amp;#39;s&lt;/span&gt;
&lt;span class="c1"&gt;// expected to be in rdi. Move it to r13.&lt;/span&gt;
&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;X86Gp&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;x86&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;r13&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mov&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;x86&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;rdi&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then we get to the usual BF processing loop that emits code for every BF op:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;instructions&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;instruction&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;instructions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;switch&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;instruction&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;&amp;gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;// inc %r13&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;inc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;&amp;lt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;// dec %r13&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dec&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;+&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;// addb $1, 0(%r13)&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;x86&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;byte_ptr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;-&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;// subb $1, 0(%r13)&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sub&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;x86&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;byte_ptr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Notice the difference! No more obscure hex codes - &lt;tt class="docutils literal"&gt;assm.inc(dataptr)&lt;/tt&gt; is so
much nicer than &lt;tt class="docutils literal"&gt;0x49, 0xFF, 0xC5&lt;/tt&gt;, isn't it?&lt;/p&gt;
&lt;p&gt;For input and output we emit calls to our wrapper functions:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// call myputchar [dataptr]&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;movzx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;x86&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;rdi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;x86&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;byte_ptr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;imm_ptr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;myputchar&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// [dataptr] = call mygetchar&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// Store only the low byte to memory to avoid overwriting unrelated data.&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;imm_ptr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mygetchar&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mov&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;x86&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;byte_ptr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;x86&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;al&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The magic is in the &lt;tt class="docutils literal"&gt;imm_ptr&lt;/tt&gt; modifier, which places the address of the
function in the emitted code.&lt;/p&gt;
&lt;p&gt;Finally, the code handling &lt;tt class="docutils literal"&gt;[&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;]&lt;/tt&gt; is also much simpler due to asmjit's
&lt;em&gt;labels&lt;/em&gt;, which can be used before they're actually emitted:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;[&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cmp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;x86&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;byte_ptr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Label&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;open_label&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;newLabel&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Label&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;close_label&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;newLabel&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// Jump past the closing &amp;#39;]&amp;#39; if [dataptr] = 0; close_label wasn&amp;#39;t bound&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// yet (it will be bound when we handle the matching &amp;#39;]&amp;#39;), but asmjit lets&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// us emit the jump now and will handle the back-patching later.&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jz&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;close_label&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// open_label is bound past the jump; all in all, we&amp;#39;re emitting:&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;//&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;//    cmpb 0(%r13), 0&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;//    jz close_label&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// open_label:&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;//    ...&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bind&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;open_label&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// Save both labels on the stack.&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;open_bracket_stack&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;push&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BracketLabels&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;open_label&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;close_label&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;]&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;open_bracket_stack&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;DIE&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;unmatched closing &amp;#39;]&amp;#39; at pc=&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;BracketLabels&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;open_bracket_stack&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;top&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;open_bracket_stack&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;//    cmpb 0(%r13), 0&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;//    jnz open_label&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// close_label:&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;//    ...&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cmp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;x86&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;byte_ptr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jnz&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open_label&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bind&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close_label&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We just have to remember which label we used for the jump and emit the exact
same &lt;tt class="docutils literal"&gt;Label&lt;/tt&gt; object - &lt;tt class="docutils literal"&gt;asmjit&lt;/tt&gt; handles the backpatching on its own!
Moreover, all the jump offset computations are performed automatically.&lt;/p&gt;
&lt;p&gt;Finally, after emitting the code we can call it:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;using&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;JittedFunc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)(&lt;/span&gt;&lt;span class="kt"&gt;uint64_t&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="n"&gt;JittedFunc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Error&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;err&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;jit_runtime&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;// [...]&lt;/span&gt;
&lt;span class="c1"&gt;// Call it, passing the address of memory as a parameter.&lt;/span&gt;
&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="kt"&gt;uint64_t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;That's it. This JIT emits virtually the same exact code as &lt;tt class="docutils literal"&gt;simplejit&lt;/tt&gt;, and
thus we don't expect it to perform any differently. The main point of this
exercise is to show how much simpler and more pleasant emitting code is with a
library like &lt;tt class="docutils literal"&gt;asmjit&lt;/tt&gt;. It hides all the icky encoding and offset computations,
letting us focus on what's actually unique for our program - the sequence of
instructions emitted.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="optasmjit-combining-bf-optimizations-with-a-jit"&gt;
&lt;h2&gt;optasmjit - combining BF optimizations with a JIT&lt;/h2&gt;
&lt;p&gt;Finally, it's time to combine the clever optimizations we've developed in part 1
with the JIT. Here, I'm essentially taking &lt;tt class="docutils literal"&gt;optinterp3&lt;/tt&gt; from part
1 and bolting a JIT backend onto it. The result is &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/blob/main/2017/bfjit/optasmjit.cpp"&gt;optasmjit.cpp&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Recall that instead of the 8 BF ops, we have an extended set, with integer
arguments, that conveys higher-level ops in some cases:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;enum&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;BfOpKind&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;INVALID_OP&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;INC_PTR&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;DEC_PTR&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;INC_DATA&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;DEC_DATA&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;READ_STDIN&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;WRITE_STDOUT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;LOOP_SET_TO_ZERO&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;LOOP_MOVE_PTR&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;LOOP_MOVE_DATA&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;JUMP_IF_DATA_ZERO&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;JUMP_IF_DATA_NOT_ZERO&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;};&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The translation phase from BF ops to a sequence of &lt;tt class="docutils literal"&gt;BfOpKind&lt;/tt&gt; is exactly the
same as it was in &lt;tt class="docutils literal"&gt;optinterp3&lt;/tt&gt;. Let's take a look at how a couple of the new
ops are implemented now:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="no"&gt;BfOpKind&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="no"&gt;INC_PTR&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;op&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argument&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As before with the interpreters, an increment of 1 is replaced by the addition
of an argument. We use a different instruction for this - &lt;tt class="docutils literal"&gt;add&lt;/tt&gt; instead of
&lt;tt class="docutils literal"&gt;inc&lt;/tt&gt; &lt;a class="footnote-reference" href="#footnote-4" id="footnote-reference-4"&gt;[4]&lt;/a&gt;. How about something more interesting:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="no"&gt;BfOpKind&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="no"&gt;LOOP_MOVE_DATA&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// Only move if the current data isn&amp;#39;t 0:&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;//&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;//   cmpb 0(%r13), 0&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;//   jz skip_move&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;//   &amp;lt;...&amp;gt; move data&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// skip_move:&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Label&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;skip_move&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;newLabel&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cmp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;x86&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;byte_ptr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jz&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;skip_move&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mov&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;x86&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;r14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;op&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argument&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sub&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;x86&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;r14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;op&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argument&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;x86&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;r14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;op&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argument&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// Use rax as a temporary holding the value of at the original pointer;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// then use al to add it to the new location, so that only the target&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// location is affected: addb %al, 0(%r13)&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mov&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;x86&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;rax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;x86&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;byte_ptr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;x86&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;byte_ptr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;x86&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;r14&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;x86&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;al&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mov&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;asmjit&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;x86&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;byte_ptr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;assm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bind&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;skip_move&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I'll just note again how much simpler this code is to write with &lt;tt class="docutils literal"&gt;asmjit&lt;/tt&gt; than
without it. Also note the careful handling of the byte-granulated data when
touching memory - I ran into a number of nasty bugs when developing this. In
fact, using the native machine word size (64 bits in this case) for BF memory
cells would've made everything much simpler; 8-bit cells are closer to the
common semantics of the language and provide an extra challenge.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="performance"&gt;
&lt;h2&gt;Performance&lt;/h2&gt;
&lt;p&gt;Let's see how &lt;tt class="docutils literal"&gt;optasmjit&lt;/tt&gt; fares against the fastest interpreter and the
unoptimized JIT - 0.93 seconds for &lt;tt class="docutils literal"&gt;mandelbrot&lt;/tt&gt;, 0.3 seconds for &lt;tt class="docutils literal"&gt;factor&lt;/tt&gt; -
another factor of 3 in performance:&lt;/p&gt;
&lt;img alt="BF opt3 vs simplejit vs optasmjit" class="align-center" src="https://eli.thegreenplace.net/images/2017/bf-runtime-vs-optasmjit.png" /&gt;
&lt;p&gt;Notably, the performance delta with the optimized interpreter is huge: the JIT
is more than 4x faster. If we compare it all the way to the initial simple
interpreter, &lt;tt class="docutils literal"&gt;optasmjit&lt;/tt&gt; is about 40x faster - making it hard to even
compare on the same chart :-)&lt;/p&gt;
&lt;img alt="BF full performance comparison for part 2" class="align-center" src="https://eli.thegreenplace.net/images/2017/bf-runtime-full-part2.png" /&gt;
&lt;/div&gt;
&lt;div class="section" id="jits-are-fun"&gt;
&lt;h2&gt;JITs are fun!&lt;/h2&gt;
&lt;p&gt;I find writing JITs lots of fun. It's really nice to be able to hand-craft every
instruction emitted by the compiler. While this is quite painful to do without
any encoding help, libraries like &lt;tt class="docutils literal"&gt;asmjit&lt;/tt&gt; make the process much more
pleasant.&lt;/p&gt;
&lt;p&gt;We've done quite a bit in this part of the series. &lt;tt class="docutils literal"&gt;optasmjit&lt;/tt&gt; is a genuine
optimizing JIT for BF! It:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Parses BF source&lt;/li&gt;
&lt;li&gt;Translates it to a sequence of higher-level ops&lt;/li&gt;
&lt;li&gt;Optimizes these ops&lt;/li&gt;
&lt;li&gt;Compiles the ops to tight x64 assembly in memory and runs them&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let's connect these steps to some real compiler jargon. &lt;tt class="docutils literal"&gt;BfOpKind&lt;/tt&gt; ops can be
seen as the &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Intermediate_representation"&gt;compiler IR&lt;/a&gt;. Translation of
human-readable source code to IR is often the first step in compilation (though
it in itself is sometimes divided into multiple steps for realistic languages).
The translation/compilation of ops to assembly is often called &amp;quot;lowering&amp;quot;; in
some compilers this involves multiple steps and intermediate IRs.&lt;/p&gt;
&lt;p&gt;I left a lot of code out of the blog post - otherwise it would be huge! I
encourage you to go back through the full source files discussed here and
understand what's going on - every JIT is a single standalone C++ file.&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;Links to all posts in this series:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-1-an-interpreter/"&gt;Part 1 - an interpreter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-2-an-x64-jit/"&gt;Part 2 - an x64 JIT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-3-llvm/"&gt;Part 3 - LLVM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-4-in-python/"&gt;Part 4 - Python&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr class="docutils" /&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-1" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;I said &lt;em&gt;traditionally&lt;/em&gt; because many modern compilers no longer work this
way. For example, LLVM compiles IR to another, much lower-level IR that
represents machine-code level instructions; assembly can be emitted from
this IR, but also machine code directly - so the assembler is integrated
into the compiler.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-2" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-2"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Some compilers would do two passes; this is similar to our first
interpreter optimization in part 1: the first pass collects information
(such as location of all matching &lt;tt class="docutils literal"&gt;]&lt;/tt&gt;s), so the second pass already
knows what offsets to emit.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-3" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-3"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Please refer to asmjit's documentation for the full scoop. I'll also
mention that asmjit has a &amp;quot;compiler&amp;quot; layer which does more sophisticated
things like register allocation; in this post I'm only using the base
assembly layer.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-4" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-4"&gt;[4]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Wondering whether we could have
just used &lt;tt class="docutils literal"&gt;add 1&lt;/tt&gt; instead of &lt;tt class="docutils literal"&gt;inc&lt;/tt&gt; in the first place? Certainly! In
fact, while there probably used to be a good reason for a separate
&lt;tt class="docutils literal"&gt;inc&lt;/tt&gt; instruction, in these days of complex multi-port pipelined x64
CPUs, it's not clear which one is faster. I just wanted to show both for
diversity.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</content><category term="misc"></category><category term="Compilation"></category><category term="Code generation"></category><category term="Assembly"></category></entry><entry><title>Adventures in JIT compilation: Part 1 - an interpreter</title><link href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-1-an-interpreter/" rel="alternate"></link><published>2017-03-20T06:25:00-07:00</published><updated>2024-05-04T19:46:23-07:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2017-03-20:/2017/adventures-in-jit-compilation-part-1-an-interpreter/</id><summary type="html">&lt;p&gt;This is the first post in a series about JIT compilers. The plan is to take a
simple input language and develop some interpreters and JITs for it, in roughtly
increasing degree of complexity. It's my hope that by the end of the series
readers will have a good understanding â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is the first post in a series about JIT compilers. The plan is to take a
simple input language and develop some interpreters and JITs for it, in roughtly
increasing degree of complexity. It's my hope that by the end of the series
readers will have a good understanding of what it takes to develop a JIT
compiler and what are some of the tools available to assist with the task.&lt;/p&gt;
&lt;p&gt;The input language will be &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Brainfuck"&gt;Brainfuck&lt;/a&gt;, or BF as I'll be referring to it
from now and throughout the series. I think it's a good language for the purpose
since it really boils programmability down to the essentials. Even though it's
very tedious to program in, BF is fairly &amp;quot;mainstream&amp;quot; as far as programming
languages go, with some concepts like memory pointers and loops mapping directly
to familiar C constructs.&lt;/p&gt;
&lt;p&gt;As the implementation language I'll be using C++. This is, perhaps, not the most
commonly used &amp;quot;starter&amp;quot; language; that said, most compilers I know are written
in C++ (or C), and hence many of the most popular low-level code-generation
libraries in existence are in these languages. In later parts of this series
we'll be using some C++ libraries, and this is by far easiest to do from C++
itself. Besides, I try to keep my code straightforward throughout the series -
there is very little use of advanced C++ features here.&lt;/p&gt;
&lt;div class="section" id="the-bf-language"&gt;
&lt;h2&gt;The BF language&lt;/h2&gt;
&lt;p&gt;The BF language is simple to describe, but I don't do this here. Please take a
look at &lt;a class="reference external" href="https://esolangs.org/wiki/Brainfuck"&gt;the spec&lt;/a&gt;, read the Wikipedia
page, or one of the other existing resources. An in-browser interpreter such as
&lt;a class="reference external" href="https://copy.sh/brainfuck/"&gt;this one&lt;/a&gt; can be very useful.&lt;/p&gt;
&lt;p&gt;I'll just give an example to develop a taste for the language. The following BF
program prints the numbers 1 to 5 to the screen:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;++++++++ ++++++++ ++++++++ ++++++++ ++++++++ ++++++++
&amp;gt;+++++
[&amp;lt;+.&amp;gt;-]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here's what it does:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Line 1 initializes memory cell 0 to the value 48, which happens to be the
ASCII code for &lt;tt class="docutils literal"&gt;0&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;Line 2 initializes memory cell 1 to 5, which is our loop counter.&lt;/li&gt;
&lt;li&gt;Line 3 is a loop that, at each iteration, increments cell 0 and prints its
value out, then decrements cell 1 and checks if it has reached the value 0.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="a-simple-interpreter"&gt;
&lt;h2&gt;A simple interpreter&lt;/h2&gt;
&lt;p&gt;To get an initial feel for the language and to have a reliable reference
implementation, we'll start with a simple interpreter that processes one BF
character at a time and does what's necessary to &amp;quot;execute&amp;quot; it.&lt;/p&gt;
&lt;p&gt;One of the reasons for my choosing BF as the source language is its simplicity.
You'll find a lot of tutorials online that purport to develop interpreters or
compilers but end up focusing 90% of their time on writing the parser. I think
the later stages of compilation are much more interesting, so my &amp;quot;parser&amp;quot; for BF
looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;Program&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;instructions&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;};&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="n"&gt;Program&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;parse_from_stream&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;istream&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Program&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;program&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;getline&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;);)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;auto&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;&amp;gt;&amp;#39;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;||&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;&amp;lt;&amp;#39;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;||&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;+&amp;#39;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;||&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;-&amp;#39;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;||&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;||&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;          &lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;||&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;[&amp;#39;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;||&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;]&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;program&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;instructions&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;push_back&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;program&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that this is a valid implementation according to the &lt;a class="reference external" href="https://esolangs.org/wiki/Brainfuck"&gt;BF spec&lt;/a&gt;: all characters except the 8 supported
ones are to be treated as comments and ignored &lt;a class="footnote-reference" href="#footnote-1" id="footnote-reference-1"&gt;[1]&lt;/a&gt;. This parser is going to
serve us throughout the series.&lt;/p&gt;
&lt;p&gt;With that out of the way, here's the actual interpreter:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;constexpr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;MEMORY_SIZE&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;30000&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;simpleinterp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Program&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;bool&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;verbose&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// Initialize state.&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;vector&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;uint8_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MEMORY_SIZE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;while&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;instructions&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;instruction&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;instructions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;switch&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;instruction&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;&amp;gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;&amp;lt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;+&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;-&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;cout&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;put&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;cin&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;// [...]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;All these cases are rather trivial. The more interesting ones are the control
flow ops - &lt;tt class="docutils literal"&gt;[&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;]&lt;/tt&gt;. We'll start with &lt;tt class="docutils literal"&gt;[&lt;/tt&gt; - jump forward if the current
data location is zero. This op makes it possible to skip a loop or implement a
simple &lt;tt class="docutils literal"&gt;if&lt;/tt&gt;-like condition.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;[&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bracket_nesting&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;saved_pc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;while&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bracket_nesting&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;instructions&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;instructions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;]&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;bracket_nesting&lt;/span&gt;&lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;instructions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;[&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;bracket_nesting&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="n"&gt;bracket_nesting&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;DIE&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;unmatched &amp;#39;[&amp;#39; at pc=&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;saved_pc&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The most important thing to note here is that the &lt;tt class="docutils literal"&gt;[&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;]&lt;/tt&gt; brackets in BF
can be nested; therefore, when figuring out where to jump, we have to find the
matching bracket. If this seems like something wasteful to do at run-time,
you're right - keep reading!&lt;/p&gt;
&lt;p&gt;For &lt;tt class="docutils literal"&gt;]&lt;/tt&gt; we do something very similar. In BF, &lt;tt class="docutils literal"&gt;]&lt;/tt&gt; is jumping to an earlier
&lt;tt class="docutils literal"&gt;[&lt;/tt&gt; if the current data location is not zero. This is how loops advance to the
next iteration (or stop).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;]&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;!=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bracket_nesting&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;saved_pc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;while&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bracket_nesting&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;instructions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;[&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;bracket_nesting&lt;/span&gt;&lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;instructions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;]&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;bracket_nesting&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="n"&gt;bracket_nesting&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;DIE&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;unmatched &amp;#39;]&amp;#39; at pc=&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;saved_pc&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And that's it! The interpreter loop concludes with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;default&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;DIE&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;bad char &amp;#39;&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;instruction&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&amp;#39; at pc=&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The full code for this simple interpreter can be found in
&lt;a class="reference external" href="https://github.com/eliben/code-for-blog/blob/main/2017/bfjit/simpleinterp.cpp"&gt;simpleinterp.cpp&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="measuring-the-performance-of-bf-programs"&gt;
&lt;h2&gt;Measuring the performance of BF programs&lt;/h2&gt;
&lt;p&gt;Whenever we develop something like an interpreter or compiler, execution speed
is a paramount concern. Therefore, it's common for compiler writers to have
benchmark suites they refer to for measurements. For BF, I'll be using a couple
of programs throughout the series to measure how fast our implementation is. One
is a &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/blob/main/2017/bfjit/bf-programs/mandelbrot.bf"&gt;Mandelbrot generator&lt;/a&gt;;
another is a &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/blob/main/2017/bfjit/tests/testcases/factor.bf"&gt;factorization program&lt;/a&gt;
invoked on the large-ish prime 179424691 &lt;a class="footnote-reference" href="#footnote-2" id="footnote-reference-2"&gt;[2]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The simple interpreter shown above takes 38.6 seconds on &lt;tt class="docutils literal"&gt;mandelbrot&lt;/tt&gt; and 16.5
seconds on &lt;tt class="docutils literal"&gt;factor&lt;/tt&gt; &lt;a class="footnote-reference" href="#footnote-3" id="footnote-reference-3"&gt;[3]&lt;/a&gt;. Now let's see how we can &lt;em&gt;greatly&lt;/em&gt; improve these
numbers.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="optimized-interpreter-take-1"&gt;
&lt;h2&gt;Optimized interpreter - take 1&lt;/h2&gt;
&lt;p&gt;The most obvious optimization opportunity for the simple interpreter is to avoid
laboriously looking for the matching bracket every time a &lt;tt class="docutils literal"&gt;[&lt;/tt&gt; or &lt;tt class="docutils literal"&gt;]&lt;/tt&gt; is
encountered. Imagine a realistic program with a hot inner loop (by &amp;quot;hot&amp;quot; here I
mean it runs many, many - possibly billions - of times throughtout the execution
of the program). Is it really necessary to scan the source to find the matching
bracket &lt;em&gt;every single time&lt;/em&gt;? Of course not. We can just precompute these jump
destinations ahead of time, since the BF program doesn't change throughout its
execution.&lt;/p&gt;
&lt;p&gt;This is the idea behind &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/blob/main/2017/bfjit/optinterp.cpp"&gt;optinterp.cpp&lt;/a&gt;
- our first optimized
interpreter. Much of the code is the same as for the simple interpreter, so I'll
just highlight the differences. A crucial addition is this function, which is
run before the actual interpretation happens:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;vector&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;compute_jumptable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Program&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;program_size&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;instructions&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;vector&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;jumptable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;program_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;while&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;program_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;instruction&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;instructions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;instruction&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;[&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bracket_nesting&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;seek&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="k"&gt;while&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bracket_nesting&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;seek&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;program_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;instructions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;seek&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;]&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;          &lt;/span&gt;&lt;span class="n"&gt;bracket_nesting&lt;/span&gt;&lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;instructions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;seek&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;[&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;          &lt;/span&gt;&lt;span class="n"&gt;bracket_nesting&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="n"&gt;bracket_nesting&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;jumptable&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;seek&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;jumptable&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;seek&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;DIE&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;unmatched &amp;#39;[&amp;#39; at pc=&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;jumptable&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It computes the jump destinations for all the &lt;tt class="docutils literal"&gt;[&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;]&lt;/tt&gt; ops in the
program. Its operation is essentially identical to the scanning forward /
backward for a matching bracket in the main loop of the simple interpreter. The
result is the vector &lt;tt class="docutils literal"&gt;jumptable&lt;/tt&gt;, where for every &lt;tt class="docutils literal"&gt;[&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;]&lt;/tt&gt; at offset
&lt;tt class="docutils literal"&gt;i&lt;/tt&gt; in the program, &lt;tt class="docutils literal"&gt;jumptable[i]&lt;/tt&gt; holds the offset of the matching bracket.
For any other op at offset &lt;tt class="docutils literal"&gt;i&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;jumptable[i]&lt;/tt&gt; is simply 0.&lt;/p&gt;
&lt;p&gt;The actual main loop of &lt;tt class="docutils literal"&gt;optinterp&lt;/tt&gt; is the same as in &lt;tt class="docutils literal"&gt;simpleinterp&lt;/tt&gt;, except
for the clauses for brackets, which become simply:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;[&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;jumptable&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;]&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;!=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;jumptable&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As you'd expect, &lt;tt class="docutils literal"&gt;optinterp&lt;/tt&gt; is quite a bit faster; it takes only 18.4 seconds
to run &lt;tt class="docutils literal"&gt;mandelbrot&lt;/tt&gt; and 6.7 seconds to run &lt;tt class="docutils literal"&gt;factor&lt;/tt&gt; - more than a factor of
2 improvement!&lt;/p&gt;
&lt;img alt="BF interpreter runtime plot" class="align-center" src="https://eli.thegreenplace.net/images/2017/bf-runtime-vs-opt.png" /&gt;
&lt;/div&gt;
&lt;div class="section" id="optimized-interpreter-take-2"&gt;
&lt;h2&gt;Optimized interpreter - take 2&lt;/h2&gt;
&lt;p&gt;The optimization applied in the previous section was very beneficial, but it's
also fairly trivial - we avoid completely unnecessary work at run-time, if we
can just precompute it at compile time. To make our interpreter even faster,
we'll have to get more creative.&lt;/p&gt;
&lt;p&gt;The first step in optimizing anything is measuring and profiling the current
code. Some past experience helps avoid needless steps in this process. For
example, it's fairly clear that almost 100% of the run-time of the interpreter
will be spent in the single function that interprets the program; therefore,
function/call profiling won't be of much help.&lt;/p&gt;
&lt;p&gt;The main loop is fairly small, however, and there doesn't appear to be much to
optimize at first glance (disregarding micro-optimizaitons which I won't worry
about here). Well, except that this loop runs for every BF instruction
encountered in the source program, so it can run &lt;em&gt;tons&lt;/em&gt; of times. So what we'll
do is get a breakdown of the ops that execute during a typical program run. The
code for &lt;tt class="docutils literal"&gt;optinterp&lt;/tt&gt; already has this tracing included - it's protected with
the &lt;tt class="docutils literal"&gt;BFTRACE&lt;/tt&gt; preprocessor macro because it's costly and we want to avoid
doing it in &amp;quot;real&amp;quot; runs.&lt;/p&gt;
&lt;p&gt;Here's the execution profile we get from a typical run of the &lt;tt class="docutils literal"&gt;factor&lt;/tt&gt;
benchmark on the prime 179424691. On the left is the operation, and on the right
the number of times it was executed by the interpreter for the program at hand:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;.  --&amp;gt;  21
,  --&amp;gt;  10
+  --&amp;gt;  212,428,900
]  --&amp;gt;  242,695,606
&amp;lt;  --&amp;gt;  1,220,387,704
-  --&amp;gt;  212,328,376
&amp;gt;  --&amp;gt;  1,220,387,724
[  --&amp;gt;  118,341,127
.. Total: 3,226,569,468
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;A couple of immediate observations:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;The total number of operations is &lt;em&gt;huge&lt;/em&gt;: over 3 billion times around the
main interpreter loop. It's a good thing we're using C++ for the interpreter
- running 3 billion iterations of anything in a higher level language would
be painful!&lt;/li&gt;
&lt;li&gt;The ratio of pointer movement instructions to loops is suspiciously high.
There's something like 242 million loop iterations executed (the count for
&lt;tt class="docutils literal"&gt;]&lt;/tt&gt;) but a total of 2.4 billion pointer moves: &lt;tt class="docutils literal"&gt;&amp;lt;&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;&amp;gt;&lt;/tt&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We'd expect and hope for the hot loops to be short and tight - why is every loop
doing so much?&lt;/p&gt;
&lt;p&gt;A cursory glance at the source of &lt;tt class="docutils literal"&gt;factor.bf&lt;/tt&gt; provides a clue. Here's a
representative snippet:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;  &amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;[&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;]&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;
  [&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;[-]&amp;lt;&amp;lt;[-&amp;gt;+&amp;lt;]&amp;lt;[-&amp;gt;&amp;gt;&amp;gt;+&amp;lt;&amp;lt;&amp;lt;]&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;]&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;
  [+&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;[-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;+&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;[-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;-&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;+&amp;gt;
           [-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;+&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;[-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;-&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;+&amp;gt;
           [-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;+&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;[-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;-&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;+&amp;gt;
           [-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;+&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;[-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;-&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;+&amp;gt;
           [-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;+&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;]]]]]]]]]&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;
           [-&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;+&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;]-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;]
  &amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;
  [-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;+&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;]
    &amp;gt;&amp;gt;&amp;gt;[&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;[-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;+++++&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;]&amp;gt;&amp;gt;&amp;gt;]&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;
  [+&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;[-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;+&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;[-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;-&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;+&amp;gt;&amp;gt;&amp;gt;
            [-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;+&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;[-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;-&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;+&amp;gt;&amp;gt;&amp;gt;
            [-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;+&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;[-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;-&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;+&amp;gt;&amp;gt;&amp;gt;
            [-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;+&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;[-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;-&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;+&amp;gt;&amp;gt;&amp;gt;
            [-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;+&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;]]]]]]]]]&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;
            [-&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;+&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;]-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;]
  &amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;[-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;+&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;]&amp;gt;&amp;gt;
  [&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;[-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;+++++&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;]&amp;gt;&amp;gt;]&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;
  [&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;]&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;
  &amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;
]
&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note the fairly long sequences of &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;/tt&gt;. Just a bit of thought
about the semantics of BF makes this clear - these are necessary to get anything
done because we want to be able to get from cell to cell to update data.&lt;/p&gt;
&lt;p&gt;Now let's think what it means to execute a sequence such as &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;/tt&gt; in our
interpreter. Our main loop executes 7 times, each time doing:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Advance &lt;tt class="docutils literal"&gt;pc&lt;/tt&gt; and compare it to program size.&lt;/li&gt;
&lt;li&gt;Grab the instruction at &lt;tt class="docutils literal"&gt;pc&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;Switch on the value of the instruction to the right &lt;tt class="docutils literal"&gt;case&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;Execute the case.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;That's quite expensive. What if we could compress all the long sequences of
&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;/tt&gt;? After all, what we do for a single &lt;tt class="docutils literal"&gt;&amp;lt;&lt;/tt&gt; is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;&amp;lt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So for seven &lt;tt class="docutils literal"&gt;&amp;lt;&lt;/tt&gt;s we could do:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="no"&gt;something&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="no"&gt;representing&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="no"&gt;s&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;...:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is easy to generalize. We can detect any consecutive sequence in the BF
source and encode it as a pair: the operation, and the repetition count. Then
at execution time we simply repeat the op the required number of times.&lt;/p&gt;
&lt;p&gt;The full code for this interpreter is &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/blob/main/2017/bfjit/optinterp2.cpp"&gt;optinterp2.cpp&lt;/a&gt;.
Previously, we kept a separate jump table correlated to the &lt;tt class="docutils literal"&gt;[&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;]&lt;/tt&gt;
instructions in the input program. Now we need extra information for every BF
instruction, so we'll just translate the &lt;tt class="docutils literal"&gt;Program&lt;/tt&gt; into a sequences of ops of
the type:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;enum&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;BfOpKind&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;INVALID_OP&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;INC_PTR&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;DEC_PTR&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;INC_DATA&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;DEC_DATA&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;READ_STDIN&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;WRITE_STDOUT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;JUMP_IF_DATA_ZERO&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;JUMP_IF_DATA_NOT_ZERO&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;};&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="c1"&gt;// Every op has a single numeric argument. For JUMP_* ops it&amp;#39;s the offset to&lt;/span&gt;
&lt;span class="c1"&gt;// which a jump should be made; for all other ops, it&amp;#39;s the number of times the&lt;/span&gt;
&lt;span class="c1"&gt;// op is to be repeated.&lt;/span&gt;
&lt;span class="k"&gt;struct&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;BfOp&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;BfOp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BfOpKind&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;kind_param&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;argument_param&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;kind&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kind_param&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;argument_param&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;BfOpKind&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;kind&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;BfOpKind&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;INVALID_OP&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;argument&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;};&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The interpretation happens in two steps. First we run &lt;tt class="docutils literal"&gt;translate_program&lt;/tt&gt; to
read the program and generate a &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;std::vector&amp;lt;BfOp&amp;gt;&lt;/span&gt;&lt;/tt&gt;. This translation is
pretty straight-forward: it detects repetitions in ops like &lt;tt class="docutils literal"&gt;&amp;lt;&lt;/tt&gt; and encodes
them in the &lt;tt class="docutils literal"&gt;argument&lt;/tt&gt; field. A slightly tricky aspect here is handling the
jumps, since the offsets of all ops in the program change (a run of seven
consecutive &lt;tt class="docutils literal"&gt;&amp;lt;&lt;/tt&gt;s turns into a single &lt;tt class="docutils literal"&gt;DEC_PTR&lt;/tt&gt;, for example). Take a look
at the code for the full details.&lt;/p&gt;
&lt;p&gt;As planned, the main interpreter loop becomes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;switch&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kind&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="no"&gt;BfOpKind&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="no"&gt;INC_PTR&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;op&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argument&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="no"&gt;BfOpKind&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="no"&gt;DEC_PTR&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;op&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argument&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="no"&gt;BfOpKind&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="no"&gt;INC_DATA&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;op&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argument&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="no"&gt;BfOpKind&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="no"&gt;DEC_DATA&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;op&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argument&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;// [...] etc.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;How fast is it? The &lt;tt class="docutils literal"&gt;mandelbrot&lt;/tt&gt; benchmark now takes 11.9 seconds, and
&lt;tt class="docutils literal"&gt;factor&lt;/tt&gt; takes 3.7 seconds; another 40% reduction in run-time.&lt;/p&gt;
&lt;img alt="BF interpreter runtime plot with opt2" class="align-center" src="https://eli.thegreenplace.net/images/2017/bf-runtime-vs-opt2.png" /&gt;
&lt;/div&gt;
&lt;div class="section" id="optimized-interpreter-take-3"&gt;
&lt;h2&gt;Optimized interpreter - take 3&lt;/h2&gt;
&lt;p&gt;Our optimized interpreter now runs the &lt;tt class="docutils literal"&gt;mandelbrot&lt;/tt&gt; benchmark more than 3x
faster than the original, naive interpreter. Can we do even better?&lt;/p&gt;
&lt;p&gt;First, let's take a look at instruction tracing for &lt;tt class="docutils literal"&gt;optinterp2&lt;/tt&gt;, repeating
the previous experiment:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;.  --&amp;gt;  21
]  --&amp;gt;  242,695,606
,  --&amp;gt;  10
+  --&amp;gt;  191,440,613
&amp;lt;  --&amp;gt;  214,595,790
-  --&amp;gt;  205,040,514
&amp;gt;  --&amp;gt;  270,123,690
[  --&amp;gt;  118,341,127
.. Total: 1,242,237,371
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The total instruction count went down almost 3x. Also, now the number of BF loop
executions is more comparable to the number of other instructions, meaning that
we don't do &lt;em&gt;too much&lt;/em&gt; work in every iteration. This was our goal with the
optimization of repetitions, after all.&lt;/p&gt;
&lt;p&gt;In fact, this execution profile is annoyingly flat. Performance gurus don't like
flat profiles because there's nothing in particular sticking out that one could
optimize. This usually means we should measure / trace something else as well.&lt;/p&gt;
&lt;p&gt;An interesting question worth answering is - what is every BF loop doing. In
other words, what are the hottest loops we are running, and can we spend some
more specialized effort to optimize them? This would require more sophisticated
tracing machinery, which I've already included in the code of
&lt;tt class="docutils literal"&gt;optinterp2&lt;/tt&gt;. This machinery traces loops and records the instruction
sequence executed by each loop iteration in the program. It then sorts them by
the number of appearances and shows the most common (hottest) loops. Here is
the result for the &lt;tt class="docutils literal"&gt;factor&lt;/tt&gt; benchmark:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;-1&amp;lt;10+1&amp;gt;10      --&amp;gt; 32,276,219
-1              --&amp;gt; 28,538,377
-1&amp;lt;4+1&amp;gt;4        --&amp;gt; 15,701,515
-1&amp;gt;3+1&amp;gt;1+1&amp;lt;4    --&amp;gt; 12,581,941
-1&amp;gt;3+1&amp;gt;2+1&amp;lt;5    --&amp;gt; 9,579,970
-1&amp;lt;3+1&amp;gt;3        --&amp;gt; 9,004,028
&amp;gt;3              --&amp;gt; 8,911,600
-1&amp;lt;1-1&amp;gt;1        --&amp;gt; 6,093,976
-1&amp;gt;3+1&amp;lt;3        --&amp;gt; 6,085,735
-1&amp;lt;1+1&amp;lt;3+1&amp;gt;4    --&amp;gt; 5,853,530
-1&amp;gt;3+2&amp;lt;3        --&amp;gt; 5,586,229
&amp;gt;2              --&amp;gt; 5,416,630
-1&amp;gt;1+1&amp;lt;1        --&amp;gt; 5,104,333
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;What do these traces mean? The first, most common one says:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Decrement current memory cell&lt;/li&gt;
&lt;li&gt;Move 10 cells to the left&lt;/li&gt;
&lt;li&gt;Increment current memory cell&lt;/li&gt;
&lt;li&gt;Move 10 cells to the right&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The loop doing this was executed 32 million times! Similarly, a loop doing the
simple &amp;quot;decrement the current cell&amp;quot; was executed 28 million times. If you look
in the source of &lt;tt class="docutils literal"&gt;factor.bf&lt;/tt&gt;, these loops are easy to spot. The first one is
&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;[-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;+&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;]&lt;/span&gt;&lt;/tt&gt;; the second one is just &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;[-]&lt;/span&gt;&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;What if we could optimize these loops entirely away? After all, they are doing
something that is much easier to express in a higher-level language. &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;[-]&lt;/span&gt;&lt;/tt&gt;
merely sets the current memory cell to 0. &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;[-&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;+&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;]&lt;/span&gt;&lt;/tt&gt; is more
involved, but not much more: all it does is add the value of the current memory
cell 10 cells to the left. The trace shown above features many loops of this
kind, along with another; loops like &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;[&amp;gt;&amp;gt;&amp;gt;]&lt;/span&gt;&lt;/tt&gt; move to the right in jumps of 3
until encountering a non-zero cell.&lt;/p&gt;
&lt;p&gt;In &lt;tt class="docutils literal"&gt;optinterp2&lt;/tt&gt; we've added higher-level ops to the interpreter. We can add
some even higher-level ops to optimize away these loops.
&lt;a class="reference external" href="https://github.com/eliben/code-for-blog/blob/main/2017/bfjit/optinterp3.cpp"&gt;optinterp3.cpp&lt;/a&gt; does
just that. It adds a few more operation kinds for encoding common loops:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;enum&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;BfOpKind&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;INVALID_OP&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;INC_PTR&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;DEC_PTR&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;INC_DATA&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;DEC_DATA&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;READ_STDIN&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;WRITE_STDOUT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;LOOP_SET_TO_ZERO&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;LOOP_MOVE_PTR&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;LOOP_MOVE_DATA&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;JUMP_IF_DATA_ZERO&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;JUMP_IF_DATA_NOT_ZERO&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;};&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The new ops are &lt;tt class="docutils literal"&gt;LOOP_SET_TO_ZERO&lt;/tt&gt; which replaces &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;[-]&lt;/span&gt;&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;LOOP_MOVE_PTR&lt;/tt&gt;
for loops like &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;[&amp;gt;&amp;gt;&amp;gt;]&lt;/span&gt;&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;LOOP_MOVE_DATA&lt;/tt&gt; for loops like &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;[-&amp;lt;&amp;lt;&amp;lt;+&amp;gt;&amp;gt;&amp;gt;]&lt;/span&gt;&lt;/tt&gt;.
We'll now need a slightly more sophisticated translation step that detects these
loops in the input program and emits the proper &lt;tt class="docutils literal"&gt;LOOP_*&lt;/tt&gt; ops. For an example
of how it's done, here's the translation for &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;[-]&lt;/span&gt;&lt;/tt&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;vector&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;BfOp&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;optimize_loop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;vector&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;BfOp&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ops&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;                                &lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loop_start&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;vector&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;BfOp&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;new_ops&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ops&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loop_start&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;BfOp&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;repeated_op&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ops&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;loop_start&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;repeated_op&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;kind&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;BfOpKind&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;INC_DATA&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;||&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;repeated_op&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;kind&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;BfOpKind&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;DEC_DATA&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;new_ops&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;push_back&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BfOp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BfOpKind&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;LOOP_SET_TO_ZERO&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// [...]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This function is called when translating the BF program to a sequence of ops.
&lt;tt class="docutils literal"&gt;loop_start&lt;/tt&gt; is the index in &lt;tt class="docutils literal"&gt;ops&lt;/tt&gt; where the most recent loop starts. The
code shown above detects the case where the only contents of the loop is a
single &lt;tt class="docutils literal"&gt;-&lt;/tt&gt; (or &lt;tt class="docutils literal"&gt;+&lt;/tt&gt; since in BF memory cells hold unsigned values with
wrap-around). In such cases, a &lt;tt class="docutils literal"&gt;LOOP_SET_TO_ZERO&lt;/tt&gt; op is emitted. When the
interpreter itself runs into a &lt;tt class="docutils literal"&gt;LOOP_SET_TO_ZERO&lt;/tt&gt;, it does just what you'd
expect:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="no"&gt;BfOpKind&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="no"&gt;LOOP_SET_TO_ZERO&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dataptr&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The other loop optimizations are a tiny bit more involved, but all follow the
same basic idea.&lt;/p&gt;
&lt;p&gt;We expect this optimization to be very significant - we've just taken some of
the hottest loops the program runs and folded them into a single, efficient
instruction (or a sequence of efficient instructions for pointer-movement
loops). And indeed, &lt;tt class="docutils literal"&gt;optinterp3&lt;/tt&gt; is very fast: 3.9 seconds on &lt;tt class="docutils literal"&gt;mandelbrot&lt;/tt&gt;
and 1.97 seconds on &lt;tt class="docutils literal"&gt;factor&lt;/tt&gt;.&lt;/p&gt;
&lt;img alt="BF interpreter runtime plot with opt3" class="align-center" src="https://eli.thegreenplace.net/images/2017/bf-runtime-vs-opt3.png" /&gt;
&lt;p&gt;The overall speedup is dramatic. &lt;tt class="docutils literal"&gt;optinterp3&lt;/tt&gt; is almost 10x faster than
&lt;tt class="docutils literal"&gt;simpleinterp&lt;/tt&gt; on our benchmarks. While we could certainly make it even
faster, I think these optimizations are sufficient for our needs; let's talk
about what we can learn from them instead.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="on-compilers-bytecode-and-tracing-jits"&gt;
&lt;h2&gt;On compilers, bytecode and tracing JITs&lt;/h2&gt;
&lt;p&gt;It turns out there's a surprising amount of insight to be gained from the
exercise this post went through.&lt;/p&gt;
&lt;p&gt;First, let's start with the distinction between compilers and interpreters.
According &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Compiler"&gt;to Wikipedia&lt;/a&gt;, a compiler
is:&lt;/p&gt;
&lt;blockquote&gt;
a computer program (or a set of programs) that transforms source code written
in a programming language (the source language) into another computer
language (the target language), with the latter often having a binary form
known as object code.&lt;/blockquote&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;gcc&lt;/tt&gt; would be the canonical example of this: it transforms source code
written in C (or C++) into assembly language for, say, Intel CPUs. But there
are many other kinds of compilers: &lt;a class="reference external" href="https://www.call-cc.org/"&gt;Chicken&lt;/a&gt;
compiles Scheme into C; &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Rhino_(JavaScript_engine)"&gt;Rhino&lt;/a&gt;
compiles Javascript to JVM bytecode; the &lt;a class="reference external" href="https://clang.llvm.org/"&gt;Clang frontend&lt;/a&gt; compiles C++ to LLVM IR. CPython, the canonical
Python implementation compiles Python source code &lt;a class="reference external" href="https://eli.thegreenplace.net/2010/06/30/python-internals-adding-a-new-statement-to-python"&gt;to bytecode&lt;/a&gt;,
and so on. In general, the term &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Bytecode"&gt;Bytecode&lt;/a&gt; refers to any intermediate
representation / virtual instruction set designed for efficient interpretation.&lt;/p&gt;
&lt;p&gt;Based on this definition, while &lt;tt class="docutils literal"&gt;simpleinterp&lt;/tt&gt; is indeed just a BF
interpreter, the optimized interpreters described here are more like compilers +
bytecode interpreters. Consider &lt;tt class="docutils literal"&gt;optinterp3&lt;/tt&gt; for example. The source language
is BF; the target language is bytecode with the following instruction set:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;enum&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;BfOpKind&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;INVALID_OP&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;INC_PTR&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;DEC_PTR&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;INC_DATA&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;DEC_DATA&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;READ_STDIN&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;WRITE_STDOUT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;LOOP_SET_TO_ZERO&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;LOOP_MOVE_PTR&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;LOOP_MOVE_DATA&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;JUMP_IF_DATA_ZERO&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;JUMP_IF_DATA_NOT_ZERO&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;};&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;... where each instruction has a single argument. &lt;tt class="docutils literal"&gt;optinterp3&lt;/tt&gt; first
&lt;em&gt;compiles&lt;/em&gt; BF to this bytecode, and only then executes the bytecode. So if we
squint a bit, there's a JIT compiler here already - with the caveat that the
compilation target is not executable machine code but rather this specialized
bytecode. Worry not - we'll get to a &lt;em&gt;real&lt;/em&gt; JIT in the next part of the series.&lt;/p&gt;
&lt;p&gt;Finally, I'd like to point out that the loop optimizations performed in
&lt;tt class="docutils literal"&gt;optinterp3&lt;/tt&gt; are the static version of a &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Tracing_just-in-time_compilation"&gt;tracing JIT&lt;/a&gt;. We used
tracing to observe which loops occur most commonly in our benchmarks, and
optimized these loops. While the loops we optimized were very generic and surely
appear in most large BF programs, we could take it further. We could optimize
even more of the hottest loops, but with time we'd get into more specialized
paths in our particular benchmarks.&lt;/p&gt;
&lt;p&gt;To be fully generic, we'd have to defer this optimization to run-time, which is
what a tracing JIT does. A tracing JIT interprets code in the source language
and keeps track of the hottest loops (and for dynamic languages, of the &lt;em&gt;actual&lt;/em&gt;
run-time types of values flowing through the loops). When the same loop goes
over some threshold (say, invoked more than a million times) the loop is
optimized and compiled into efficient machine code.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="parting-words-for-part-1"&gt;
&lt;h2&gt;Parting words for part 1&lt;/h2&gt;
&lt;p&gt;In this post, we've seen an interpreter for BF being gradually refined from a
naive approach to a compile-to-optimized-bytecode approach, speeding it up 10x
in the process. Hopefully this provides a good feel for the source language, as
well as some of the tradeoffs involved in optimizing for it.&lt;/p&gt;
&lt;p&gt;In the next part of the series I'll present an actual JIT for BF - compiling BF
into tight x64 machine code and invoking it, all at run-time. I'll show how to
construct such a JIT compiler entirely from scratch (using nothing but the
standard system libraries) and also how to use assembly encoding libraries for
easier development. Stay tuned - it's going to be fun!&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;Links to all posts in this series:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-1-an-interpreter/"&gt;Part 1 - an interpreter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-2-an-x64-jit/"&gt;Part 2 - an x64 JIT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-3-llvm/"&gt;Part 3 - LLVM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-4-in-python/"&gt;Part 4 - Python&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr class="docutils" /&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-1" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;An observant reader will note I could have used a switch statement or
a lookup table here for more efficiency. I'm an avid adherent to the
&amp;quot;until you've measured it, it ain't slow&amp;quot; philosophy. The parsing stage
of BF takes negligible time for any realistic program, so it's hardly
important to optimize this part. On my machine, the largest BF program I
could find (Mandelbrot) is ~11,000 instructions and takes 360
&lt;em&gt;microseconds&lt;/em&gt; to parse, most of which is almost certainly dominated by
the file read time.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-2" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-2"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;p class="first"&gt;I'm using two different programs to prevent overfitting for one
particular benchmark. Naturally it would be more professional to use a
whole suite of benchmarks, but this is just a hobby blog post so let's
not overdo it B-)&lt;/p&gt;
&lt;p class="last"&gt;In fact, even real-world benchmark suites for large projects tend to be
&lt;a class="reference external" href="https://v8project.blogspot.com/2016/12/how-v8-measures-real-world-performance.html"&gt;poor approximations for the real world&lt;/a&gt;.&lt;/p&gt;
&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-3" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-3"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;p class="first"&gt;All the performance numbers for this series were collected on my Haswell
Linux (Ubuntu 14.04) box; the C++ code was compiled with the default gcc
4.8.4. I got slightly different results with Clang in some cases, but
this series is not about comparing host C++ compilers, so I'll just use
gcc throughout.&lt;/p&gt;
&lt;p class="last"&gt;It's also worth noting these execution times are end-to-end for the whole
binary and include loading the interpreter binary, reading the BF file,
doing any pre-processing / optimization / code emission and actually
running the benchmark. For any run time beyond ~100 ms, all
secondary factors are negligible compared to the actual benchmark
run-time (the time it took to execute the BF program at hand).&lt;/p&gt;
&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</content><category term="misc"></category><category term="Compilation"></category><category term="Code generation"></category></entry><entry><title>Some thoughts on LLVM vs. libjit</title><link href="https://eli.thegreenplace.net/2014/01/15/some-thoughts-on-llvm-vs-libjit" rel="alternate"></link><published>2014-01-15T05:49:56-08:00</published><updated>2023-02-04T13:41:52-08:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2014-01-15:/2014/01/15/some-thoughts-on-llvm-vs-libjit</id><summary type="html">
        &lt;p&gt;Having recently completed a &lt;a class="reference external" href="https://eli.thegreenplace.net/2014/01/07/getting-started-with-libjit-part-3/"&gt;series of articles&lt;/a&gt; on using libjit and understanding how it works, I couldn't stop comparing it to LLVM inside my head. This is hardly surprising, since LLVM has been a significant part of my professional life for the past 3.5 years, and will remain in â€¦&lt;/p&gt;</summary><content type="html">
        &lt;p&gt;Having recently completed a &lt;a class="reference external" href="https://eli.thegreenplace.net/2014/01/07/getting-started-with-libjit-part-3/"&gt;series of articles&lt;/a&gt; on using libjit and understanding how it works, I couldn't stop comparing it to LLVM inside my head. This is hardly surprising, since LLVM has been a significant part of my professional life for the past 3.5 years, and will remain in this position in the foreseeable future.&lt;/p&gt;
&lt;p&gt;So this post is some unfiltered thoughts on libjit and LLVM - what's similar, what's different, and which one is more suitable for new projects.&lt;/p&gt;
&lt;p&gt;First, a tiny bit of background. LLVM hardly needs introduction for the readers of my blog, but just for completeness - it was &lt;a class="reference external" href="http://llvm.org/releases/"&gt;first released&lt;/a&gt; in late 2003. However, according to Chris Lattner's (one of the creators of LLVM and its main developer for many years) recent presentation, the first ideas for it came together in 2000 and the first prototype was hacked together in early 2001.&lt;/p&gt;
&lt;p&gt;Today, LLVM is one of the most significant infrastructural backbones of modern computing, no less. It's the default compiler for the OS X and iOS platforms (FreeBSD is deprecating gcc in favor of LLVM &amp;amp; Clang too), and is heavily used in production by almost all major software companies. New things pop up all the time, like the (Windows-based, mind you) toolchain of the new Sony PS4 being completely built on top of LLVM.&lt;/p&gt;
&lt;p&gt;libjit's first release was &lt;a class="reference external" href="http://www.dotgnu.org/"&gt;in April 2004&lt;/a&gt;, as part of the now-defunct DotGNU project. This was a much less complete release than LLVM 1.0, though (version 0.0.0f - doesn't sound very reassuring for running your nuclear reactor, does it?). Its goals, from the beginning, were quite similar to LLVM's, if somewhat more modest. It also aimed to provide the backend of a compiler from a target-independent IR.&lt;/p&gt;
&lt;p&gt;Some internet archaeology brought up &lt;a class="reference external" href="http://lists.gnu.org/archive/html/dotgnu-libjit/2004-05/msg00012.html"&gt;this fascinating mailing list thread&lt;/a&gt; from May 2004, in which Chris Lattner asks Rhys Weatherley (the creator of libjit) whether the two projects can &amp;quot;join forces&amp;quot;, since their goals are similar. If you have any interest in open-source, you can't miss this discussion - go read it now. After a few weak justification attempts, Chris and Rhys got to the real issue. In open-source, people often start new projects &lt;em&gt;just because it's fun&lt;/em&gt;, as well as &lt;em&gt;to retain complete control&lt;/em&gt;. There may be an existing project that does something similar. The effort to use this existing project is, in all likeness, smaller than the effort to roll your own. But what would you prefer - spending time adapting a large body of existing code you didn't write (and whose brace style you hate!) to your needs and quibbling over methodology on mailing lists, or gloriously hacking into the night - your fingers burning holes in the keyboard producing new code? Especially when this isn't a &amp;quot;day job&amp;quot;, but something you do for fun... Yeah, I thought so. Joel's &lt;a class="reference external" href="http://www.joelonsoftware.com/articles/fog0000000007.html"&gt;In Defense of the NIH syndrome&lt;/a&gt; is a classic now (it's 13 years old, oh my) but it rings as true, and possibly truer, for open-source as for the corporate setting Joel first aimed it at.&lt;/p&gt;
&lt;p&gt;But I digress... The short version of the paragraph above is that libjit and LLVM really do have similar goals, and if the mood of their overlords had been different on a few pleasant spring nights of 2004, we could've had just a single project today; that would, in all likeness, be LLVM. Could this also help the DotGNU project on the whole, which lost more and more steam over the years until its official abandonment in 2012? Who knows... If you have a time machine, let me know please.&lt;/p&gt;
&lt;p&gt;But lo and behold - libjit is still alive today. It seems to live in a state of life support because there's not too much active development going on, but it's definitely not dead. Its current maintainer is fairly responsive and seems keen to fix things, including documentation.&lt;/p&gt;
&lt;p&gt;As I mentioned, libjit's initial goals were much less ambitious than LLVM's, and it remained so. LLVM's philosophy of &amp;quot;everything is a pluggable library&amp;quot; kept driving its development, and if you look at LLVM today - everything is indeed quite pluggable, including newer parts like MC. LLVM supports pluggability in its very core. The so called mid-level IR infrastructure (arguably LLVM's best-designed part) is pluggability executed to perfection. You write generic passes that analyze and transform IR, and hook them together in any way you see fit (along with dozens of industrial-strength compilation passes already provided by LLVM). But the backend parts too: you can choose from more than one instruction selector (or write your own), multiple register allocators, schedulers, code emitters, assemblers, and so on.&lt;/p&gt;
&lt;p&gt;libjit is not like that. While it was designed to be able to emit code for multiple architectures (it has both flavors of x86, some experimental ARM support as well as old &amp;quot;attic&amp;quot; code for Alpha), its internals are not modular; sure, you can add more optimizations (or a different register allocator) to libjit, but you'll have to hack it into libjit itself - the requisite APIs and data structures are not really exposed on the library level, the way they are with LLVM.&lt;/p&gt;
&lt;p&gt;The libjit IR is also somewhat more limited, having been designed with a single front-end in mind (DotGNU). True, the designer aimed to make it fairly abstract, but some things are definitely missing compared to LLVM, which has been shape by years of use in multiple different front-ends. For example, the type system of libjit is far less flexible, supporting only a subset of integer and floating-point types (like &lt;tt class="docutils literal"&gt;int32&lt;/tt&gt;, not the arbitrary LLVM jungle of &lt;tt class="docutils literal"&gt;int73&lt;/tt&gt; if you want it).&lt;/p&gt;
&lt;p&gt;But generality comes at a cost: LLVM is both relatively slow and its code is relatively difficult to grok. It's not slow for a regular (AOT - Ahead of Time) compiler, but it &lt;em&gt;is&lt;/em&gt; slow for a JIT compiler, a common source of pain for some LLVM users.&lt;/p&gt;
&lt;p&gt;Now, a disclaimer: I did not benchmark libjit's compilation speed vs. LLVM; I was simply too lazy to generate equivalent and large-enough inputs for both. I'm also not saying that libjit is faster than LLVM, perhaps it isn't. After all, the amount of engineering power expended on LLVM has been orders of magnitude larger than for libjit, which may very well have led to much more optimized code. All I want to imply here is that libjit &lt;em&gt;could&lt;/em&gt; be faster than LLVM. Generality is almost always at odds with performance in software, a sad fact we all wish wasn't true but, oh, it is. Is this very important? Not for most uses of LLVM today, but since libjit's main goal is JIT, then perhaps. But without real measurements and profiling, I don't have anything intelligent to contribute here.&lt;/p&gt;
&lt;p&gt;libjit is also much simpler to understand. I've spent enough time with LLVM to appreciate its complexity, as well as see &lt;a class="reference external" href="http://stackoverflow.com/questions/tagged/llvm"&gt;how confused many programmers are about it&lt;/a&gt;. libjit was dramatically easier to grok for me. This may have two reasons: one is definitely its significantly smaller size and simpler internal structure. There is simply much less code to read, and much less abstraction levels to keep in the head. The other reason is my (sometimes controversial) opinion about the choice of programming language. libjit is written in C, which IMHO is easier to understand than C++. But that's a whole other issue, unrelated to this post (you know where to find me for your hatemail).&lt;/p&gt;
&lt;p&gt;There's another significant difference between LLVM and libjit. LLVM, despite the historical meaning of its acronym and the numerous attempts that have been made over the years to make it work for dynamic languages, is still in its core a backend for compiling static languages like C, C++ and Objective C. By this, I mean languages that don't really have a significant runtime, like Java or C#. libjit, on the other hand, was designed to serve as a backend for a .NET implementation. That said, like the rest of libjit, these parts are not really battle-proven, so it's hard to attest to their completeness and stability.&lt;/p&gt;
&lt;p&gt;So, which one should you use or learn? As for use, there's no question; LLVM is an industrial strength, heavily tested and verified system. It's being used daily on millions (maybe billions) of devices; it's being hacked on by hundreds of programmers from dozens of companies. If it fits your needs, LLVM is the way to go. And these days it fits most needs. Not all of them, mind you. For example, as I've already mentioned above, LLVM is not great for fast JIT-ing. And to be honest, I don't think it's possible to create a really fast JIT within the framework of LLVM, &lt;em&gt;because&lt;/em&gt; of its modularity. The faster the JIT, the more you'll have to deviate from the framework of LLVM. This is a serious problem for &lt;a class="reference external" href="http://blog.chromium.org/2013/11/portable-native-client-pinnacle-of.html"&gt;Portable Native Client&lt;/a&gt;, for instance.&lt;/p&gt;
&lt;p&gt;libjit, on the other hand, is much more limited, aimed at dynamic runtimes and can (potentially) JIT-compile faster. It's also not being used too much, and lacks credibility w.r.t. features and stability. libjit itself only comes with toy examples - not very reassuring if you want to bet your future project on it.&lt;/p&gt;
&lt;p&gt;In terms of educational value, libjit is great. If you want to learn about compiler backends, I would definitely start with libjit and only move to LLVM later. I hope my &lt;a class="reference external" href="https://eli.thegreenplace.net/2014/01/07/getting-started-with-libjit-part-3/"&gt;series of articles&lt;/a&gt; will be useful here.&lt;/p&gt;

    </content><category term="misc"></category><category term="Code generation"></category><category term="Compilation"></category></entry><entry><title>Getting started with libjit - part 3</title><link href="https://eli.thegreenplace.net/2014/01/07/getting-started-with-libjit-part-3" rel="alternate"></link><published>2014-01-07T06:00:59-08:00</published><updated>2023-06-30T23:16:27-07:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2014-01-07:/2014/01/07/getting-started-with-libjit-part-3</id><summary type="html">
        &lt;p&gt;This is part 3 in a series of articles on libjit. &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/10/17/getting-started-with-libjit-part-1/"&gt;Part 1&lt;/a&gt; served as a basic introduction to the library and showed how to get started, along with some simple performance measurements. &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/11/12/getting-started-with-libjit-part-2/"&gt;Part 2&lt;/a&gt; peered deeper into the capabilities of libjit, focusing on interface between native and JITed code â€¦&lt;/p&gt;</summary><content type="html">
        &lt;p&gt;This is part 3 in a series of articles on libjit. &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/10/17/getting-started-with-libjit-part-1/"&gt;Part 1&lt;/a&gt; served as a basic introduction to the library and showed how to get started, along with some simple performance measurements. &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/11/12/getting-started-with-libjit-part-2/"&gt;Part 2&lt;/a&gt; peered deeper into the capabilities of libjit, focusing on interface between native and JITed code. In this part, I'm switching gears and looking at the internals of libjit. I'll follow through the compilation of a simple function with libjit, highlighting some interesting aspects of libjit's design on the way.&lt;/p&gt;
&lt;div class="section" id="input-code"&gt;
&lt;h3&gt;Input code&lt;/h3&gt;
&lt;p&gt;I'll reuse the iterative GCD example from part 1. The equivalent C code is:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt; &lt;span style="color: #00007f"&gt;gcd_iter&lt;/span&gt;(&lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt; u, &lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt; v) {
  &lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt; t;
  &lt;span style="color: #00007f; font-weight: bold"&gt;while&lt;/span&gt; (v) {
    t = u;
    u = v;
    v = t % v;
  }
  &lt;span style="color: #00007f; font-weight: bold"&gt;return&lt;/span&gt; u &amp;lt; &lt;span style="color: #007f7f"&gt;0&lt;/span&gt; ? -u : u; &lt;span style="color: #007f00"&gt;/* abs(u) */&lt;/span&gt;
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Take a look at &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/10/17/getting-started-with-libjit-part-1/"&gt;part 1&lt;/a&gt; (or the &lt;tt class="docutils literal"&gt;gcd_iter.c&lt;/tt&gt; sample in &lt;a class="reference external" href="https://github.com/eliben/libjit-samples"&gt;the repository&lt;/a&gt;) for details on the libjit calls required to emulate this function.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="libjit-ir"&gt;
&lt;h3&gt;libjit IR&lt;/h3&gt;
&lt;p&gt;The libjit API includes &lt;tt class="docutils literal"&gt;jit_dump_function&lt;/tt&gt;, which can dump the contents of a &lt;tt class="docutils literal"&gt;jit_function_t&lt;/tt&gt; for us. It has two modes of operation. Before the function is compiled to native code, the libjit IR will be dumped. If the function has already been compiled (with &lt;tt class="docutils literal"&gt;jit_function_compile&lt;/tt&gt;), the produced machine code is disassembled &lt;a class="footnote-reference" href="#id7" id="id2"&gt;[1]&lt;/a&gt; and the assembly is dumped. In this article we'll be looking at both dumps, starting with the &amp;quot;uncompiled&amp;quot; libjit IR.&lt;/p&gt;
&lt;p&gt;Before I show the IR dump, a short introduction to how libjit does things. Internally, the IR is divided into &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Basic_block"&gt;basic blocks&lt;/a&gt;, which is a convenient abstraction often used by compilers to represent intermediate code. Basic blocks may serve as targets of braches (&lt;tt class="docutils literal"&gt;goto&lt;/tt&gt; instructions in libjit IR); therefore, each may have one or more labels referring to it. The libjit API has functions that explicitly create basic blocks, but the functions I used do so implicitly. This is more convenient. For example, &lt;tt class="docutils literal"&gt;jit_insn_branch_if&lt;/tt&gt; both ends the current basic block (because it's an exit point) and may create an additional basic block at its destination (unless it already exists).&lt;/p&gt;
&lt;p&gt;Another thing to note is that while C code that uses the libjit API has named variables for values and labels, libjit is oblivious to it. Unlike LLVM, libjit does not have a way to give meaningful names to values and labels, so it just generates numbered names. However, even so the correspondence between libjit API calls and the IR is very obvious and easy to follow, as the following annotated dump shows. I'm using some of the nomenclature (such as label names) from the API calls in the comments to help pinpoint the correspondence between them.&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #00007f; font-weight: bold"&gt;function&lt;/span&gt; gcd [uncompiled](i1 : &lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt;, i2 : &lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt;) : &lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt;
      &lt;span style="color: #007f00"&gt;// Note that some ABI details are exposed here. This is built on&lt;/span&gt;
      &lt;span style="color: #007f00"&gt;// a x64 Linux machine, where the first two integer arguments to&lt;/span&gt;
      &lt;span style="color: #007f00"&gt;// a function are passed in rdi and rsi&lt;/span&gt;
      incoming_reg(i1, rdi)
      incoming_reg(i2, rsi)
      &lt;span style="color: #007f00"&gt;// label_while:&lt;/span&gt;
.L0:
      &lt;span style="color: #007f00"&gt;// if (v == 0) goto label_after_while&lt;/span&gt;
      &lt;span style="color: #007f00"&gt;// libjit folds a comparison instruction into a branch - hence it&lt;/span&gt;
      &lt;span style="color: #007f00"&gt;// seems that i7 is not necessary and can be optimized away as&lt;/span&gt;
      &lt;span style="color: #007f00"&gt;// dead code&lt;/span&gt;
      i7 = i2 == &lt;span style="color: #007f7f"&gt;0&lt;/span&gt;
      &lt;span style="color: #00007f; font-weight: bold"&gt;if&lt;/span&gt; i2 == &lt;span style="color: #007f7f"&gt;0&lt;/span&gt; then &lt;span style="color: #00007f; font-weight: bold"&gt;goto&lt;/span&gt; .L1
.L:
      &lt;span style="color: #007f00"&gt;// t &amp;lt;- u&lt;/span&gt;
      i5 = i1
      &lt;span style="color: #007f00"&gt;// u &amp;lt;- v&lt;/span&gt;
      i1 = i2
      &lt;span style="color: #007f00"&gt;// v &amp;lt;- t % v via a temporary&lt;/span&gt;
      i8 = i5 % i2
      i2 = i8 i7 = i2 == &lt;span style="color: #007f7f"&gt;0&lt;/span&gt;
      &lt;span style="color: #00007f; font-weight: bold"&gt;if&lt;/span&gt; i2 == &lt;span style="color: #007f7f"&gt;0&lt;/span&gt; then &lt;span style="color: #00007f; font-weight: bold"&gt;goto&lt;/span&gt; .L2

      &lt;span style="color: #007f00"&gt;// goto label_while&lt;/span&gt;
      &lt;span style="color: #00007f; font-weight: bold"&gt;goto&lt;/span&gt; .L0
      &lt;span style="color: #007f00"&gt;// ends_in_dead is a marker libjit places on blocks that don&amp;#39;t&lt;/span&gt;
      &lt;span style="color: #007f00"&gt;// have a fall-through edge. These are blocks that end with&lt;/span&gt;
      &lt;span style="color: #007f00"&gt;// unconditional branches, returns, etc.&lt;/span&gt;
      ends_in_dead
.L1:
      i9 = i1 &amp;gt;= &lt;span style="color: #007f7f"&gt;0&lt;/span&gt;
      &lt;span style="color: #007f00"&gt;// if (u &amp;gt;= 0) then goto label_pos&lt;/span&gt;
      &lt;span style="color: #00007f; font-weight: bold"&gt;if&lt;/span&gt; i1 &amp;gt;= &lt;span style="color: #007f7f"&gt;0&lt;/span&gt; then &lt;span style="color: #00007f; font-weight: bold"&gt;goto&lt;/span&gt; .L2
.L:
      &lt;span style="color: #007f00"&gt;// return -u&lt;/span&gt;
      i10 = -i1
      return_int(i10)
      ends_in_dead
.L2:
      &lt;span style="color: #007f00"&gt;// label_pos: return u&lt;/span&gt;
      return_int(i1)
      ends_in_dead
.L:
.L:
end
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The most important thing to remember about this IR dump is that it's very closely parallel to the libjit API calls used to create it. In this respect, libjit is very much like LLVM: the IR is directly created by the builder API. An important difference is that unlike LLVM, where a textual representation of the IR is a language that can be used for full serialization (and even directly programmed in), in the case of libjit no such representation exists. The above is just a dump for debugging purposes.&lt;/p&gt;
&lt;p&gt;I still think it's pretty useful for verifying that the code created by the API calls makes sense. While less important when the API calls are made manually, as they were here, it becomes crucial when the calls are generated programmatically - such as by a front-end that compiles some language to libjit.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="from-libjit-ir-to-machine-code"&gt;
&lt;h3&gt;From libjit IR to machine code&lt;/h3&gt;
&lt;p&gt;Now it's time to examine the machine code produced by libjit for &lt;tt class="docutils literal"&gt;gcd_iter&lt;/tt&gt; on my x64 machine. The following is an annotated disassembly dump, which I'll then use as a springboard to dive into some of the internal workings of libjit.&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;                  &lt;span style="color: #007f00"&gt;// Prologue&lt;/span&gt;
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f940058713f:     push   %rbp
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f9400587140:     mov    %rsp,%rbp
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f9400587143:     sub    $0x20,%rsp
                  &lt;span style="color: #007f00"&gt;// r14 and r15 are callee-saved; save them since&lt;/span&gt;
                  &lt;span style="color: #007f00"&gt;// we&amp;#39;ll use them&lt;/span&gt;
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f9400587147:     mov    %r14,(%rsp)
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f940058714b:     mov    %r15,&lt;span style="color: #007f7f"&gt;0x8&lt;/span&gt;(%rsp)
                  &lt;span style="color: #007f00"&gt;// rdi holds u, rsi holds v. Put them in r15 and r14&lt;/span&gt;
                  &lt;span style="color: #007f00"&gt;// respectively&lt;/span&gt;
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f9400587150:     mov    %rdi,%r15
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f9400587153:     mov    %rsi,%r14

                  &lt;span style="color: #007f00"&gt;// label_while:&lt;/span&gt;
                  &lt;span style="color: #007f00"&gt;// if (v == 0) goto after_while&lt;/span&gt;
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f9400587156:     test   %r14d,%r14d
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f9400587159:     je     &lt;span style="color: #007f7f"&gt;0x7f94005871ab&lt;/span&gt;

                  &lt;span style="color: #007f00"&gt;// .. otherwise&lt;/span&gt;
                  &lt;span style="color: #007f00"&gt;// t &amp;lt;- u&lt;/span&gt;
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f940058715f:     mov    %r15d,%eax
                  &lt;span style="color: #007f00"&gt;// u &amp;lt;- v&lt;/span&gt;
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f9400587162:     mov    %r14d,%r15d
                  &lt;span style="color: #007f00"&gt;// save t on the stack&lt;/span&gt;
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f9400587165:     mov    %eax,-&lt;span style="color: #007f7f"&gt;0x8&lt;/span&gt;(%rbp)
                  &lt;span style="color: #007f00"&gt;// if (v != 0) goto v_nonzero&lt;/span&gt;
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f9400587168:     test   %r14d,%r14d
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f940058716b:     jne    &lt;span style="color: #007f7f"&gt;0x7f9400587181&lt;/span&gt;

                  &lt;span style="color: #007f00"&gt;// .. otherwise call&lt;/span&gt;
                  &lt;span style="color: #007f00"&gt;// jit_exception_builtin(JIT_RESULT_DIVISION_BY_ZERO)&lt;/span&gt;
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f940058716d:     mov    $0xfffffffe,%edi
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f9400587172:     mov    $0x8,%eax
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f9400587177:     mov    $0x4060ea,%r11
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f940058717e:     callq  *%r11

                  &lt;span style="color: #007f00"&gt;// v_nonzero:&lt;/span&gt;
                  &lt;span style="color: #007f00"&gt;// if (v != -1) godo ready_for_rem&lt;/span&gt;
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f9400587181:     cmp    $0xffffffff,%r14d
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f9400587185:     jne    &lt;span style="color: #007f7f"&gt;0x7f94005871a2&lt;/span&gt;

                  &lt;span style="color: #007f00"&gt;// .. otherwise&lt;/span&gt;
                  &lt;span style="color: #007f00"&gt;// if (t != -2**32) goto ready_for_rem&lt;/span&gt;
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f9400587187:     cmp    $0x80000000,%eax
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f940058718c:     jne    &lt;span style="color: #007f7f"&gt;0x7f94005871a2&lt;/span&gt;

                  &lt;span style="color: #007f00"&gt;// .. otherwise call&lt;/span&gt;
                  &lt;span style="color: #007f00"&gt;// jit_exception_builtin(JIT_RESULT_ARITHMETIC)&lt;/span&gt;
                  &lt;span style="color: #007f00"&gt;// Because a minimum signed number is divided by -1;&lt;/span&gt;
                  &lt;span style="color: #007f00"&gt;// the quotient is then an arithmetic overflow.&lt;/span&gt;
                  &lt;span style="color: #007f00"&gt;// [-2^32 is representable in 2s complement 32-bit, but&lt;/span&gt;
                  &lt;span style="color: #007f00"&gt;//  not 2^32]&lt;/span&gt;
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f940058718e:     mov    $0xffffffff,%edi
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f9400587193:     mov    $0x8,%eax
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f9400587198:     mov    $0x4060ea,%r11
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f940058719f:     callq  *%r11

                  &lt;span style="color: #007f00"&gt;// ready_for_rem:&lt;/span&gt;
                  &lt;span style="color: #007f00"&gt;// sign-extend t (eax) into (edx) for division and&lt;/span&gt;
                  &lt;span style="color: #007f00"&gt;// perform signed division. Remainder is in rdx,&lt;/span&gt;
                  &lt;span style="color: #007f00"&gt;// which is moved to r14, so v &amp;lt;- t % u&lt;/span&gt;
                  &lt;span style="color: #007f00"&gt;// then goto label_while&lt;/span&gt;
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f94005871a2:     cltd
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f94005871a3:     idiv   %r14d
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f94005871a6:     mov    %rdx,%r14
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f94005871a9:     jmp    &lt;span style="color: #007f7f"&gt;0x7f9400587156&lt;/span&gt;

                  &lt;span style="color: #007f00"&gt;// after_while:&lt;/span&gt;
                  &lt;span style="color: #007f00"&gt;// if (u &amp;gt;= 0) goto u_nonnegative&lt;/span&gt;
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f94005871ab:     test   %r15d,%r15d
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f94005871ae:     jge    &lt;span style="color: #007f7f"&gt;0x7f94005871be&lt;/span&gt;

                  &lt;span style="color: #007f00"&gt;// ... otherwise place u into the return register&lt;/span&gt;
                  &lt;span style="color: #007f00"&gt;// and negate it, then goto epilogue&lt;/span&gt;
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f94005871b4:     mov    %r15d,%eax
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f94005871b7:     neg    %eax
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f94005871b9:     jmpq   &lt;span style="color: #007f7f"&gt;0x7f94005871c1&lt;/span&gt;

                  &lt;span style="color: #007f00"&gt;// u_nonnegative:&lt;/span&gt;
                  &lt;span style="color: #007f00"&gt;// Place u into the return register rax&lt;/span&gt;
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f94005871be:     mov    %r15d,%eax

                  &lt;span style="color: #007f00"&gt;// epilogue:&lt;/span&gt;
                  &lt;span style="color: #007f00"&gt;// Restore saved regs &amp;amp; epilogue&lt;/span&gt;
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f94005871c1:     mov    (%rsp),%r14
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f94005871c5:     mov    &lt;span style="color: #007f7f"&gt;0x8&lt;/span&gt;(%rsp),%r15
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f94005871ca:     mov    %rbp,%rsp
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f94005871cd:     pop    %rbp
&lt;span style="color: #007f7f"&gt;7&lt;/span&gt;f94005871ce:     retq
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;While in general the control flow here is very similar to the IR version and hence easy to understand, there's a bunch of error checking going on before the remainder operation is performed, and this complicates matters. libjit turns out to be very meticulous about arithmetic errors and implants runtime checks against two situations that are undefined by the C standard.&lt;/p&gt;
&lt;p&gt;The easier one is division by zero. When &lt;tt class="docutils literal"&gt;v&lt;/tt&gt; is zero, the operation &lt;tt class="docutils literal"&gt;t % v&lt;/tt&gt; has undefined behavior. libjit inserts a runtime check comparing the divisor to zero and calling an exception function &lt;a class="footnote-reference" href="#id8" id="id3"&gt;[2]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The more complex error case arises in division by -1. Since integers are represented in 2s complement, there is a single negative number (-2^32 for 32-bit &lt;tt class="docutils literal"&gt;int&lt;/tt&gt;s) that does not have a positive mirror. If this negative number is divided by -1, the result is arithmetic overflow, which is also undefined behavior. Here again, libjit inserts the requisite runtime checks that ensure this case gets caught and properly reported &lt;a class="footnote-reference" href="#id10" id="id4"&gt;[3]&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="instruction-selection"&gt;
&lt;h3&gt;Instruction selection&lt;/h3&gt;
&lt;p&gt;The code generated for the remainder operation is a great opportunity to peer into the innards of libjit. What defines such complex behavior - generating a whole code sequence with multiple checks and calls, for a single operation? After all, on the libjit IR level, the remainder is just the &lt;tt class="docutils literal"&gt;%&lt;/tt&gt; operator.&lt;/p&gt;
&lt;p&gt;The following is a fast paced quest through the source code of libjit. Code references are typically made to function names and files relative to the root directory of a libjit source snapshot.&lt;/p&gt;
&lt;p&gt;We'll start by looking into &lt;tt class="docutils literal"&gt;jit_insn_rem&lt;/tt&gt;, which creates the remainder operation. Together with the other instruction creation APIs of libjit, this function lives in &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;jit/jit-insn.c&lt;/span&gt;&lt;/tt&gt;. &lt;tt class="docutils literal"&gt;jit_insn_rem&lt;/tt&gt; adds an &lt;em&gt;instruction description entry&lt;/em&gt; to the function - an instance of the &lt;tt class="docutils literal"&gt;jit_opcode_descr&lt;/tt&gt; structure.&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;jit_value_t &lt;span style="color: #00007f"&gt;jit_insn_rem&lt;/span&gt;
              (jit_function_t func, jit_value_t value1, jit_value_t value2)
{
      &lt;span style="color: #00007f; font-weight: bold"&gt;static&lt;/span&gt; jit_opcode_descr &lt;span style="color: #00007f; font-weight: bold"&gt;const&lt;/span&gt; rem_descr = {
              JIT_OP_IREM,
              JIT_OP_IREM_UN,
              JIT_OP_LREM,
              JIT_OP_LREM_UN,
              JIT_OP_FREM,
              JIT_OP_DREM,
              JIT_OP_NFREM,
              jit_intrinsic(jit_int_rem, descr_e_pi_ii),
              jit_intrinsic(jit_uint_rem, descr_e_pI_II),
              jit_intrinsic(jit_long_rem, descr_e_pl_ll),
              jit_intrinsic(jit_ulong_rem, descr_e_pL_LL),
              jit_intrinsic(jit_float32_rem, descr_f_ff),
              jit_intrinsic(jit_float64_rem, descr_d_dd),
              jit_intrinsic(jit_nfloat_rem, descr_D_DD)
      };
      &lt;span style="color: #00007f; font-weight: bold"&gt;return&lt;/span&gt; apply_arith(func, &amp;amp;rem_descr, value1, value2, &lt;span style="color: #007f7f"&gt;0&lt;/span&gt;, &lt;span style="color: #007f7f"&gt;0&lt;/span&gt;, &lt;span style="color: #007f7f"&gt;0&lt;/span&gt;);
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The most interesting part of this entry for us at this point is the opcode; &lt;tt class="docutils literal"&gt;JIT_OP_IREM&lt;/tt&gt; is the signed integer remainder opcode.&lt;/p&gt;
&lt;p&gt;There are many entries in the &lt;tt class="docutils literal"&gt;jit_opcode_descr&lt;/tt&gt; structure - per type of operands. Some of the entries are filled with intrinsics rather than opcodes, because libjit needs an intrinsic for architectures on which the opcode is not supported natively.&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;jit_function_compile&lt;/tt&gt; initiates the IR -&amp;gt; native compilation sequence in libjit. You can trace it through in the libjit code - the code is quite easy to follow. Eventually &lt;tt class="docutils literal"&gt;compile_block&lt;/tt&gt;, which is responsible for generating code for a single basic block, calls &lt;tt class="docutils literal"&gt;_jit_gen_insn&lt;/tt&gt; per instruction. This is the point when libjit switches from a target-independent code generation algorithm to a target-specific backend, that knows how to lower libjit IR instructions to actual native instructions. This part has to be implemented per backend (target architecture). I'll follow through the flow of the x86-64 backend. The meat of &lt;tt class="docutils literal"&gt;_jit_gen_insn&lt;/tt&gt; in &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;jit/jit-rules-x86-64.c&lt;/span&gt;&lt;/tt&gt; is:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #00007f; font-weight: bold"&gt;switch&lt;/span&gt;(insn-&amp;gt;opcode)
{
&lt;span style="color: #007f00"&gt;#define JIT_INCLUDE_RULES&lt;/span&gt;
&lt;span style="color: #007f00"&gt;#include &amp;quot;jit-rules-x86-64.inc&amp;quot;&lt;/span&gt;
&lt;span style="color: #007f00"&gt;#undef JIT_INCLUDE_RULES&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;.inc&lt;/tt&gt; file being included into the &lt;tt class="docutils literal"&gt;switch&lt;/tt&gt; statement is auto-generated in libjit from a corresponding &lt;tt class="docutils literal"&gt;.ins&lt;/tt&gt; file &lt;a class="footnote-reference" href="#id11" id="id5"&gt;[4]&lt;/a&gt;. The &lt;tt class="docutils literal"&gt;.ins&lt;/tt&gt; file is an instruction selector, written in a libjit-specific DSL. It contains &amp;quot;rules&amp;quot; for generating code per IR opcode. Before we look at the complex remainder opcode, let's start with something simpler to get a feel for how the thing works:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;JIT_OP_PUSH_INT: note
      [imm] -&amp;gt; {
        x86_64_push_imm(inst, $1);
        gen-&amp;gt;stack_changed = 1;
      }
      [local] -&amp;gt; {
        x86_64_push_membase_size(inst, X86_64_RBP, $1, 4);
        gen-&amp;gt;stack_changed = 1;
      }
      [reg] -&amp;gt; {
        x86_64_push_reg_size(inst, $1, 4);
        gen-&amp;gt;stack_changed = 1;
      }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This rule tells the code generator how to handle the &lt;tt class="docutils literal"&gt;JIT_OP_PUSH_INT&lt;/tt&gt; (push an integer onto the stack) opcode for x86-64. Notice that there are separate rules based on whether the argument of the opcode is an immediate, a reference to a label or a register. For example, when it's a register, the rule says to call &lt;tt class="docutils literal"&gt;x86_64_push_reg_size&lt;/tt&gt;. This is a macro defined thus:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #007f00"&gt;#define x86_64_push_reg_size(inst, reg, size) \&lt;/span&gt;
&lt;span style="color: #007f00"&gt;      do { \&lt;/span&gt;
&lt;span style="color: #007f00"&gt;              if((size) == 2) \&lt;/span&gt;
&lt;span style="color: #007f00"&gt;              { \&lt;/span&gt;
&lt;span style="color: #007f00"&gt;                      *(inst)++ = (unsigned char)0x66; \&lt;/span&gt;
&lt;span style="color: #007f00"&gt;              } \&lt;/span&gt;
&lt;span style="color: #007f00"&gt;              x86_64_rex_emit64((inst), (size), 0, 0, (reg)); \&lt;/span&gt;
&lt;span style="color: #007f00"&gt;              *(inst)++ = (unsigned char)0x50 + ((reg) &amp;amp; 0x7); \&lt;/span&gt;
&lt;span style="color: #007f00"&gt;      } while(0)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;At this point, if you really want to verify this, it's time to look into the Intel Architecture Manual, volume 2 (the instruction set reference). Enjoy :-)&lt;/p&gt;
&lt;p&gt;Now, back to our remainder. &lt;tt class="docutils literal"&gt;JIT_OP_IREM&lt;/tt&gt; has the following entry:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;JIT_OP_IREM: more_space
      [any, immzero] -&amp;gt; {
        inst = throw_builtin(inst, func, JIT_RESULT_DIVISION_BY_ZERO);
      }
      [reg, imm, if(&amp;quot;$2 == 1&amp;quot;)] -&amp;gt; {
        x86_64_clear_reg(inst, $1);
      }
      [reg, imm, if(&amp;quot;$2 == -1&amp;quot;)] -&amp;gt; {
        /* Dividing by -1 gives an exception if the argument
           is minint, or simply gives a remainder of zero */
        jit_int min_int = jit_min_int;
        unsigned char *patch;
        x86_64_cmp_reg_imm_size(inst, $1, min_int, 4);
        patch = inst;
        x86_branch8(inst, X86_CC_NE, 0, 0);
        inst = throw_builtin(inst, func, JIT_RESULT_ARITHMETIC);
        x86_patch(patch, inst);
        x86_64_clear_reg(inst, $1);
      }
      [=reg(&amp;quot;rdx&amp;quot;), *reg(&amp;quot;rax&amp;quot;), imm, scratch dreg, scratch reg(&amp;quot;rdx&amp;quot;)] -&amp;gt; {
        x86_64_mov_reg_imm_size(inst, $4, $3, 4);
        x86_64_cdq(inst);
        x86_64_idiv_reg_size(inst, $4, 4);
      }
      [=reg(&amp;quot;rdx&amp;quot;), *reg(&amp;quot;rax&amp;quot;), dreg, scratch reg(&amp;quot;rdx&amp;quot;)] -&amp;gt; {
        jit_int min_int = jit_min_int;
        unsigned char *patch, *patch2;
#ifndef JIT_USE_SIGNALS
        x86_64_test_reg_reg_size(inst, $3, $3, 4);
        patch = inst;
        x86_branch8(inst, X86_CC_NE, 0, 0);
        inst = throw_builtin(inst, func, JIT_RESULT_DIVISION_BY_ZERO);
        x86_patch(patch, in have ast);
#endif
        x86_64_cmp_reg_imm_size(inst, $3, -1, 4); part 2
        patch = inst;
        x86_branch8(inst, X86_CC_NE, 0, 0);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It's kind-of long, but most of it describes some special cases when one of the operands is constant. For example, the second code block describes the case where the divisor is a constant 1. In this case, the remainder is always 0 so the target register is just cleared. The most interesting case is the most general one - the last, where division is done between two registers. In this case, you'll see that the rule is just a template for generate code - it's very similar to the machine code we've seen in the disassembly above. It checks for a zero divisor, and then for arithmetic error. Macros are used to actually generate the machine code, as demonstrated above with &lt;tt class="docutils literal"&gt;x86_64_push_reg_size&lt;/tt&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="liveness-analysis-and-register-allocation"&gt;
&lt;h3&gt;Liveness analysis and register allocation&lt;/h3&gt;
&lt;p&gt;Another important mechanism in libjit I want to take a look at is liveness analysis (together with related target-independent optimizations) and register allocation. Since covering these topics in detail would require a book or two, I'll only skim through them on a high level, trusting the reader has some knowledge of compiler backends (or at least the will to dive deeper wherever necessary).&lt;/p&gt;
&lt;p&gt;libjit's rule-based code generation machinery already knows which registers values live in. A brief look at the machine code it generates immediately suggests that some sort of register allocation happened - there are almost no unnecessary stack spills. This happens in the &lt;tt class="docutils literal"&gt;codegen_prepare&lt;/tt&gt; function, which runs liveness analysis followed by register allocation.&lt;/p&gt;
&lt;p&gt;The liveness analysis done by libjit seems pretty standard. It places its results in the &lt;tt class="docutils literal"&gt;flags&lt;/tt&gt; field of each instruction. It also runs some simple optimizations - forward and backward copy propagations. For example, recall that in the IR we had:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;.L0:
      &lt;span style="color: #007f00"&gt;// if (v == 0) goto label_after_while&lt;/span&gt;
      &lt;span style="color: #007f00"&gt;// libjit folds a comparison instruction into a branch - hence it&lt;/span&gt;
      &lt;span style="color: #007f00"&gt;// seems that i7 is not necessary and can be optimized away as&lt;/span&gt;
      &lt;span style="color: #007f00"&gt;// dead code&lt;/span&gt;
    i7 = i2 == &lt;span style="color: #007f7f"&gt;0&lt;/span&gt;
    &lt;span style="color: #00007f; font-weight: bold"&gt;if&lt;/span&gt; i2 == &lt;span style="color: #007f7f"&gt;0&lt;/span&gt; then &lt;span style="color: #00007f; font-weight: bold"&gt;goto&lt;/span&gt; .L1
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now it's time to explain how the &amp;quot;optimized away as dead code&amp;quot; part happened. When liveness analysis gets to the &lt;tt class="docutils literal"&gt;i7 = i2 == 0&lt;/tt&gt; instruction, it notices that he destination value is not live - nothing uses it. The instruction is then replaced with a &lt;tt class="docutils literal"&gt;JIT_OP_NOP&lt;/tt&gt;, which is simply ignored during code generation.&lt;/p&gt;
&lt;p&gt;A more sophisticated analysis enables libjit to replace the second instruction in the pair &lt;a class="footnote-reference" href="#id12" id="id6"&gt;[5]&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;i8 = i5 % i2
i2 = i8
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Since &lt;tt class="docutils literal"&gt;i8&lt;/tt&gt; is not used anywhere else, backward copy propagation simply replaces the first assignment by &lt;tt class="docutils literal"&gt;i2 = i5 % i2&lt;/tt&gt; and the second becomes dead code, which is replaced with a &lt;tt class="docutils literal"&gt;JIT_OP_NOP&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;Register allocation happens in two stages. First, a simplistic global register allocation is done right after liveness analysis. All the values in the function are ordered from most to least used, and registers are allocated to the most used values. While not as optimal as graph coloring, this is a relatively cheap and simple heuristic that ensures, in most cases, that the hottest values remain in registers across basic blocks and not too many spills are generated.&lt;/p&gt;
&lt;p&gt;The second stage happens as each instruction gets generated - this is local register allocation within a block. &lt;tt class="docutils literal"&gt;_jit_regs_assign&lt;/tt&gt; in &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;jit/jit-reg-alloc.c&lt;/span&gt;&lt;/tt&gt; is the function to look out for. Calls to it are automatically created in the &lt;tt class="docutils literal"&gt;.inc&lt;/tt&gt; file. This stage is tasked with the detailed allocation of registers to instructions that require registers, spilling of existing values from registers (if the required registers are occupied), and so on.&lt;/p&gt;
&lt;p&gt;On a high level, this code is a classical low-level register allocator with a lot of careful bookkeeping (such as ABI constraints and instructions that force special registers). It keeps track of the values contained in each register and uses liveness analysis to try to spill registers with the minimal cost, when spilling is required. It also uses the global register information computed during global allocation, so it's not completely blind to what's going on outside the basic block.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="optimization"&gt;
&lt;h3&gt;Optimization&lt;/h3&gt;
&lt;p&gt;Apart from the copy propagations and dead code elimination mentioned above, libjit doesn't come with a lot of optimizations built in. It has the scaffolding ready to set custom optimization levels on each function, but these don't do much today. Perhaps it was added for future needs or for custom backends that may do more optimization during instruction selection, etc.&lt;/p&gt;
&lt;p&gt;The only other target-independent optimization (which runs by default, unless you explicitly set the optimization level to 0) is an attempt to simplify the control-flow graph of functions. This happens in the &lt;tt class="docutils literal"&gt;optimize&lt;/tt&gt; function, which first builds the CFG with &lt;tt class="docutils literal"&gt;_jit_block_build_cfg&lt;/tt&gt; and then optimizes it with &lt;tt class="docutils literal"&gt;_jit_block_clean_cfg&lt;/tt&gt;. According to comments in the code, it's based on the &amp;quot;Clean&amp;quot; algorithm from &lt;a class="reference external" href="http://www.cs.princeton.edu/~ras/clean.ps"&gt;this paper&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;While the first two parts in this series concentrated on how to use libjit, this part focuses on how libjit works under the hood. It's an audacious goal to try to cover such an intricate piece of software in a single article, so my attempt should be considered at most a high-level overview with a bit of in-depth focus here and there. I hope people who find libjit interesting and wonder how it works will find it useful; it can also be useful just to students of compilers that look for additional real-world examples to study. Software projects rarely have their internals documented, and being presented with a large lump of code is daunting. Perhaps this article can soften the learning curve.&lt;/p&gt;
&lt;img class="align-center" src="https://eli.thegreenplace.net/images/hline.jpg" style="width: 320px; height: 5px;" /&gt;
&lt;table class="docutils footnote" frame="void" id="id7" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id2"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;There's no magic here - libjit doesn't carry a disassembler of its own. It simply dumps the raw binary code into a temporary files and runs it through &lt;tt class="docutils literal"&gt;objdump&lt;/tt&gt;.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id8" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id3"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;tt class="docutils literal"&gt;jit_exception_builtin&lt;/tt&gt; lives in host code, and the host-JIT interface was explained in detail in &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/11/12/getting-started-with-libjit-part-2/"&gt;part 2&lt;/a&gt;.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id10" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id4"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;By the way, this behavior is documented in the libjit API for &lt;tt class="docutils literal"&gt;jit_insn_div&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;jit_insn_rem&lt;/tt&gt;.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id11" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id5"&gt;[4]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;I'll leave the details of this auto-generated instruction selection out of this article, but it's pretty standard in compilers. LLVM has an elaborate auto-generation framework based on TableGen. libjit has a simpler home-cooked solution. It's pretty easy to find out how it works by tracing the flow in the Makefile and looking at the &lt;tt class="docutils literal"&gt;tools/&lt;/tt&gt; directory.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id12" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id6"&gt;[5]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;I found the &lt;tt class="docutils literal"&gt;_JIT_COMPILE_DEBUG&lt;/tt&gt; flag very useful when looking at this. Turn it on in &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;jit/jit-config.h&lt;/span&gt;&lt;/tt&gt;. Similarly, &lt;tt class="docutils literal"&gt;JIT_REG_DEBUG&lt;/tt&gt; helps observe the inner workings of the register allocator.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

    </content><category term="misc"></category><category term="Assembly"></category><category term="C &amp; C++"></category><category term="Code generation"></category></entry><entry><title>Getting started with libjit - part 2</title><link href="https://eli.thegreenplace.net/2013/11/12/getting-started-with-libjit-part-2" rel="alternate"></link><published>2013-11-12T06:04:17-08:00</published><updated>2023-06-30T23:16:27-07:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2013-11-12:/2013/11/12/getting-started-with-libjit-part-2</id><summary type="html">
        &lt;p&gt;This is part 2 in a series of articles on libjit. &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/10/17/getting-started-with-libjit-part-1/"&gt;Part 1&lt;/a&gt; served as a basic introduction to the library and showed how to get started, along with some simple performance measurements. In this part, I want to discuss how to implement more interesting things with libjit, focusing on â€¦&lt;/p&gt;</summary><content type="html">
        &lt;p&gt;This is part 2 in a series of articles on libjit. &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/10/17/getting-started-with-libjit-part-1/"&gt;Part 1&lt;/a&gt; served as a basic introduction to the library and showed how to get started, along with some simple performance measurements. In this part, I want to discuss how to implement more interesting things with libjit, focusing on the fascinating boundary between JITed and host code.&lt;/p&gt;
&lt;p&gt;The &amp;quot;host&amp;quot; is the program that creates machine code at run-time and arranges for it to be executed. It's crucially important to understand this - complexity in the middle notwithstanding, JITing is eventually all about &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/11/05/how-to-jit-an-introduction/"&gt;some code in your process calling some other code&lt;/a&gt;. On the source level, this may be challenging to envision. Therefore, it's more useful to think about it on the binary level - after the host program is compiled and is actually executed in memory as machine code itself. I hope that the examples in this article will help explaining this concept. As usual, I'm using a pseudo-literate-programming approach - if the code samples aren't as readable as prose, please let me know.&lt;/p&gt;
&lt;div class="section" id="calls-from-jited-to-jited-and-from-jited-to-host"&gt;
&lt;h3&gt;Calls from JITed to JITed and from JITed to host&lt;/h3&gt;
&lt;p&gt;The iterative GCD example in &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/10/17/getting-started-with-libjit-part-1/"&gt;Part 1&lt;/a&gt; demonstrated a self-contained JITed function that made no external calls. Let's now look at a more involved example - how JITed functions can call other JITed functions, and how they can call code in the host. The full code, as usual, is in the &lt;a class="reference external" href="https://github.com/eliben/libjit-samples"&gt;libjit-samples repository&lt;/a&gt;. Here I'll reveal it gradually, with explanations. Let's start by defining this simple JITed function:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #007f00"&gt;// Builds this function, and returns an uncompiled jit_function_t:&lt;/span&gt;
&lt;span style="color: #007f00"&gt;//&lt;/span&gt;
&lt;span style="color: #007f00"&gt;// int jit_adder(int x, y) {&lt;/span&gt;
&lt;span style="color: #007f00"&gt;//    return x + y;&lt;/span&gt;
&lt;span style="color: #007f00"&gt;// }&lt;/span&gt;
jit_function_t &lt;span style="color: #00007f"&gt;build_jit_adder&lt;/span&gt;(jit_context_t context) {
  jit_context_build_start(context);

  &lt;span style="color: #007f00"&gt;// Create function signature and object. int (*)(int, int)&lt;/span&gt;
  jit_type_t params[&lt;span style="color: #007f7f"&gt;2&lt;/span&gt;] = {jit_type_int, jit_type_int};
  jit_type_t signature = jit_type_create_signature(
      jit_abi_cdecl, jit_type_int, params, &lt;span style="color: #007f7f"&gt;2&lt;/span&gt;, &lt;span style="color: #007f7f"&gt;1&lt;/span&gt;);
  jit_function_t F = jit_function_create(context, signature);

  &lt;span style="color: #007f00"&gt;// x, y are the parameters; sum is a temporary&lt;/span&gt;
  jit_value_t x = jit_value_get_param(F, &lt;span style="color: #007f7f"&gt;0&lt;/span&gt;);
  jit_value_t y = jit_value_get_param(F, &lt;span style="color: #007f7f"&gt;1&lt;/span&gt;);
  jit_value_t sum = jit_value_create(F, jit_type_int);

  &lt;span style="color: #007f00"&gt;// sum = x + y&lt;/span&gt;
  jit_value_t temp_sum = jit_insn_add(F, x, y);
  jit_insn_store(F, sum, temp_sum);

  &lt;span style="color: #007f00"&gt;// return sum&lt;/span&gt;
  jit_insn_return(F, sum);
  jit_context_build_end(context);
  &lt;span style="color: #00007f; font-weight: bold"&gt;return&lt;/span&gt; F;
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;[if you went over &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/10/17/getting-started-with-libjit-part-1/"&gt;part 1&lt;/a&gt;, this code should be trivial to grok].&lt;/p&gt;
&lt;p&gt;Now, let's define a very simple function in the host program:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt; &lt;span style="color: #00007f"&gt;native_mult&lt;/span&gt;(&lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt; a, &lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt; b) {
  &lt;span style="color: #00007f; font-weight: bold"&gt;return&lt;/span&gt; a * b;
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, let's use libjit to build a JITed function that does this:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #007f00"&gt;// void foo(int x, int y, int* result) {&lt;/span&gt;
&lt;span style="color: #007f00"&gt;//   int t = jit_adder(x, y);&lt;/span&gt;
&lt;span style="color: #007f00"&gt;//   *result = native_mult(t, y);&lt;/span&gt;
&lt;span style="color: #007f00"&gt;// }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;There are at least two things here we haven't seen before. One is calling &lt;tt class="docutils literal"&gt;jit_adder&lt;/tt&gt; - a JITed function. The other is calling &lt;tt class="docutils literal"&gt;native_mult&lt;/tt&gt; - a host function. Without further ado, here's how we build &lt;tt class="docutils literal"&gt;foo&lt;/tt&gt;:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #007f00"&gt;// Returns an uncompiled jit_function_t&lt;/span&gt;
&lt;span style="color: #007f00"&gt;// Note that jit_adder is a jit_function_t that&amp;#39;s passed into this builder.&lt;/span&gt;
jit_function_t &lt;span style="color: #00007f"&gt;build_foo&lt;/span&gt;(jit_context_t context, jit_function_t jit_adder) {
  jit_context_build_start(context);

  &lt;span style="color: #007f00"&gt;// Create function signature and object. void (*)(int, int, void*)&lt;/span&gt;
  &lt;span style="color: #007f00"&gt;// libjit treats all native pointers as void*.&lt;/span&gt;
  jit_type_t params[] = {jit_type_int, jit_type_int, jit_type_void_ptr};
  jit_type_t signature = jit_type_create_signature(
      jit_abi_cdecl, jit_type_void, params, &lt;span style="color: #007f7f"&gt;3&lt;/span&gt;, &lt;span style="color: #007f7f"&gt;1&lt;/span&gt;);
  jit_function_t F = jit_function_create(context, signature);

  &lt;span style="color: #007f00"&gt;// x, y, result are the parameters; t is a temporary&lt;/span&gt;
  jit_value_t x = jit_value_get_param(F, &lt;span style="color: #007f7f"&gt;0&lt;/span&gt;);
  jit_value_t y = jit_value_get_param(F, &lt;span style="color: #007f7f"&gt;1&lt;/span&gt;);
  jit_value_t result = jit_value_get_param(F, &lt;span style="color: #007f7f"&gt;2&lt;/span&gt;);
  jit_value_t t = jit_value_create(F, jit_type_int);

  &lt;span style="color: #007f00"&gt;// t = jit_adder(x, y)&lt;/span&gt;
  jit_value_t adder_args[] = {x, y};
  jit_value_t call_temp = jit_insn_call(
      F, &lt;span style="color: #7f007f"&gt;&amp;quot;jit_adder&amp;quot;&lt;/span&gt;, jit_adder, &lt;span style="color: #007f7f"&gt;0&lt;/span&gt;, adder_args, &lt;span style="color: #007f7f"&gt;2&lt;/span&gt;, &lt;span style="color: #007f7f"&gt;0&lt;/span&gt;);

  jit_insn_store(F, t, call_temp);

  &lt;span style="color: #007f00"&gt;// Prepare calling native_mult: create its signature&lt;/span&gt;
  jit_type_t mult_params[] = {jit_type_int, jit_type_int};
  jit_type_t mult_signature = jit_type_create_signature(
      jit_abi_cdecl, jit_type_int, params, &lt;span style="color: #007f7f"&gt;2&lt;/span&gt;, &lt;span style="color: #007f7f"&gt;1&lt;/span&gt;);

  &lt;span style="color: #007f00"&gt;// x = native_mult(t, y)&lt;/span&gt;
  jit_value_t mult_args[] = {t, y};
  jit_value_t res = jit_insn_call_native(
      F, &lt;span style="color: #7f007f"&gt;&amp;quot;native_mult&amp;quot;&lt;/span&gt;, native_mult, mult_signature,
      mult_args, &lt;span style="color: #00007f; font-weight: bold"&gt;sizeof&lt;/span&gt;(mult_args) / &lt;span style="color: #00007f; font-weight: bold"&gt;sizeof&lt;/span&gt;(jit_value_t), JIT_CALL_NOTHROW);
  jit_insn_store(F, x, res);

  &lt;span style="color: #007f00"&gt;// *result = x&lt;/span&gt;
  &lt;span style="color: #007f00"&gt;// Note that this creates a store of a value libjit considers to be a&lt;/span&gt;
  &lt;span style="color: #007f00"&gt;// jit_type_int, so the pointer must point to at least that size.&lt;/span&gt;
  jit_insn_store_relative(F, result, &lt;span style="color: #007f7f"&gt;0&lt;/span&gt;, x);

  jit_context_build_end(context);
  &lt;span style="color: #00007f; font-weight: bold"&gt;return&lt;/span&gt; F;
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The new libjit APIs used here for calling into other JITed code and into host code are &lt;tt class="docutils literal"&gt;jit_insn_call&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;jit_insn_call_native&lt;/tt&gt;, respectively. One interesting thing to note is that for the native function, the libjit API accepts the raw function pointer - the address of the host function in memory. To know how to pass parameters to the native function and how to receive the return value back from it, a libjit &amp;quot;signature&amp;quot; is created with &lt;tt class="docutils literal"&gt;jit_type_create_signature&lt;/tt&gt; first.&lt;/p&gt;
&lt;p&gt;I had previously mentioned the boundary between JITed and host code. The following diagram will hopefully help clarify what I mean:&lt;/p&gt;
&lt;img class="align-center" src="https://eli.thegreenplace.net/images/2013/10/libjit_native_boundary.png" /&gt;
&lt;p&gt;What it tries to depict is what actually happens at run-time when the JITed &lt;tt class="docutils literal"&gt;foo&lt;/tt&gt; is executed. It calls &lt;tt class="docutils literal"&gt;jit_adder&lt;/tt&gt;, which was also JITed so it's somewhere on the heap (see &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/11/05/how-to-jit-an-introduction/"&gt;my introduction to JITing&lt;/a&gt; for more background). It also calls &lt;tt class="docutils literal"&gt;native_mult&lt;/tt&gt;, which resides within the host program, so it's in the &lt;tt class="docutils literal"&gt;.text&lt;/tt&gt; section. As stated before, understanding the program flow at this level is easier than at the source level, because when the program runs, host code and JITed code are practically equals - they're both chunks of machine code tucked somewhere in the executable memory pages of the running process.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="passing-pointers-from-host-to-jited-code"&gt;
&lt;h3&gt;Passing pointers from host to JITed code&lt;/h3&gt;
&lt;p&gt;Another novelty introduced by &lt;tt class="docutils literal"&gt;build_foo&lt;/tt&gt; is that the result is not &lt;tt class="docutils literal"&gt;return&lt;/tt&gt;-ed to the host code. Rather, the host code passes a pointer into the JITed code, into which &lt;tt class="docutils literal"&gt;foo&lt;/tt&gt; writes its result. libjit makes this quite easy to express. The third argument of &lt;tt class="docutils literal"&gt;foo&lt;/tt&gt; is declared to be a pointer in the signature. Then, &lt;tt class="docutils literal"&gt;jit_insn_store_relative&lt;/tt&gt; is called, which expects a pointer as its destination argument, along with an offset and generates code to store the value to &lt;tt class="docutils literal"&gt;[dest + offest]&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;Here's how we invoke &lt;tt class="docutils literal"&gt;foo&lt;/tt&gt;:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #007f00"&gt;// Run foo with arguments and return its result&lt;/span&gt;
&lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt; &lt;span style="color: #00007f"&gt;run_foo&lt;/span&gt;(jit_function_t jit_foo, &lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt; x, &lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt; y) {
  &lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt; result, *presult = &amp;amp;result;
  &lt;span style="color: #00007f; font-weight: bold"&gt;void&lt;/span&gt;* args[] = {&amp;amp;x, &amp;amp;y, &amp;amp;presult};

  jit_function_apply(jit_foo, args, &lt;span style="color: #00007f"&gt;NULL&lt;/span&gt;);
  &lt;span style="color: #00007f; font-weight: bold"&gt;return&lt;/span&gt; result;
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The way &lt;tt class="docutils literal"&gt;result&lt;/tt&gt; is passed in needs some explaining. &lt;tt class="docutils literal"&gt;jit_function_apply&lt;/tt&gt; accepts &lt;tt class="docutils literal"&gt;args&lt;/tt&gt; as an array of &lt;tt class="docutils literal"&gt;void*&lt;/tt&gt;; quoting from the docs - &amp;quot;each element in &lt;tt class="docutils literal"&gt;args&lt;/tt&gt; is a pointer to one of the arguments&amp;quot;. So normal (non-pointer) arguments are also passed by pointer as you see above. What do we do, then, when we actually need to pass a pointer in? Right, we also pass it by pointer, just like everything else. Hence &lt;tt class="docutils literal"&gt;presult&lt;/tt&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="using-the-standard-c-library-from-jited-code"&gt;
&lt;h3&gt;Using the standard C library from JITed code&lt;/h3&gt;
&lt;p&gt;We've seen how JITed code can call native code using &lt;tt class="docutils literal"&gt;jit_insn_call_native&lt;/tt&gt;. Can the same technique be used to leverage the standard C library from JITed code? Absolutely. C library functions are just normal native functions after all. Let's see an example. The following is a code sample that JITs a simple &lt;tt class="docutils literal"&gt;void foo()&lt;/tt&gt; and makes it call &lt;tt class="docutils literal"&gt;puts&lt;/tt&gt; to print out a string.&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;  &lt;span style="color: #007f00"&gt;// void foo()&lt;/span&gt;
  jit_function_t F = jit_function_create(context,
      jit_type_create_signature(jit_abi_cdecl, jit_type_void, &lt;span style="color: #00007f"&gt;NULL&lt;/span&gt;, &lt;span style="color: #007f7f"&gt;0&lt;/span&gt;, &lt;span style="color: #007f7f"&gt;1&lt;/span&gt;));

&lt;span style="color: #007f00"&gt;  // Approach #1: allocate the string buffer on stack inside the jit-ed&lt;/span&gt;
&lt;span style="color: #007f00"&gt;  // function and store the desired characters into it.&lt;/span&gt;

&lt;span style="color: #007f00"&gt;  // char* bufptr&lt;/span&gt;
&lt;span style="color: #007f00"&gt;#define CONST_BYTE(v) (jit_value_create_nint_constant(F, jit_type_ubyte, v))&lt;/span&gt;
  jit_type_t type_cstring = jit_type_create_pointer(jit_type_sys_char, &lt;span style="color: #007f7f"&gt;1&lt;/span&gt;);
  jit_value_t bufptr = jit_value_create(F, type_cstring);

  &lt;span style="color: #007f00"&gt;// Make bufptr point to a 4-byte buffer allocated on the stack&lt;/span&gt;
  jit_insn_store(F, bufptr, jit_insn_alloca(F, CONST_BYTE(&lt;span style="color: #007f7f"&gt;4&lt;/span&gt;)));

  &lt;span style="color: #007f00"&gt;// Store &amp;quot;abc&amp;quot; (with explicit terminating zero) into bufptr&lt;/span&gt;
  jit_insn_store_relative(F, bufptr, &lt;span style="color: #007f7f"&gt;0&lt;/span&gt;, CONST_BYTE(&lt;span style="color: #7f007f"&gt;&amp;#39;a&amp;#39;&lt;/span&gt;));
  jit_insn_store_relative(F, bufptr, &lt;span style="color: #007f7f"&gt;1&lt;/span&gt;, CONST_BYTE(&lt;span style="color: #7f007f"&gt;&amp;#39;b&amp;#39;&lt;/span&gt;));
  jit_insn_store_relative(F, bufptr, &lt;span style="color: #007f7f"&gt;2&lt;/span&gt;, CONST_BYTE(&lt;span style="color: #7f007f"&gt;&amp;#39;c&amp;#39;&lt;/span&gt;));
  jit_insn_store_relative(F, bufptr, &lt;span style="color: #007f7f"&gt;3&lt;/span&gt;, CONST_BYTE(&lt;span style="color: #7f007f"&gt;&amp;#39;\x00&amp;#39;&lt;/span&gt;));

  &lt;span style="color: #007f00"&gt;// Create the signature of puts: int (*)(char*)&lt;/span&gt;
  jit_type_t puts_signature = jit_type_create_signature(
      jit_abi_cdecl, jit_type_int, &amp;amp;type_cstring, &lt;span style="color: #007f7f"&gt;1&lt;/span&gt;, &lt;span style="color: #007f7f"&gt;1&lt;/span&gt;);

  &lt;span style="color: #007f00"&gt;// puts(bufptr);&lt;/span&gt;
  jit_insn_call_native(
      F, &lt;span style="color: #7f007f"&gt;&amp;quot;puts&amp;quot;&lt;/span&gt;, puts, puts_signature, &amp;amp;bufptr, &lt;span style="color: #007f7f"&gt;1&lt;/span&gt;, JIT_CALL_NOTHROW);

  &lt;span style="color: #007f00"&gt;// Approach #2: use the address of a string literal in the host code&lt;/span&gt;
  &lt;span style="color: #007f00"&gt;// directly, storing it into a constant. Note that this has to explicitly&lt;/span&gt;
  &lt;span style="color: #007f00"&gt;// specify that host pointers are 64-bit.&lt;/span&gt;

  jit_value_t hostmemptr = jit_value_create_long_constant(
      F, type_cstring, (&lt;span style="color: #00007f; font-weight: bold"&gt;long&lt;/span&gt;)&lt;span style="color: #7f007f"&gt;&amp;quot;foobar&amp;quot;&lt;/span&gt;);

  jit_insn_call_native(
      F, &lt;span style="color: #7f007f"&gt;&amp;quot;puts&amp;quot;&lt;/span&gt;, puts, puts_signature, &amp;amp;hostmemptr, &lt;span style="color: #007f7f"&gt;1&lt;/span&gt;, JIT_CALL_NOTHROW);

  jit_dump_function(stdout, F, &lt;span style="color: #7f007f"&gt;&amp;quot;F [uncompiled]&amp;quot;&lt;/span&gt;);
  jit_function_compile(F);
  jit_dump_function(stdout, F, &lt;span style="color: #7f007f"&gt;&amp;quot;F [compiled]&amp;quot;&lt;/span&gt;);

  &lt;span style="color: #007f00"&gt;// Run&lt;/span&gt;
  jit_function_apply(F, &lt;span style="color: #00007f"&gt;NULL&lt;/span&gt;, &lt;span style="color: #00007f"&gt;NULL&lt;/span&gt;);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This code demonstrates two alternative ways to get a string constant into the JITed code:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Using purely JITed instructions to allocate a 4-byte buffer on the stack and store the characters &lt;tt class="docutils literal"&gt;{'a', 'b', 'c', '\0'}&lt;/tt&gt; into it.&lt;/li&gt;
&lt;li&gt;Passing a pointer to the host-allocated string constant &lt;tt class="docutils literal"&gt;&amp;quot;foobar&amp;quot;&lt;/tt&gt; with &lt;tt class="docutils literal"&gt;jit_value_create_long_constant&lt;/tt&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The first way is more straightforward, IMHO, because the second one touches once more on the interface between host and JITed code. When &lt;tt class="docutils literal"&gt;jit_value_create_long_constant&lt;/tt&gt; is called, it expects a numeric constant. By passing &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;(long)&amp;quot;foobar&amp;quot;&lt;/span&gt;&lt;/tt&gt; into it, we pass the address of the string constant &lt;a class="footnote-reference" href="#id4" id="id3"&gt;[1]&lt;/a&gt;. When the JITed code runs and tries to access this address (by passing it to &lt;tt class="docutils literal"&gt;puts&lt;/tt&gt; - back into host-code!), the address still points at the string constant, so everything works.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="final-words"&gt;
&lt;h3&gt;Final words&lt;/h3&gt;
&lt;p&gt;In this article I tried to make a special focus on the interface between host and JITed code. This is to emphasize the importance of this interface - which is sometimes tricky to grok, but nonetheless is one of the most important things about modern JITs.&lt;/p&gt;
&lt;p&gt;For example, the technique of passing a host pointer directly to JITed code shown in the previous section is just a hint of the tricks employed by modern JITs. The shared in-process execution of host and JITed code enables such things to be done without losing much performance in the process.&lt;/p&gt;
&lt;p&gt;Note that some JITs allow more advanced execution modes, such as a remote code emission mode, where code is emitted to run in a different process. For example, LLVM's MCJIT does that for the LLDB (debugger) use case to emit code that will run in the debugged process's memory space. In this case special provision is obviously required to have references between host and JITed code.&lt;/p&gt;
&lt;img class="align-center" src="https://eli.thegreenplace.net/images/hline.jpg" style="width: 320px; height: 5px;" /&gt;
&lt;table class="docutils footnote" frame="void" id="id4" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id3"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Note that by casting the pointer to &lt;tt class="docutils literal"&gt;long&lt;/tt&gt;, we also expose a platform-specific detail: this code runs on 64-bit Linux, which is LP64.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

    </content><category term="misc"></category><category term="Assembly"></category><category term="C &amp; C++"></category><category term="Code generation"></category></entry><entry><title>How to JIT - an introduction</title><link href="https://eli.thegreenplace.net/2013/11/05/how-to-jit-an-introduction" rel="alternate"></link><published>2013-11-05T05:59:12-08:00</published><updated>2023-06-30T23:16:27-07:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2013-11-05:/2013/11/05/how-to-jit-an-introduction</id><summary type="html">
        &lt;p&gt;When I wrote the &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/10/17/getting-started-with-libjit-part-1/"&gt;introductory article for libjit&lt;/a&gt;, I aimed it at programmers who know what JITs are, at least to some extent. I did mention what a JIT is, but only very briefly. The purpose of this article is to provide a better introductory overview of JITing, with code â€¦&lt;/p&gt;</summary><content type="html">
        &lt;p&gt;When I wrote the &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/10/17/getting-started-with-libjit-part-1/"&gt;introductory article for libjit&lt;/a&gt;, I aimed it at programmers who know what JITs are, at least to some extent. I did mention what a JIT is, but only very briefly. The purpose of this article is to provide a better introductory overview of JITing, with code samples that don't rely on any libraries.&lt;/p&gt;
&lt;div class="section" id="defining-jit"&gt;
&lt;h3&gt;Defining JIT&lt;/h3&gt;
&lt;p&gt;JIT is simply an acronym for &amp;quot;Just In Time&amp;quot;. That, in itself, doesn't help much - the term is quite cryptic and seems to have little to do with programming. First, let's define what &amp;quot;a JIT&amp;quot; actually refers to. I find the following way to think about this useful:&lt;/p&gt;
&lt;blockquote&gt;
Whenever a program, while running, creates and runs some new executable code which was not part of the program when it was stored on disk, itâ€™s a JIT.&lt;/blockquote&gt;
&lt;p&gt;What about the historical usage of the term &amp;quot;JIT&amp;quot;, though? Luckily, John Aycock from the University of Calgary has written a very interesting paper named &amp;quot;A Brief History of Just-In-Time&amp;quot; (google it, PDFs are available online) looking at JIT techniques from a historical point of view. According to Aycock's paper, the first mention of code generation and execution during program runtime is apparent as early as McCarthy's LISP paper from 1960. In later work, such as Thompson's 1968 regex paper, it was even more apparent (regexes are compiled into machine code and executed on the fly).&lt;/p&gt;
&lt;p&gt;The term JIT was first brought into use in computing literature by James Gosling for Java. Aycock mentions that Gosling has borrowed the term from the domain of &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Just_in_time_%28business%29"&gt;manufacturing&lt;/a&gt; and started using it in the early 1990s.&lt;/p&gt;
&lt;p&gt;This is as far as I'll go into history here. Read the Aycock paper if you're interested in more details. Let's now see what the definition quoted above means in practice.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="jit-create-machine-code-then-run-it"&gt;
&lt;h3&gt;JIT - create machine code, then run it&lt;/h3&gt;
&lt;p&gt;I think that JIT technology is easier to explain when divided into two distinct phases:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Phase 1: create &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Machine_code"&gt;machine code&lt;/a&gt; at program run-time.&lt;/li&gt;
&lt;li&gt;Phase 2: execute that machine code, also at program run-time.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Phase 1 is where 99% of the challenges of JITing are. But it's also the less mystical part of the process, because this is exactly what a compiler does. Well known compilers like &lt;tt class="docutils literal"&gt;gcc&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;clang&lt;/tt&gt; translate C/C++ source code into machine code. The machine code is emitted into an output stream, but it could very well be just kept in memory (and in fact, both &lt;tt class="docutils literal"&gt;gcc&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;clang/llvm&lt;/tt&gt; have building blocks for keeping the code in memory for JIT execution). Phase 2 is what I want to focus on in this article.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="running-dynamically-generated-code"&gt;
&lt;h3&gt;Running dynamically-generated code&lt;/h3&gt;
&lt;p&gt;Modern operating systems are picky about what they allow a program to do at runtime. The wild-west days of the past came to an end with the advent of &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Protected_mode"&gt;protected mode&lt;/a&gt;, which allows an OS to restrict chunks of virtual memory with various permissions. So in &amp;quot;normal&amp;quot; code, you can create new data dynamically on the heap, but &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Executable_space_protection"&gt;you can't just run stuff from the heap&lt;/a&gt; without asking the OS to explicitly allow it.&lt;/p&gt;
&lt;p&gt;At this point I hope it's obvious that machine code is just data - a stream of bytes. So, this:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #00007f; font-weight: bold"&gt;unsigned&lt;/span&gt; &lt;span style="color: #00007f; font-weight: bold"&gt;char&lt;/span&gt;[] code = {&lt;span style="color: #007f7f"&gt;0x48&lt;/span&gt;, &lt;span style="color: #007f7f"&gt;0x89&lt;/span&gt;, &lt;span style="color: #007f7f"&gt;0xf8&lt;/span&gt;};
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Really depends on the eye of the beholder. To some, it's just some data that could represent anything. To others, it's the binary encoding of real, valid x86-64 machine code:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;mov %rdi, %rax
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So getting machine code into memory is easy. But how to make it runnable, and then run it?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="let-s-see-some-code"&gt;
&lt;h3&gt;Let's see some code&lt;/h3&gt;
&lt;p&gt;The rest of this article contains code samples for a POSIX-compliant Unix OS (specifically Linux). On other OSes (like Windows) the code would be different in the details, but not in spirit. All modern OSes have convenient APIs to implement the same thing.&lt;/p&gt;
&lt;p&gt;Without further ado, here's how we dynamically create a function in memory and execute it. The function is intentionally very simple, implementing this C code:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #00007f; font-weight: bold"&gt;long&lt;/span&gt; &lt;span style="color: #00007f"&gt;add4&lt;/span&gt;(&lt;span style="color: #00007f; font-weight: bold"&gt;long&lt;/span&gt; num) {
  &lt;span style="color: #00007f; font-weight: bold"&gt;return&lt;/span&gt; num + &lt;span style="color: #007f7f"&gt;4&lt;/span&gt;;
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here's a first try (the full code with a Makefile is available in &lt;a class="reference external" href="https://github.com/eliben/libjit-samples"&gt;this repo&lt;/a&gt;):&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #007f00"&gt;#include &amp;lt;stdio.h&amp;gt;&lt;/span&gt;
&lt;span style="color: #007f00"&gt;#include &amp;lt;stdlib.h&amp;gt;&lt;/span&gt;
&lt;span style="color: #007f00"&gt;#include &amp;lt;string.h&amp;gt;&lt;/span&gt;
&lt;span style="color: #007f00"&gt;#include &amp;lt;sys/mman.h&amp;gt;&lt;/span&gt;


&lt;span style="color: #007f00"&gt;// Allocates RWX memory of given size and returns a pointer to it. On failure,&lt;/span&gt;
&lt;span style="color: #007f00"&gt;// prints out the error and returns NULL.&lt;/span&gt;
&lt;span style="color: #00007f; font-weight: bold"&gt;void&lt;/span&gt;* &lt;span style="color: #00007f"&gt;alloc_executable_memory&lt;/span&gt;(&lt;span style="color: #00007f; font-weight: bold"&gt;size_t&lt;/span&gt; size) {
  &lt;span style="color: #00007f; font-weight: bold"&gt;void&lt;/span&gt;* ptr = mmap(&lt;span style="color: #007f7f"&gt;0&lt;/span&gt;, size,
                   PROT_READ | PROT_WRITE | PROT_EXEC,
                   MAP_PRIVATE | MAP_ANONYMOUS, -&lt;span style="color: #007f7f"&gt;1&lt;/span&gt;, &lt;span style="color: #007f7f"&gt;0&lt;/span&gt;);
  &lt;span style="color: #00007f; font-weight: bold"&gt;if&lt;/span&gt; (ptr == (&lt;span style="color: #00007f; font-weight: bold"&gt;void&lt;/span&gt;*)-&lt;span style="color: #007f7f"&gt;1&lt;/span&gt;) {
    perror(&lt;span style="color: #7f007f"&gt;&amp;quot;mmap&amp;quot;&lt;/span&gt;);
    &lt;span style="color: #00007f; font-weight: bold"&gt;return&lt;/span&gt; &lt;span style="color: #00007f"&gt;NULL&lt;/span&gt;;
  }
  &lt;span style="color: #00007f; font-weight: bold"&gt;return&lt;/span&gt; ptr;
}

&lt;span style="color: #00007f; font-weight: bold"&gt;void&lt;/span&gt; &lt;span style="color: #00007f"&gt;emit_code_into_memory&lt;/span&gt;(&lt;span style="color: #00007f; font-weight: bold"&gt;unsigned&lt;/span&gt; &lt;span style="color: #00007f; font-weight: bold"&gt;char&lt;/span&gt;* m) {
  &lt;span style="color: #00007f; font-weight: bold"&gt;unsigned&lt;/span&gt; &lt;span style="color: #00007f; font-weight: bold"&gt;char&lt;/span&gt; code[] = {
    &lt;span style="color: #007f7f"&gt;0x48&lt;/span&gt;, &lt;span style="color: #007f7f"&gt;0x89&lt;/span&gt;, &lt;span style="color: #007f7f"&gt;0xf8&lt;/span&gt;,                   &lt;span style="color: #007f00"&gt;// mov %rdi, %rax&lt;/span&gt;
    &lt;span style="color: #007f7f"&gt;0x48&lt;/span&gt;, &lt;span style="color: #007f7f"&gt;0x83&lt;/span&gt;, &lt;span style="color: #007f7f"&gt;0xc0&lt;/span&gt;, &lt;span style="color: #007f7f"&gt;0x04&lt;/span&gt;,             &lt;span style="color: #007f00"&gt;// add $4, %rax&lt;/span&gt;
    &lt;span style="color: #007f7f"&gt;0xc3&lt;/span&gt;                                &lt;span style="color: #007f00"&gt;// ret&lt;/span&gt;
  };
  memcpy(m, code, &lt;span style="color: #00007f; font-weight: bold"&gt;sizeof&lt;/span&gt;(code));
}

&lt;span style="color: #00007f; font-weight: bold"&gt;const&lt;/span&gt; &lt;span style="color: #00007f; font-weight: bold"&gt;size_t&lt;/span&gt; SIZE = &lt;span style="color: #007f7f"&gt;1024&lt;/span&gt;;
&lt;span style="color: #00007f; font-weight: bold"&gt;typedef&lt;/span&gt; &lt;span style="color: #00007f; font-weight: bold"&gt;long&lt;/span&gt; (*JittedFunc)(&lt;span style="color: #00007f; font-weight: bold"&gt;long&lt;/span&gt;);

&lt;span style="color: #007f00"&gt;// Allocates RWX memory directly.&lt;/span&gt;
&lt;span style="color: #00007f; font-weight: bold"&gt;void&lt;/span&gt; &lt;span style="color: #00007f"&gt;run_from_rwx&lt;/span&gt;() {
  &lt;span style="color: #00007f; font-weight: bold"&gt;void&lt;/span&gt;* m = alloc_executable_memory(SIZE);
  emit_code_into_memory(m);

  JittedFunc func = m;
  &lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt; result = func(&lt;span style="color: #007f7f"&gt;2&lt;/span&gt;);
  printf(&lt;span style="color: #7f007f"&gt;&amp;quot;result = %d\n&amp;quot;&lt;/span&gt;, result);
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The main 3 steps performed by this code are:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Use &lt;tt class="docutils literal"&gt;mmap&lt;/tt&gt; to allocate a readable, writable and executable chunk of memory on the heap.&lt;/li&gt;
&lt;li&gt;Copy the machine code implementing &lt;tt class="docutils literal"&gt;add4&lt;/tt&gt; into this chunk.&lt;/li&gt;
&lt;li&gt;Execute code from this chunk by casting it to a function pointer and calling through it.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note that step 3 can only happen because the memory chunk containing the machine code is &lt;em&gt;executable&lt;/em&gt;. Without setting the right permission, that call would result in a runtime error from the OS (most likely a segmentation fault). This would happen if, for example, we allocated &lt;tt class="docutils literal"&gt;m&lt;/tt&gt; with a regular call to &lt;tt class="docutils literal"&gt;malloc&lt;/tt&gt;, which allocates readable and writable, but not executable memory.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="digression-heap-malloc-and-mmap"&gt;
&lt;h3&gt;Digression - heap, malloc and mmap&lt;/h3&gt;
&lt;p&gt;Diligent readers may have noticed a half-slip I made in the previous section, by referring to memory returned from &lt;tt class="docutils literal"&gt;mmap&lt;/tt&gt; as &amp;quot;heap memory&amp;quot;. Very strictly speaking, &amp;quot;heap&amp;quot; is a name that designates the memory used by &lt;tt class="docutils literal"&gt;malloc&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;free&lt;/tt&gt; et. al. to manage runtime-allocated memory, as opposed to &amp;quot;stack&amp;quot; which is managed implicitly by the compiler.&lt;/p&gt;
&lt;p&gt;That said, it's not so simple :-) While traditionally (i.e. a long time ago) &lt;tt class="docutils literal"&gt;malloc&lt;/tt&gt; only used one source for its memory (the &lt;tt class="docutils literal"&gt;sbrk&lt;/tt&gt; system call), these days most malloc implementations use &lt;tt class="docutils literal"&gt;mmap&lt;/tt&gt; in many cases. The details differ between OSes and implementations, but often &lt;tt class="docutils literal"&gt;mmap&lt;/tt&gt; is used for the large chunks and &lt;tt class="docutils literal"&gt;sbrk&lt;/tt&gt; for the small chunks. The tradeoffs have to do with the relative efficiency of the two methods of requesting more memory from the OS.&lt;/p&gt;
&lt;p&gt;So calling memory provided by &lt;tt class="docutils literal"&gt;mmap&lt;/tt&gt; &amp;quot;heap memory&amp;quot; is not a mistake, IMHO, and that's what I intend to keep on doing.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="caring-more-about-security"&gt;
&lt;h3&gt;Caring more about security&lt;/h3&gt;
&lt;p&gt;The code shown above has a problem - it's a security hole. The reason is the RWX (Readable, Writable, eXecutable) chunk of memory it allocates - a paradise for attacks and exploits. So let's be a bit more responsible about it. Here's some slightly modified code:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #007f00"&gt;// Allocates RW memory of given size and returns a pointer to it. On failure,&lt;/span&gt;
&lt;span style="color: #007f00"&gt;// prints out the error and returns NULL. Unlike malloc, the memory is allocated&lt;/span&gt;
&lt;span style="color: #007f00"&gt;// on a page boundary so it&amp;#39;s suitable for calling mprotect.&lt;/span&gt;
&lt;span style="color: #00007f; font-weight: bold"&gt;void&lt;/span&gt;* &lt;span style="color: #00007f"&gt;alloc_writable_memory&lt;/span&gt;(&lt;span style="color: #00007f; font-weight: bold"&gt;size_t&lt;/span&gt; size) {
  &lt;span style="color: #00007f; font-weight: bold"&gt;void&lt;/span&gt;* ptr = mmap(&lt;span style="color: #007f7f"&gt;0&lt;/span&gt;, size,
                   PROT_READ | PROT_WRITE,
                   MAP_PRIVATE | MAP_ANONYMOUS, -&lt;span style="color: #007f7f"&gt;1&lt;/span&gt;, &lt;span style="color: #007f7f"&gt;0&lt;/span&gt;);
  &lt;span style="color: #00007f; font-weight: bold"&gt;if&lt;/span&gt; (ptr == (&lt;span style="color: #00007f; font-weight: bold"&gt;void&lt;/span&gt;*)-&lt;span style="color: #007f7f"&gt;1&lt;/span&gt;) {
    perror(&lt;span style="color: #7f007f"&gt;&amp;quot;mmap&amp;quot;&lt;/span&gt;);
    &lt;span style="color: #00007f; font-weight: bold"&gt;return&lt;/span&gt; &lt;span style="color: #00007f"&gt;NULL&lt;/span&gt;;
  }
  &lt;span style="color: #00007f; font-weight: bold"&gt;return&lt;/span&gt; ptr;
}

&lt;span style="color: #007f00"&gt;// Sets a RX permission on the given memory, which must be page-aligned. Returns&lt;/span&gt;
&lt;span style="color: #007f00"&gt;// 0 on success. On failure, prints out the error and returns -1.&lt;/span&gt;
&lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt; &lt;span style="color: #00007f"&gt;make_memory_executable&lt;/span&gt;(&lt;span style="color: #00007f; font-weight: bold"&gt;void&lt;/span&gt;* m, &lt;span style="color: #00007f; font-weight: bold"&gt;size_t&lt;/span&gt; size) {
  &lt;span style="color: #00007f; font-weight: bold"&gt;if&lt;/span&gt; (mprotect(m, size, PROT_READ | PROT_EXEC) == -&lt;span style="color: #007f7f"&gt;1&lt;/span&gt;) {
    perror(&lt;span style="color: #7f007f"&gt;&amp;quot;mprotect&amp;quot;&lt;/span&gt;);
    &lt;span style="color: #00007f; font-weight: bold"&gt;return&lt;/span&gt; -&lt;span style="color: #007f7f"&gt;1&lt;/span&gt;;
  }
  &lt;span style="color: #00007f; font-weight: bold"&gt;return&lt;/span&gt; &lt;span style="color: #007f7f"&gt;0&lt;/span&gt;;
}

&lt;span style="color: #007f00"&gt;// Allocates RW memory, emits the code into it and sets it to RX before&lt;/span&gt;
&lt;span style="color: #007f00"&gt;// executing.&lt;/span&gt;
&lt;span style="color: #00007f; font-weight: bold"&gt;void&lt;/span&gt; &lt;span style="color: #00007f"&gt;emit_to_rw_run_from_rx&lt;/span&gt;() {
  &lt;span style="color: #00007f; font-weight: bold"&gt;void&lt;/span&gt;* m = alloc_writable_memory(SIZE);
  emit_code_into_memory(m);
  make_memory_executable(m, SIZE);

  JittedFunc func = m;
  &lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt; result = func(&lt;span style="color: #007f7f"&gt;2&lt;/span&gt;);
  printf(&lt;span style="color: #7f007f"&gt;&amp;quot;result = %d\n&amp;quot;&lt;/span&gt;, result);
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It's equivalent to the earlier snippet in all respects except one: the memory is first allocated with RW permissions (just like a normal &lt;tt class="docutils literal"&gt;malloc&lt;/tt&gt; would do). This is all we really need to write our machine code into it. When the code is there, we use &lt;tt class="docutils literal"&gt;mprotect&lt;/tt&gt; to change the chunk's permission from RW to RX, making it executable but &lt;em&gt;no longer writable&lt;/em&gt;. So the effect is the same, but at no point in the execution of our program the chunk is both writable and executable, which is good from a security point of view.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="what-about-malloc"&gt;
&lt;h3&gt;What about malloc?&lt;/h3&gt;
&lt;p&gt;Could we use &lt;tt class="docutils literal"&gt;malloc&lt;/tt&gt; instead of &lt;tt class="docutils literal"&gt;mmap&lt;/tt&gt; for allocating the chunk in the previous snippet? After all, RW memory is exactly what &lt;tt class="docutils literal"&gt;malloc&lt;/tt&gt; provides. Yes, we could. However, it's more trouble than it's worth, really. The reason is that protection bits can only be set on virtual memory page boundaries. Therefore, had we used &lt;tt class="docutils literal"&gt;malloc&lt;/tt&gt; we'd have to manually ensure that the allocation is aligned at a page boundary. Otherwise, &lt;tt class="docutils literal"&gt;mprotect&lt;/tt&gt; could have unwanted effects from failing to enabling/disabling more than actually required. &lt;tt class="docutils literal"&gt;mmap&lt;/tt&gt; takes care of this for us by only allocating at page boundaries (because &lt;tt class="docutils literal"&gt;mmap&lt;/tt&gt;, by design, maps whole pages).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="tying-loose-ends"&gt;
&lt;h3&gt;Tying loose ends&lt;/h3&gt;
&lt;p&gt;This article started with a high-level overview of what we mean when we say JIT, and ended with hands-on code snippets that show how to dynamically emit machine code into memory and execute it.&lt;/p&gt;
&lt;p&gt;The technique shown here is pretty much how real JIT engines (e.g. LLVM and libjit) emit and run executable machine code from memory. What remains is just a &amp;quot;simple&amp;quot; matter of synthesizing that machine code from something else.&lt;/p&gt;
&lt;p&gt;LLVM has a full compiler available, so it can actually translate C and C++ code (through LLVM IR) to machine code at runtime, and then execute it. libjit picks the ball up at a much lower level - it can serve as a backend for a compiler. In fact, &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/10/17/getting-started-with-libjit-part-1/"&gt;my introductory article on libjit&lt;/a&gt; already demonstrates how to emit and run non-trivial code with libjit. But JITing is a more general concept. Emitting code at run-time can be done for &lt;a class="reference external" href="http://pyevolve.sourceforge.net/wordpress/?p=914"&gt;data structures&lt;/a&gt;, &lt;a class="reference external" href="http://sljit.sourceforge.net/"&gt;regular expressions&lt;/a&gt;  and even &lt;a class="reference external" href="http://luajit.org/ext_ffi.html"&gt;accessing C from language VMs&lt;/a&gt;. Digging in my blog's archives helped me find a mention of some &lt;a class="reference external" href="https://eli.thegreenplace.net/2005/09/04/cool-hack-creating-custom-subroutines-on-the-fly-in-perl/"&gt;JITing I did 8 years ago&lt;/a&gt;. That was Perl code generating more Perl code at run-time (from a XML description of a serialization format), but the idea is the same.&lt;/p&gt;
&lt;p&gt;This is why I felt that splitting the JITing concept into two phases is important. For phase 2 (which was explained in this article), the implementation is relatively obvious and uses well defined OS APIs. For phase 1, the possibilites are endless and what you do ultimately depends on the application you're developing.&lt;/p&gt;
&lt;/div&gt;

    </content><category term="misc"></category><category term="C &amp; C++"></category><category term="Code generation"></category><category term="Compilation"></category></entry><entry><title>Getting started with libjit - part 1</title><link href="https://eli.thegreenplace.net/2013/10/17/getting-started-with-libjit-part-1" rel="alternate"></link><published>2013-10-17T06:52:25-07:00</published><updated>2023-06-30T23:16:27-07:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2013-10-17:/2013/10/17/getting-started-with-libjit-part-1</id><summary type="html">
        &lt;p&gt;libjit is a very interesting project. It's a C library for generating executable machine code at runtime. As such, it can serve as a back-end of a JIT compiler. libjit was originally created as part of the larger DotGNU project (portable .NET runtime). Since DotGNU has been discontinued, libjit has â€¦&lt;/p&gt;</summary><content type="html">
        &lt;p&gt;libjit is a very interesting project. It's a C library for generating executable machine code at runtime. As such, it can serve as a back-end of a JIT compiler. libjit was originally created as part of the larger DotGNU project (portable .NET runtime). Since DotGNU has been discontinued, libjit has fallen on and off into oblivion, but recently it's being maintained again.&lt;/p&gt;
&lt;p&gt;libjit is not easy to get started with, and hence this series of articles. I spent a couple of days getting it to build and writing some simple programs using it, so I wanted to document this effort. libjit is one of those typical open-source projects in which the only real authority is the latest source code. Don't even look at the last &amp;quot;released&amp;quot; version - the code in Git is much more up-to-date. Similar for documentation: while the &lt;a class="reference external" href="http://www.gnu.org/software/libjit/doc/libjit.html"&gt;online docs&lt;/a&gt; are a pretty good place to get started, they are direly out of date when compared to the source code. That said, the project's source code is clean and well-documented C, so it's pretty easy to grok. Also, the tutorial part of the documentation is useful - make sure you go over it before reading this post; otherwise, it may be difficult to understand what libjit is about.&lt;/p&gt;
&lt;div class="section" id="a-few-words-on-jits"&gt;
&lt;h3&gt;A few words on JITs&lt;/h3&gt;
&lt;p&gt;JITs have become very popular in the past decade or so due to their use in popular mainstream languages like Java, JavaScript and C#. However, the idea of recompiling a program at runtime is almost as old as programming itself &lt;a class="footnote-reference" href="#id5" id="id1"&gt;[1]&lt;/a&gt;. Generating native machine code from higher-level bytecode at runtime is a concept many language designers have encountered in the past 50 years, and the problems/tradeoffs they ran into are comfortingly similar. In other words, it's an old and familiar problem.&lt;/p&gt;
&lt;p&gt;While &amp;quot;a JIT&amp;quot; is usually thought about as part of some larger bytecode virtual machine (such as the JVM), it's a more general concept. I find the following way to think about this useful:&lt;/p&gt;
&lt;blockquote&gt;
Whenever a program, while running, creates and runs some new executable code which was not part of the program when it was stored on disk, it's a JIT.&lt;/blockquote&gt;
&lt;p&gt;libjit fits this description well, since it's more general than the traditional VM association of JITs is (even though libjit was also originally conceived for the purpose of implementing a VM). True, libjit can be used to speed-up a VM by compiling bytecode to machine code at runtime. But it can be used for other things as well:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Dynamic code generation from DSLs like regexes.&lt;/li&gt;
&lt;li&gt;Dynamic code generation for specialized data structures and algorithms.&lt;/li&gt;
&lt;li&gt;Implementing FFI (Foreign Function Interface) mechanisms for interfacing with native code.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As we'll see, libjit is very general, so the possibilities are only limited by the imagination.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-libjit-api"&gt;
&lt;h3&gt;The libjit API&lt;/h3&gt;
&lt;p&gt;[reminder: please go over &lt;a class="reference external" href="http://www.gnu.org/software/libjit/doc/libjit_3.html"&gt;the tutorial in the official docs of libjit&lt;/a&gt; before reading on]&lt;/p&gt;
&lt;p&gt;I found the libjit API to be very well designed and intuitive. Once you spend some time with it, it becomes obvious how to do additional things without even looking them up. What follows is a short summary of how it works.&lt;/p&gt;
&lt;p&gt;By means of its API calls, libjit builds an in-memory intermediate representation of a fairly low level bytecode. In formal terms, the IR  is based on a &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Three-address_code"&gt;three-address code&lt;/a&gt; &lt;a class="footnote-reference" href="#id6" id="id2"&gt;[2]&lt;/a&gt;. This is somewhat similar to LLVM IR, although there are also important differences. For example, unlike LLVM, libjit does not have a serialized textual or binary representation of its IR - it only exists in memory.&lt;/p&gt;
&lt;p&gt;Some of the most important data structures / objects in libjit are:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;jit_value_t&lt;/tt&gt;: a generic &lt;em&gt;value&lt;/em&gt; that serves as an argument to, and the potential return value from, libjit operations.&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;jit_label_t&lt;/tt&gt;: represents a jump target, just like in assembly languages.&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;jit_function_t&lt;/tt&gt;: represents a JIT-ed function that contains instructions and labels, can be compiled, run, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;JIT &lt;em&gt;instructions&lt;/em&gt; are created by means of &lt;tt class="docutils literal"&gt;jit_insn_*&lt;/tt&gt; calls. These calls accept the function object to add the instruction to, as well as potentially some values and/or labels. If the instruction returns a value, the API call will return a &lt;tt class="docutils literal"&gt;jit_value_t&lt;/tt&gt; that represents it. Instructions are added to functions linearly - think of a function consisting of a sequence of instructions - each new &lt;tt class="docutils literal"&gt;jit_insn_*&lt;/tt&gt; call appends one instruction to the end of that sequence.&lt;/p&gt;
&lt;p&gt;Let's now get to a complete example that shows how these interact in practice.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="building-libjit"&gt;
&lt;h3&gt;Building libjit&lt;/h3&gt;
&lt;p&gt;First things first. I cloned the latest code from Git. libjit doesn't come with a &lt;tt class="docutils literal"&gt;configure&lt;/tt&gt; script; rather, it needs to be generated with autotools using the provided &lt;tt class="docutils literal"&gt;auto_gen.sh&lt;/tt&gt; script. I had to install &lt;tt class="docutils literal"&gt;libtool&lt;/tt&gt; first, and a couple of other build dependencies:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;$ sudo apt-get install libtool flex bison texinfo
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After this, I could run &lt;tt class="docutils literal"&gt;./auto_gen.sh&lt;/tt&gt; followed by the usual &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;configure-make&lt;/span&gt;&lt;/tt&gt; sequence. &lt;tt class="docutils literal"&gt;make check&lt;/tt&gt; can also be used to run the tests.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="linking-with-libjit"&gt;
&lt;h3&gt;Linking with libjit&lt;/h3&gt;
&lt;p&gt;The libjit makefile creates both a static archive and a shared library, so you can choose whether you want to link libjit in statically or dynamically. Note that the library is quite large (a couple of MBs). Here's a portion of my makefile that compiles a program (&lt;tt class="docutils literal"&gt;gcd_iter.c&lt;/tt&gt;, which we'll see soon) and links it successfully with libjit:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;LIBJIT_PATH = $$HOME/test/libjit
LIBJIT_INCLUDE_PATH = &lt;span style="color: #00007f; font-weight: bold"&gt;$(&lt;/span&gt;LIBJIT_PATH&lt;span style="color: #00007f; font-weight: bold"&gt;)&lt;/span&gt;/include
LIBJIT_LIB_PATH = &lt;span style="color: #00007f; font-weight: bold"&gt;$(&lt;/span&gt;LIBJIT_PATH&lt;span style="color: #00007f; font-weight: bold"&gt;)&lt;/span&gt;/jit/.libs
LIBJIT_AR = &lt;span style="color: #00007f; font-weight: bold"&gt;$(&lt;/span&gt;LIBJIT_LIB_PATH&lt;span style="color: #00007f; font-weight: bold"&gt;)&lt;/span&gt;/libjit.a

CC = gcc
LD = gcc
CCOPT = -g -O0
CCFLAGS = -c &lt;span style="color: #00007f; font-weight: bold"&gt;$(&lt;/span&gt;CCOPT&lt;span style="color: #00007f; font-weight: bold"&gt;)&lt;/span&gt;
LDFLAGS = -lpthread -lm -ldl

gcd_iter: gcd_iter.o
      &lt;span style="color: #00007f; font-weight: bold"&gt;$(&lt;/span&gt;LD&lt;span style="color: #00007f; font-weight: bold"&gt;)&lt;/span&gt; $^ &lt;span style="color: #00007f; font-weight: bold"&gt;$(&lt;/span&gt;LIBJIT_AR&lt;span style="color: #00007f; font-weight: bold"&gt;)&lt;/span&gt; &lt;span style="color: #00007f; font-weight: bold"&gt;$(&lt;/span&gt;LDFLAGS&lt;span style="color: #00007f; font-weight: bold"&gt;)&lt;/span&gt; -o $@

gcd_iter.o: gcd_iter.c
      &lt;span style="color: #00007f; font-weight: bold"&gt;$(&lt;/span&gt;CC&lt;span style="color: #00007f; font-weight: bold"&gt;)&lt;/span&gt; -I&lt;span style="color: #00007f; font-weight: bold"&gt;$(&lt;/span&gt;LIBJIT_INCLUDE_PATH&lt;span style="color: #00007f; font-weight: bold"&gt;)&lt;/span&gt; -I. &lt;span style="color: #00007f; font-weight: bold"&gt;$(&lt;/span&gt;CCFLAGS&lt;span style="color: #00007f; font-weight: bold"&gt;)&lt;/span&gt; $^ -o $@
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is a completely generic &amp;quot;out of source&amp;quot; build. Your code can be located anywhere - all you need to supply is &lt;tt class="docutils literal"&gt;LIBJIT_PATH&lt;/tt&gt;. It builds and links libjit statically.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="creating-a-simple-program"&gt;
&lt;h3&gt;Creating a simple program&lt;/h3&gt;
&lt;p&gt;The libjit tutorial has code for recursive GCD computation. Let's see how to write an iterative one, which contains a loop and somewhat more temporary value traffic. We'll build a JIT function that implements this algorithm:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt; &lt;span style="color: #00007f"&gt;gcd_iter&lt;/span&gt;(&lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt; u, &lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt; v) {
  &lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt; t;
  &lt;span style="color: #00007f; font-weight: bold"&gt;while&lt;/span&gt; (v) {
    t = u;
    u = v;
    v = t % v;
  }
  &lt;span style="color: #00007f; font-weight: bold"&gt;return&lt;/span&gt; u &amp;lt; &lt;span style="color: #007f7f"&gt;0&lt;/span&gt; ? -u : u; &lt;span style="color: #007f00"&gt;/* abs(u) */&lt;/span&gt;
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here it is:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #007f00"&gt;// Returns an uncompiled jit_function_t.&lt;/span&gt;
jit_function_t &lt;span style="color: #00007f"&gt;build_gcd_func&lt;/span&gt;(jit_context_t context) {
  jit_context_build_start(context);

  &lt;span style="color: #007f00"&gt;// Create function signature and object. int (*)(int, int)&lt;/span&gt;
  jit_type_t params[&lt;span style="color: #007f7f"&gt;2&lt;/span&gt;] = {jit_type_int, jit_type_int};
  jit_type_t signature = jit_type_create_signature(
      jit_abi_cdecl, jit_type_int, params, &lt;span style="color: #007f7f"&gt;2&lt;/span&gt;, &lt;span style="color: #007f7f"&gt;1&lt;/span&gt;);
  jit_function_t F = jit_function_create(context, signature);

  &lt;span style="color: #007f00"&gt;// u, v are function parameters; t is a temporary value.&lt;/span&gt;
  jit_value_t u, v, t;
  u = jit_value_get_param(F, &lt;span style="color: #007f7f"&gt;0&lt;/span&gt;);
  v = jit_value_get_param(F, &lt;span style="color: #007f7f"&gt;1&lt;/span&gt;);
  t = jit_value_create(F, jit_type_int);

  &lt;span style="color: #007f00"&gt;// Create the while (v) condition with a label that allows to loop back.&lt;/span&gt;
  &lt;span style="color: #007f00"&gt;//&lt;/span&gt;
  &lt;span style="color: #007f00"&gt;// label_while:&lt;/span&gt;
  &lt;span style="color: #007f00"&gt;//   if (v == 0) goto label_after_while&lt;/span&gt;
  &lt;span style="color: #007f00"&gt;//   .. contents of while loop&lt;/span&gt;
  &lt;span style="color: #007f00"&gt;//&lt;/span&gt;
  &lt;span style="color: #007f00"&gt;// label_after_while is created as undefined at this point, so that&lt;/span&gt;
  &lt;span style="color: #007f00"&gt;// instructions can have forward references to it. It will be placed later.&lt;/span&gt;
  jit_label_t label_while = jit_label_undefined;
  jit_label_t label_after_while = jit_label_undefined;
  jit_value_t const0 = jit_value_create_nint_constant(F, jit_type_int, &lt;span style="color: #007f7f"&gt;0&lt;/span&gt;);

  jit_insn_label(F, &amp;amp;label_while);
  jit_value_t cmp_v_0 = jit_insn_eq(F, v, const0);
  jit_insn_branch_if(F, cmp_v_0, &amp;amp;label_after_while);

  &lt;span style="color: #007f00"&gt;// t = u&lt;/span&gt;
  jit_insn_store(F, t, u);
  &lt;span style="color: #007f00"&gt;// u = v&lt;/span&gt;
  jit_insn_store(F, u, v);

  &lt;span style="color: #007f00"&gt;// v = t % v&lt;/span&gt;
  jit_value_t rem = jit_insn_rem(F, t, v);
  jit_insn_store(F, v, rem);

  &lt;span style="color: #007f00"&gt;//   goto label_while&lt;/span&gt;
  &lt;span style="color: #007f00"&gt;// label_after_while:&lt;/span&gt;
  &lt;span style="color: #007f00"&gt;//   ...&lt;/span&gt;
  jit_insn_branch(F, &amp;amp;label_while);
  jit_insn_label(F, &amp;amp;label_after_while);

  &lt;span style="color: #007f00"&gt;//   if (u &amp;gt;= 0) goto label_positive&lt;/span&gt;
  &lt;span style="color: #007f00"&gt;//   return -u&lt;/span&gt;
  &lt;span style="color: #007f00"&gt;// label_pos:&lt;/span&gt;
  &lt;span style="color: #007f00"&gt;//   return u&lt;/span&gt;
  jit_label_t label_positive = jit_label_undefined;
  jit_value_t cmp_u_0 = jit_insn_ge(F, u, const0);
  jit_insn_branch_if(F, cmp_u_0, &amp;amp;label_positive);

  jit_value_t minus_u = jit_insn_neg(F, u);
  jit_insn_return(F, minus_u);
  jit_insn_label(F, &amp;amp;label_positive);
  jit_insn_return(F, u);

  jit_context_build_end(context);
  &lt;span style="color: #00007f; font-weight: bold"&gt;return&lt;/span&gt; F;
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The code should be quite readable now, but for extra points take a look at the reference documentation for the APIs used. Just a word of caution: the most up-to-date reference documentation for libjit is in code comments in the latests git snapshot.&lt;/p&gt;
&lt;p&gt;Another note, on error reporting. libjit is, unfortunately, not very good at it. If you do something wrong, it will bite you. I've spent almost an hour chasing a bizarre stack-thrashing bug because &lt;tt class="docutils literal"&gt;t&lt;/tt&gt; was not initialized with &lt;tt class="docutils literal"&gt;jit_value_create&lt;/tt&gt;. I had initially written the code expecting &lt;tt class="docutils literal"&gt;jit_insn_store(F, t, u)&lt;/tt&gt; to just do the right thing. It doesn't. And it doesn't tell you about it either. Initialize your &lt;tt class="docutils literal"&gt;jit_value_t&lt;/tt&gt; variables!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="interpreted-vs-compiled"&gt;
&lt;h3&gt;Interpreted vs. compiled&lt;/h3&gt;
&lt;p&gt;As mentioned above, the libjit API defines an IR for describing programs. libjit has a built-in interpreter that can execute programs directly from this IR, without lowering further to machine code. This is used on architectures for which libjit doesn't yet have a backend. On architectures that do have a backend (like the x86-64 machine I'm working on), the default build sequence will only link the machine-specific backend in.&lt;/p&gt;
&lt;p&gt;This can be changed by passing the &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--enable-interpreter&lt;/span&gt;&lt;/tt&gt; flag to &lt;tt class="docutils literal"&gt;./configure&lt;/tt&gt;. The flag tells the configuration script to set up the interpreter as the backend, leaving the machine-specific code generators out. This can be useful for debugging libjit as well. We'll see some performance numbers for the interpreter later.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="running-the-jit-ed-code-apply-vs-direct-invocation"&gt;
&lt;h3&gt;Running the JIT-ed code: apply vs. direct invocation&lt;/h3&gt;
&lt;p&gt;How do we run the GCD function built by &lt;tt class="docutils literal"&gt;build_gcd_func&lt;/tt&gt;? The most straightforward way is using &lt;tt class="docutils literal"&gt;jit_function_apply&lt;/tt&gt;:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;jit_function_t gcd = build_gcd_func(context);

&lt;span style="color: #007f00"&gt;// Compile (JIT) the function to machine code&lt;/span&gt;
jit_context_build_start(context);
jit_function_compile(gcd);
jit_context_build_end(context);

&lt;span style="color: #007f00"&gt;// Run the function on argv input&lt;/span&gt;
&lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt; u = atoi(argv[&lt;span style="color: #007f7f"&gt;1&lt;/span&gt;]);
&lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt; v = atoi(argv[&lt;span style="color: #007f7f"&gt;2&lt;/span&gt;]);
&lt;span style="color: #00007f; font-weight: bold"&gt;void&lt;/span&gt;* args[&lt;span style="color: #007f7f"&gt;2&lt;/span&gt;] = {&amp;amp;u, &amp;amp;v};

jit_int result;
jit_function_apply(gcd, args, &amp;amp;result);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;jit_function_apply&lt;/tt&gt; is a fully general method for invoking JIT-ed code from dynamic language runtimes. It makes no assumptions for the &lt;em&gt;caller&lt;/em&gt; - the addresses of arguments are taken, and &lt;tt class="docutils literal"&gt;jit_function_apply&lt;/tt&gt; uses the signature of the called function object to figure out how to provide these arguments to the actual function (w.r.t. calling convention, etc) &lt;a class="footnote-reference" href="#id7" id="id3"&gt;[3]&lt;/a&gt;. It also provides the ability to compile the function on-demand, sets up libjit-specific exception handling, etc.&lt;/p&gt;
&lt;p&gt;While great for dynamic language runtimes, when we just want to call JIT-ed code from a compiled C or C++ program, &lt;tt class="docutils literal"&gt;jit_function_apply&lt;/tt&gt; carries needless overhead. Since the caller in this case almost certainly has the same calling convention (or, in other words, shares the ABI) it's wasteful to go through this general process - why not just get the pointer of the entry point of the JIT-ed code and invoke it directly?&lt;/p&gt;
&lt;p&gt;This is exactly what the libjit &lt;em&gt;closure&lt;/em&gt; &lt;a class="footnote-reference" href="#id8" id="id4"&gt;[4]&lt;/a&gt; mechanism provides. Using a closure, the &lt;tt class="docutils literal"&gt;jit_function_apply&lt;/tt&gt; call is replaced with this:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #00007f; font-weight: bold"&gt;typedef&lt;/span&gt; &lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt; (*FF)(&lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt;, &lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt;);
FF gcd_f = jit_function_to_closure(gcd);
&lt;span style="color: #00007f; font-weight: bold"&gt;int&lt;/span&gt; result = gcd_f(u, v);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;jit_function_to_closure&lt;/tt&gt; returns the address of the entry point (the first instruction) of the JIT-ed code. To call it directly, we must tell the compiler (of the calling code) how to interpret the address, by specifying a function pointer type.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="performance"&gt;
&lt;h3&gt;Performance&lt;/h3&gt;
&lt;p&gt;I ran the GCD computation on two large primes (which resulted in 17 iterations before returning 1), 5 million times in a loop, and compared the runtime of the various libjit run methods (interpreter, apply, closure) vs. the same function implemented in C and compiled natively with &lt;tt class="docutils literal"&gt;gcc &lt;span class="pre"&gt;-O0&lt;/span&gt;&lt;/tt&gt; or &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-O3&lt;/span&gt;&lt;/tt&gt;:&lt;/p&gt;
&lt;img class="align-center" src="https://eli.thegreenplace.net/images/2013/10/libjit_chart_1.png" /&gt;
&lt;p&gt;Some thoughts on these results:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The interpreter is indeed slow, but not as slow as I'd expect. I'm actually impressed that it provides reasonable performance, given how low-level the libjit IR is.&lt;/li&gt;
&lt;li&gt;The large difference between apply and closure is due to the short function runtime. Only 17 iterations of the GCD loop fly by quickly, but for &lt;tt class="docutils literal"&gt;jit_function_apply&lt;/tt&gt; we pay the large overhead for switching from native to JIT-ed code on every call. If the function was longer-running, I'm sure that the difference between apply and closure would be smaller. Note also that the overhead is only paid when moving from native to JIT and back - calls bounded within the JIT-ed code are fast.&lt;/li&gt;
&lt;li&gt;It does not surprise me that libjit (with the closure call approach) beats &lt;tt class="docutils literal"&gt;gcc &lt;span class="pre"&gt;-O0&lt;/span&gt;&lt;/tt&gt;. Keep in mind that &lt;tt class="docutils literal"&gt;gcc &lt;span class="pre"&gt;-O0&lt;/span&gt;&lt;/tt&gt; starts from C code, while for libjit we laid out a very low-level IR representation manually. So we've basically done all the compilation work and handed the results to execution. Still, some things (like register allocation and peephole optimizations) live below this level, which is why &lt;tt class="docutils literal"&gt;gcc &lt;span class="pre"&gt;-O3&lt;/span&gt;&lt;/tt&gt; managed to produce code that's 25% faster than libjit.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="what-s-next"&gt;
&lt;h3&gt;What's next&lt;/h3&gt;
&lt;p&gt;In future parts of this article I intend to look at the machine code generated by libjit, as well as explore its other features such as calls from JITed to native code. All the code for the article is free (public domain) and available in my &lt;a class="reference external" href="https://github.com/eliben/libjit-samples"&gt;libjit-samples&lt;/a&gt;  Github repository.&lt;/p&gt;
&lt;img class="align-center" src="https://eli.thegreenplace.net/images/hline.jpg" style="width: 320px; height: 5px;" /&gt;
&lt;table class="docutils footnote" frame="void" id="id5" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;The paper &amp;quot;A brief history of Just-In-Time&amp;quot; by John Aycock states that the earliest signs for JIT ideas can be found in McCarthy's original LISP research from the early 1960s. It was just not called &amp;quot;JIT&amp;quot; those days - this term was coined for Java and taken from the world of manufacturing.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id6" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id2"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;I originally quoted the &lt;a class="reference external" href="http://en.wikipedia.org/wiki/DotGNU"&gt;DotGNU Wikipedia page&lt;/a&gt; which also said that libjit IR keeps variables in static single assignment (SSA) form. After discussing this with Aleksey Demakov, the current maintainer of libjit, I removed that part because libjit doesn't really use SSA. Store instructions may be used to assign different values to the same variable within a single basic block, and there are also no Phi nodes. In LLVM, on the other hand, all register values are kept in SSA form.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id7" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id3"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;This is similar to how foreign function interfaces (FFI) work; for example, &lt;a class="reference external" href="http://sourceware.org/libffi/"&gt;libffi&lt;/a&gt;.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id8" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id4"&gt;[4]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Not the best usage for the term closure, IMHO, but I'll stick to it since this is the nomenclature in libjit's code and documentation.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

    </content><category term="misc"></category><category term="Assembly"></category><category term="C &amp; C++"></category><category term="Code generation"></category></entry><entry><title>A deeper look into the LLVM code generator, Part 1</title><link href="https://eli.thegreenplace.net/2013/02/25/a-deeper-look-into-the-llvm-code-generator-part-1" rel="alternate"></link><published>2013-02-25T05:42:20-08:00</published><updated>2023-06-30T23:16:27-07:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2013-02-25:/2013/02/25/a-deeper-look-into-the-llvm-code-generator-part-1</id><summary type="html">
        &lt;p&gt;In a &lt;a class="reference external" href="https://eli.thegreenplace.net/2012/11/24/life-of-an-instruction-in-llvm/"&gt;previous article&lt;/a&gt;, I followed the various incarnations an instruction takes when it's being compiled from the source language to machine code in LLVM. The article briefly mentioned a lot of layers within LLVM, each of which is interesting and non trivial.&lt;/p&gt;
&lt;p&gt;Here I want to focus on one â€¦&lt;/p&gt;</summary><content type="html">
        &lt;p&gt;In a &lt;a class="reference external" href="https://eli.thegreenplace.net/2012/11/24/life-of-an-instruction-in-llvm/"&gt;previous article&lt;/a&gt;, I followed the various incarnations an instruction takes when it's being compiled from the source language to machine code in LLVM. The article briefly mentioned a lot of layers within LLVM, each of which is interesting and non trivial.&lt;/p&gt;
&lt;p&gt;Here I want to focus on one of the most important and complex layers - the code generator, and specifically the instruction selection mechanism. A short reminder: the task of the code generator is to transform the high-level, mostly target-independent LLVM IR into low-level, target dependent machine language. Instruction selection is the process wherein the abstract operations in IR are mapped to concrete instructions of the target architecture.&lt;/p&gt;
&lt;p&gt;This article will follow a simple example to show the instruction selection mechanism in action (&lt;em&gt;ISel&lt;/em&gt; in LLVM parlance).&lt;/p&gt;
&lt;div class="section" id="getting-started-a-dag-for-simple-multiplication"&gt;
&lt;h3&gt;Getting started: a DAG for simple multiplication&lt;/h3&gt;
&lt;p&gt;Here's some sample IR:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;define i64 @imul(i64 %a, i64 %b) nounwind readnone {
entry:
  %mul = mul nsw i64 %b, %a
  ret i64 %mul
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It's compiled with Clang (&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-emit-llvm&lt;/span&gt;&lt;/tt&gt; option) on a x64 machine from this C code:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span style="color: #00007f; font-weight: bold"&gt;long&lt;/span&gt; &lt;span style="color: #00007f"&gt;imul&lt;/span&gt;(&lt;span style="color: #00007f; font-weight: bold"&gt;long&lt;/span&gt; a, &lt;span style="color: #00007f; font-weight: bold"&gt;long&lt;/span&gt; b) {
    &lt;span style="color: #00007f; font-weight: bold"&gt;return&lt;/span&gt; a * b;
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The first thing done by the code generator is convert the IR into a selection DAG representation. This is the initial DAG, right after it's built:&lt;/p&gt;
&lt;img class="align-center" src="https://eli.thegreenplace.net/images/2013/dag_imul5.png" /&gt;
&lt;p&gt;There's really not much interesting going on here, and all the types are legal for the target architecture; therefore, this is also the DAG that reaches the instruction selection stage.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="patterns-for-instruction-selection"&gt;
&lt;h3&gt;Patterns for instruction selection&lt;/h3&gt;
&lt;p&gt;Instruction selection is arguably the most important part of the code generation phase. Its task is to convert a legal selection DAG into a new DAG of target machine code. In other words, the abstract, target-independent input has to be matched to concrete, target-dependent output. For this purpose LLVM uses an elaborate pattern-matching algorithm that consists of two major steps.&lt;/p&gt;
&lt;p&gt;The first step happens &amp;quot;offline&amp;quot;, when LLVM itself is being built, and involves the TableGen tool, which generates the pattern matching tables from instruction definitions. TableGen is an important part of the LLVM eco-system, and it plays an especially central role in instruction selection, so it's worthwhile to spend a couple of minutes talking about it (there's also official documentation, starting with &lt;a class="reference external" href="http://llvm.org/docs/TableGenFundamentals.html"&gt;TableGen fundamentals&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The problem with TableGen is that some of its uses are so complex (and instruction selection, as we'll shortly see, is one of the worst offenders) that it's easy to forget how simple the idea is in its core. The LLVM developers realized a long time ago that a lot of repetitive code has to be written for each new target. Take a machine instruction, for instance. An instruction is being used in code generation, in the assembler, in the disassembler, in optimizers, and in many other places. Each such use results in a &amp;quot;table&amp;quot; that maps instructions to some piece of information. Wouldn't it be nice if we could just define all instructions in one central place which collects all the interesting information we need about them and then generate all the tables automatically? This is precisely what TableGen was born to do.&lt;/p&gt;
&lt;p&gt;Let's examine an instruction definition relevant to this article (taken from &lt;tt class="docutils literal"&gt;lib/Target/X86/X86InstrArithmetic.td&lt;/tt&gt; and reformatted a bit):&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;def IMUL64rr : RI&amp;lt;0xAF, MRMSrcReg, (outs GR64:$dst),
                                   (ins GR64:$src1, GR64:$src2),
                  &amp;quot;imul{q}\t{$src2, $dst|$dst, $src2}&amp;quot;,
                  [(set GR64:$dst, EFLAGS,
                        (X86smul_flag GR64:$src1, GR64:$src2))],
                  IIC_IMUL64_RR&amp;gt;,
                 TB;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If this looks like gibberish, don't worry, that's the right first impression to have. To factor out common code and fanatically preserve DRY, TableGen grew some advanced features like multiple inheritance, a form of templating and more; all of these make definitions somewhat difficult to understand at first. If you want to see the &amp;quot;naked&amp;quot; definition of &lt;tt class="docutils literal"&gt;IMUL64rr&lt;/tt&gt;, you can run this from the root of the LLVM source tree:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;$ llvm-tblgen lib/Target/X86/X86.td -I=include -I=lib/Target/X86
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The 13.5 MB output only contains simple &lt;tt class="docutils literal"&gt;defs&lt;/tt&gt; - table entries from which TableGen backends can take what they need. The &lt;tt class="docutils literal"&gt;def&lt;/tt&gt; for &lt;tt class="docutils literal"&gt;IMUL64rr&lt;/tt&gt; has something like 75 fields. But we'll only focus on the ones we need for this article, and the condensed description pasted above will do.&lt;/p&gt;
&lt;p&gt;The most important field for our discussion is the sixth template argument in the &lt;tt class="docutils literal"&gt;def&lt;/tt&gt; above:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;[(set GR64:$dst, EFLAGS,
      (X86smul_flag GR64:$src1, GR64:$src2))],
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is the &lt;em&gt;pattern&lt;/em&gt; on which the &lt;tt class="docutils literal"&gt;IMUL64rr&lt;/tt&gt; can be selected. It's essentially &lt;a class="reference external" href="http://en.wikipedia.org/wiki/S_expression"&gt;an s-expression&lt;/a&gt; describing the DAG path that will be matched. In this case it roughly means: an &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;X86ISD::SMUL&lt;/span&gt;&lt;/tt&gt; node (this is concealed behind the &lt;tt class="docutils literal"&gt;X86smul_flag&lt;/tt&gt; definition) with two 64-bit GPR (General Purpose Register) arguments is invoked and returns two results - one assigned to a destination GPR and the other to the status flag register &lt;a class="footnote-reference" href="#id8" id="id1"&gt;[1]&lt;/a&gt;. When the automatic instruction selection sees such a sequence in the DAG, it will
match it to the said &lt;tt class="docutils literal"&gt;IMUL64rr&lt;/tt&gt; instruction.&lt;/p&gt;
&lt;p&gt;A careful reader will, at this point, notice that I'm cheating a little bit. If the node matched by this pattern is &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;X86ISD::SMUL&lt;/span&gt;&lt;/tt&gt;, then how did it match the DAG shown above which has an &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;ISD::MUL&lt;/span&gt;&lt;/tt&gt; node? Indeed, it didn't. I will show the pattern that actually matches the DAG shortly, but I felt it's important to demonstrate the instruction definitions with patterns, to enable me to discuss how all patterns are mashed together later.&lt;/p&gt;
&lt;p&gt;So what is the difference between &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;ISD::MUL&lt;/span&gt;&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;X86ISD::SMUL&lt;/span&gt;&lt;/tt&gt; &lt;a class="footnote-reference" href="#id9" id="id2"&gt;[2]&lt;/a&gt; ? In the former, we don't care about the actual flags affected by the multiplication, while in the latter we do. In the case of multiplication in C, we usually don't care about the flags affected, hence &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;ISD::MUL&lt;/span&gt;&lt;/tt&gt; is selected. But LLVM provides some special intrinsics such as &lt;tt class="docutils literal"&gt;llvm.smul.with.overflow&lt;/tt&gt; in which an overflow flag can be returned from the operation. For these (and possibly other uses), the &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;X86ISD::SMUL&lt;/span&gt;&lt;/tt&gt; node exists &lt;a class="footnote-reference" href="#id10" id="id3"&gt;[3]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;What, then, actually matches the &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;ISD::MUL&lt;/span&gt;&lt;/tt&gt; node here? This pattern from &lt;tt class="docutils literal"&gt;lib/Target/X86/X86InstrCompiler.td&lt;/tt&gt;:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;def : Pat&amp;lt;(mul GR64:$src1, GR64:$src2),
          (IMUL64rr GR64:$src1, GR64:$src2)&amp;gt;;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is an anonymous TableGen record that defines a &amp;quot;pattern&amp;quot; which is detached from any specific instruction. The pattern is simply a mapping from a DAG input to DAG output, the latter containing a selected instruction. We don't care how this mapping is called, so TableGen lets us define anonymous instances. In this case, the pattern should be fairly straightforward. Here's an interesting snippet from &lt;tt class="docutils literal"&gt;include/llvm/Target/TargetSelectionDAG.td&lt;/tt&gt;, where the &lt;tt class="docutils literal"&gt;Pattern&lt;/tt&gt; class (and its &lt;tt class="docutils literal"&gt;Pat&lt;/tt&gt; specialization) is defined:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;// Selection DAG Pattern Support.
//
// Patterns are what are actually matched against by the target-flavored
// instruction selection DAG.  Instructions defined by the target implicitly
// define patterns in most cases, but patterns can also be explicitly added when
// an operation is defined by a sequence of instructions (e.g. loading a large
// immediate value on RISC targets that do not support immediates as large as
// their GPRs).
//

class Pattern&amp;lt;dag patternToMatch, list&amp;lt;dag&amp;gt; resultInstrs&amp;gt; {
  dag             PatternToMatch  = patternToMatch;
  list&amp;lt;dag&amp;gt;       ResultInstrs    = resultInstrs;
  list&amp;lt;Predicate&amp;gt; Predicates      = [];  // See class Instruction in Target.td.
  int             AddedComplexity = 0;   // See class Instruction in Target.td.
}

// Pat - A simple (but common) form of a pattern, which produces a simple result
// not needing a full list.
class Pat&amp;lt;dag pattern, dag result&amp;gt; : Pattern&amp;lt;pattern, [result]&amp;gt;;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The large comment at the top of this snippet is helpful, but it describes an exactly opposite situation of what we're observing for &lt;tt class="docutils literal"&gt;IMUL64rr&lt;/tt&gt;. In our case, the pattern defined within the instruction is actually the more complex one, while the basic pattern is defined outside with a &lt;tt class="docutils literal"&gt;Pattern&lt;/tt&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-pattern-matching-mechanism"&gt;
&lt;h3&gt;The pattern matching mechanism&lt;/h3&gt;
&lt;p&gt;TableGen descriptions of target instructions support numerous pattern kinds. We've examined patterns implicitly defined within instruction definitions and patterns explicitly defined as stand-alones. In addition there are also &amp;quot;complex&amp;quot; patterns that specify a C++ function to be called, and &amp;quot;pattern fragments&amp;quot; that can contain arbitrary snippets of C++ code that do custom matching. If you're interested, these pattern types are somewhat described in the comments within &lt;tt class="docutils literal"&gt;include/llvm/Target/TargetSelectionDAG.td&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;Mixing up C++ code in TableGen works because the final result of the TableGen run (with the specific DAG ISel backend) is a C++ method that gets embedded into a target's implementation of the &lt;tt class="docutils literal"&gt;SelectionDAGISel&lt;/tt&gt; interface.&lt;/p&gt;
&lt;p&gt;To be more specific, the sequence is:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The generic &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;SelectionDAGISel::DoInstructionSelection&lt;/span&gt;&lt;/tt&gt; method calls &lt;tt class="docutils literal"&gt;Select&lt;/tt&gt; per DAG node.&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;Select&lt;/tt&gt; is an abstract method, implemented by the targets. For example &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;X86DAGToDAGISel::Select&lt;/span&gt;&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;The latter intercepts some nodes for manual matching, but delegates the bulk of the work to &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;X86DAGToDAGISel::SelectCode&lt;/span&gt;&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;X86DAGToDAGISel::SelectCode&lt;/span&gt;&lt;/tt&gt; is auto-generated by TableGen &lt;a class="footnote-reference" href="#id11" id="id4"&gt;[4]&lt;/a&gt;, and contains the matcher table, followed by a call to the generic &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;SelectionDAGISel::SelectCodeCommon&lt;/span&gt;&lt;/tt&gt;, passing it the table.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So what is the matcher table? Essentially, it's a &amp;quot;program&amp;quot; written in a sort of a &amp;quot;bytecode&amp;quot; specific for instruction selection. To enable flexible pattern matching while staying efficient, TableGen munges all the patterns together and generates a program that, given a DAG mode, figures out which pattern it matches. &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;SelectionDAGISel::SelectCodeCommon&lt;/span&gt;&lt;/tt&gt; serves as the interpreter for this bytecode.&lt;/p&gt;
&lt;p&gt;Unfortunately, the bytecode language for pattern matching is not documented anywhere. To understand how it works, there's no substitute to looking at the interpreter code and at the generated bytecode for some backend &lt;a class="footnote-reference" href="#id12" id="id5"&gt;[5]&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="example-matching-our-sample-dag-node"&gt;
&lt;h3&gt;Example: matching our sample DAG node&lt;/h3&gt;
&lt;p&gt;Let's examine how the &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;ISD::MUL&lt;/span&gt;&lt;/tt&gt; node in our sample DAG is matched. For this purpose, it's very useful to pass the &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-debug&lt;/span&gt;&lt;/tt&gt; option to &lt;tt class="docutils literal"&gt;llc&lt;/tt&gt;, which makes it dump detailed debugging information throughout the code generation process. In particular, the selection process for each DAG node can be traced. Here's the relevant portion for our &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;ISD::MUL&lt;/span&gt;&lt;/tt&gt; node:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;Selecting: 0x38c4ee0: i64 = mul 0x38c4de0, 0x38c4be0 [ORD=1] [ID=7]

ISEL: Starting pattern match on root node: 0x38c4ee0: i64 = mul 0x38c4de0, 0x38c4be0 [ORD=1] [ID=7]

  Initial Opcode index to 57917
  Match failed at index 57922
  Continuing at 58133
  Match failed at index 58137
  Continuing at 58246
  Match failed at index 58249
  Continuing at 58335
  TypeSwitch[i64] from 58337 to 58380
MatchAddress: X86ISelAddressMode 0x7fff447ca040
Base_Reg nul Base.FrameIndex 0
 Scale1
IndexReg nul Disp 0
GV nul CP nul
ES nul JT-1 Align0
  Match failed at index 58380
  Continuing at 58396
  Match failed at index 58407
  Continuing at 58516
  Match failed at index 58517
  Continuing at 58531
  Match failed at index 58532
  Continuing at 58544
  Match failed at index 58545
  Continuing at 58557
  Morphed node: 0x38c4ee0: i64,i32 = IMUL64rr 0x38c4de0, 0x38c4be0 [ORD=1]

ISEL: Match complete!
=&amp;gt; 0x38c4ee0: i64,i32 = IMUL64rr 0x38c4de0, 0x38c4be0 [ORD=1]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The indices mentioned here refer to the matcher table. You can see them in a comment at the beginning of each line in the generated &lt;tt class="docutils literal"&gt;X86GenDAGISel.inc&lt;/tt&gt; file. Here's the beginning of that table &lt;a class="footnote-reference" href="#id13" id="id6"&gt;[6]&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;// The main instruction selector code.
SDNode *SelectCode(SDNode *N) {
  // Some target values are emitted as 2 bytes, TARGET_VAL handles
  // this.
  #define TARGET_VAL(X) X &amp;amp; 255, unsigned(X) &amp;gt;&amp;gt; 8
  static const unsigned char MatcherTable[] = {
/*0*/     OPC_SwitchOpcode /*221 cases */, 73|128,103/*13257*/,  TARGET_VAL(ISD::STORE),// -&amp;gt;13262
/*5*/       OPC_RecordMemRef,
/*6*/       OPC_RecordNode,   // #0 = &amp;#39;st&amp;#39; chained node
/*7*/       OPC_Scope, 5|128,2/*261*/, /*-&amp;gt;271*/ // 7 children in Scope
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;At position 0 we have a &lt;tt class="docutils literal"&gt;OPC_SwitchOpcode&lt;/tt&gt; operation, which is kind of a huge switch table on the node opcode. It's followed by a list of cases. Each case begins with its size (so that the matcher knows where to go if matching the case fails), and then the opcode. For example, as you can see in the listing above, the first case in the table is for opcode &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;ISD::STORE&lt;/span&gt;&lt;/tt&gt;, and its size is 13257 (the size is encoded in a special variable-length-encoding since the table is byte-based).&lt;/p&gt;
&lt;p&gt;Looking at the debug output, the matching of our &lt;tt class="docutils literal"&gt;MUL&lt;/tt&gt; node starts at offset 57917. Here's the relevant part of the table:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;          /*SwitchOpcode*/ 53|128,8/*1077*/,  TARGET_VAL(ISD::MUL),// -&amp;gt;58994
/*57917*/   OPC_Scope, 85|128,1/*213*/, /*-&amp;gt;58133*/ // 7 children in Scope
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So, as expected, this is the switch case with &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;ISD::MUL&lt;/span&gt;&lt;/tt&gt; as the opcode. The matching for this case starts with &lt;tt class="docutils literal"&gt;OPC_Scope&lt;/tt&gt;, which is an instruction to the interpreter to push its current state. If something fails within the scope, the state can be then restored to proceed with matching the next cases. In the snippet above, if matching fails in the scope, it will proceed in offset 58133.&lt;/p&gt;
&lt;p&gt;You can see this happening in the debug output:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;Initial Opcode index to 57917
Match failed at index 57922
Continuing at 58133
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;At 57922, the interpreter tries to match the child of the node to a &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;ISD::LOAD&lt;/span&gt;&lt;/tt&gt; (meaning - multiply with in-memory argument), fails, and jumps to 58133 as the scope dictates. Similarly, the rest of the matching process can be traced - following the debug output and the matching table as a reference. Something interesting happens at offset 58337 though. Here's the relevant table part:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;/*58337*/     OPC_SwitchType /*2 cases */, 38,  MVT::i32,// -&amp;gt;58378
/*58340*/       OPC_Scope, 17, /*-&amp;gt;58359*/ // 2 children in Scope
/*58342*/         OPC_CheckPatternPredicate, 4, // (!Subtarget-&amp;gt;is64Bit())
/*58344*/         OPC_CheckComplexPat, /*CP*/3, /*#*/0, // SelectLEAAddr:$src #1 #2 #3 #4 #5
/*58347*/         OPC_MorphNodeTo, TARGET_VAL(X86::LEA32r), 0,
                      1/*#VTs*/, MVT::i32, 5/*#Ops*/, 1, 2, 3, 4, 5,
                  // Src: lea32addr:i32:$src - Complexity = 18
                  // Dst: (LEA32r:i32 lea32addr:i32:$src)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is the result of a &lt;em&gt;complex pattern&lt;/em&gt; described above. &lt;tt class="docutils literal"&gt;SelectLEAAddr&lt;/tt&gt; is a C++ method (defined by the X86 backen's ISel implementation) and it gets invoked to try and match the node operand to a LEA &lt;a class="footnote-reference" href="#id14" id="id7"&gt;[7]&lt;/a&gt;. The debug printout that follows comes from that method, and as we can see, eventually fails.&lt;/p&gt;
&lt;p&gt;Finally, where the interpreter reaches offset 58557, the match succeeds. Here's the relevant table part:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;/*58557*/       /*Scope*/ 12, /*-&amp;gt;58570*/
/*58558*/         OPC_CheckType, MVT::i64,
/*58560*/         OPC_MorphNodeTo, TARGET_VAL(X86::IMUL64rr), 0,
                      2/*#VTs*/, MVT::i64, MVT::i32, 2/*#Ops*/, 0, 1,
                  // Src: (mul:i64 GR64:i64:$src1, GR64:i64:$src2) - Complexity = 3
                  // Dst: (IMUL64rr:i64:i32 GR64:i64:$src1, GR64:i64:$src2)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Simply put, after it fails matching a bunch of optimizations and special cases, the matcher finally uses a generic integer-multiply between 64-bit registers, which is matched to the &lt;tt class="docutils literal"&gt;IMUL64rr&lt;/tt&gt; machine instruction.&lt;/p&gt;
&lt;p&gt;If it appears from the trace that the instruction selector works hard to find a suitable instruction, that is true. To generate good code, some work has to be done to try and match various optimized sequences before falling back to generic ones. In the next part of the article, I will show some more advanced cases of instruction selection with optimization.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-final-code"&gt;
&lt;h3&gt;The final code&lt;/h3&gt;
&lt;p&gt;This is how the DAG looks &lt;em&gt;after&lt;/em&gt; instruction selection:&lt;/p&gt;
&lt;img class="align-center" src="https://eli.thegreenplace.net/images/2013/dag_imul_postisel.png" /&gt;
&lt;p&gt;Since the entry DAG was pretty basic, this one is very similar; the main difference is that the multiplication and return nodes were selected to actual instructions.&lt;/p&gt;
&lt;p&gt;If you remember from &lt;a class="reference external" href="https://eli.thegreenplace.net/2012/11/24/life-of-an-instruction-in-llvm/"&gt;the life of an instruction in LLVM article&lt;/a&gt;, the instruction goes through a couple of additional incarnations after being matched by the instruction selector. The final code that gets emitted is:&lt;/p&gt;
&lt;div class="highlight" style="background: #ffffff"&gt;&lt;pre style="line-height: 125%"&gt;imul:                                   # @imul
      imulq   %rsi, %rdi
      movq    %rdi, %rax
      ret
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;imulq&lt;/tt&gt; is the assembly (GAS flavor) representation of &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;X86::IMUL64rr&lt;/span&gt;&lt;/tt&gt;. It  multiplies the function's arguments (according to the AMD64 ABI, the first two integers come in &lt;tt class="docutils literal"&gt;%rsi&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;%rdi&lt;/tt&gt;); then the result is moved to the return register - &lt;tt class="docutils literal"&gt;%rax&lt;/tt&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;This article provided an in-depth peek into the instruction selection process - a key part of the LLVM code generator. While it uses a relatively simple example, it should contain sufficient information to gain some initial understanding of the mechanisms involved. In the next part of the article, I will examine a couple of additional examples through which other aspects of the code generation process should become clearer.&lt;/p&gt;
&lt;img class="align-center" src="https://eli.thegreenplace.net/images/hline.jpg" style="width: 320px; height: 5px;" /&gt;
&lt;table class="docutils footnote" frame="void" id="id8" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Although the status flags are &amp;quot;implicit&amp;quot; on x86 (there's no explicit register you can work with), LLVM treats it as explicit to aid the code generation algorithms.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id9" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id2"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;X86ISD::SMUL&lt;/span&gt;&lt;/tt&gt; is the X86-specific lowering of the generic &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;ISD::SMULO&lt;/span&gt;&lt;/tt&gt; node.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id10" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id3"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;You may have a &amp;quot;oh my, why is this so complex?&amp;quot; reaction at this point. The TL;DR; answer is &amp;quot;compilers are hard, let's go fishing&amp;quot;. A longer rationale would be: the x86 instruction set is very large and complex. Moreover, LLVM is a compiler with many (quite different) targets and much of its machinery is thus engineered to be target-independent. The result is inherent complexity. To put it differently - the x86 TableGen definitions are about 20 KLOC in size. Add to that another 20 KLOC or so of custom C++ lowering code and compare to the Intel architecture manual which contains 3,000 &lt;em&gt;pages&lt;/em&gt; or so. In terms of Kolmogorov complexity, this isn't very bad :-)&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id11" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id4"&gt;[4]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;It's generated into &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;&amp;lt;BUILD_DIR&amp;gt;/lib/Target/X86/X86GenDAGISel.inc&lt;/span&gt;&lt;/tt&gt;, a file that's &lt;tt class="docutils literal"&gt;#included&lt;/tt&gt; by &lt;tt class="docutils literal"&gt;lib/Target/X86/X86ISelDAGToDAG.cpp&lt;/tt&gt;.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id12" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id5"&gt;[5]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;If you want to understand &lt;em&gt;how&lt;/em&gt; this bytecode is generated from the TableGen pattern definitions, you also need to look inside the TableGen DAG ISel backend.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id13" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id6"&gt;[6]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Note that the values in this table are relevant to the version of LLVM I have built for this example (r174056). Changes in X86 pattern definitions may result in different numbering, but the principle is the same.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id14" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id7"&gt;[7]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Some multiplications can be optimized to use the faster &lt;tt class="docutils literal"&gt;LEA&lt;/tt&gt; instruction.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

    </content><category term="misc"></category><category term="Code generation"></category><category term="Compilation"></category><category term="LLVM &amp; Clang"></category></entry></feed>