<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Eli Bendersky's website - EE &amp; Embedded</title><link href="https://eli.thegreenplace.net/" rel="alternate"></link><link href="https://eli.thegreenplace.net/feeds/ee-embedded.atom.xml" rel="self"></link><id>https://eli.thegreenplace.net/</id><updated>2024-05-04T19:46:23-07:00</updated><entry><title>Sum of same-frequency sinusoids</title><link href="https://eli.thegreenplace.net/2023/sum-of-same-frequency-sinusoids/" rel="alternate"></link><published>2023-03-11T19:44:00-08:00</published><updated>2024-05-04T19:46:23-07:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2023-03-11:/2023/sum-of-same-frequency-sinusoids/</id><summary type="html">&lt;p&gt;I was reviewing an electronics textbook the other day, and it made an offhand
comment that &amp;quot;sinusoidal signals of the same frequency always add up to a
sinusoid, even if their magnitudes and phases are different&amp;quot;.
This gave me pause; is that really so? Even with different phases?&lt;/p&gt;
&lt;p&gt;Using EE …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I was reviewing an electronics textbook the other day, and it made an offhand
comment that &amp;quot;sinusoidal signals of the same frequency always add up to a
sinusoid, even if their magnitudes and phases are different&amp;quot;.
This gave me pause; is that really so? Even with different phases?&lt;/p&gt;
&lt;p&gt;Using EE notation, a sinusoidal signal with magnitude &lt;object class="valign-m3" data="https://eli.thegreenplace.net/images/math/86684571efbdc2d7a49562ba00dd15056c517135.svg" style="height: 16px;" type="image/svg+xml"&gt;A_1&lt;/object&gt;, frequency
&lt;img alt="w" class="valign-0" src="https://eli.thegreenplace.net/images/math/aff024fe4ab0fece4091de044c58c9ae4233383a.png" style="height: 8px;" /&gt; and phase &lt;object class="valign-m4" data="https://eli.thegreenplace.net/images/math/3d9f2f00378f60e70beb5531aa2169a534bffe40.svg" style="height: 16px;" type="image/svg+xml"&gt;\phi_1&lt;/object&gt; is &lt;object class="valign-m5" data="https://eli.thegreenplace.net/images/math/6e641a468b62c6db3c69c21e1328e23ad284a748.svg" style="height: 19px;" type="image/svg+xml"&gt;A_1 sin(wt+\phi_1)&lt;/object&gt; &lt;a class="footnote-reference" href="#footnote-1" id="footnote-reference-1"&gt;[1]&lt;/a&gt;. The
book's statement amounts to:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/a1b13ea5023ad1e0b1f2dde7cf495c7da83f6657.svg" style="height: 19px;" type="image/svg+xml"&gt;\[A_1 sin(wt+\phi_1)+A_2 sin(wt+\phi_2)=A_3 sin(wt+\phi_3)\]&lt;/object&gt;
&lt;p&gt;The sum is also a sinusoid with the same frequency, but potentially different
magnitude and phase. I couldn't find this equality in any of my reference books,
so why is it true?&lt;/p&gt;
&lt;div class="section" id="empirical-probing"&gt;
&lt;h2&gt;Empirical probing&lt;/h2&gt;
&lt;p&gt;Let's start by asking whether this is true at all? It's not at all obvious that
this should work. &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/tree/main/2023/sinusoid"&gt;Armed with Python, Numpy and matplotlib&lt;/a&gt;, I
plotted two sinusoidal signals with the same frequency but different magnitudes
and phases:&lt;/p&gt;
&lt;img alt="Two sinusoidal signals plotted together" class="align-center" src="https://eli.thegreenplace.net/images/2023/two-sinusoids.png" /&gt;
&lt;p&gt;Now, plotting their sum in green on the same chart:&lt;/p&gt;
&lt;img alt="Two sinusoidal signals plotted together with their sum signal" class="align-center" src="https://eli.thegreenplace.net/images/2023/sinusoids-with-sum.png" /&gt;
&lt;p&gt;Well, look at that. It seems to be working. I guess it's time to prove it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="proof-using-trig-identities"&gt;
&lt;h2&gt;Proof using trig identities&lt;/h2&gt;
&lt;p&gt;The first proof I want to demonstrate doesn't use any fancy math beyond some
basic trigonometric identities. One of best known ones is:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/78bab16c56ec9b9da0b5dc2543c8a5dabee73f08.svg" style="height: 19px;" type="image/svg+xml"&gt;\[sin(a+b)=sin(a)cos(b)+cos(a)sin(b) \hspace{2cm} (id. 1)\]&lt;/object&gt;
&lt;p&gt;Taking our sum of sinusoids:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/72c2f9d4c2be1adde9b7b4ba1bf94f31b3a8dd15.svg" style="height: 19px;" type="image/svg+xml"&gt;\[A_1 sin(wt+\phi_1)+A_2 sin(wt+\phi_2)\]&lt;/object&gt;
&lt;p&gt;Applying (id.1) to each of the terms, and then regrouping, we get:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/dac6d8532a46bbf7490d4e9083835914b8b61005.svg" style="height: 45px;" type="image/svg+xml"&gt;\[\begin{align*}
&amp;lt;sum&amp;gt;&amp;amp;=A_1\left [sin(wt)cos(\phi_1)+cos(wt)sin(\phi_1)  \right ]+A_2\left [sin(wt)cos(\phi_2)+cos(wt)sin(\phi_2)  \right ]\\
&amp;amp;=\left [A_1 cos(\phi_1) + A_2 cos(\phi_2) \right ]sin(wt)+\left [ A_1 sin(\phi_1) + A_2 sin(\phi_2)\right ]cos(wt)\\
\end{align*}\]&lt;/object&gt;
&lt;p&gt;Now, a change of variables trick: we'll assume we can solve the following
set of equations for some &lt;img alt="B" class="valign-0" src="https://eli.thegreenplace.net/images/math/ae4f281df5a5d0ff3cad6371f76d5c29b6d953ec.png" style="height: 12px;" /&gt; and &lt;img alt="\theta" class="valign-0" src="https://eli.thegreenplace.net/images/math/cb005d76f9f2e394a770c2562c2e150a413b3216.png" style="height: 12px;" /&gt; &lt;a class="footnote-reference" href="#footnote-2" id="footnote-reference-2"&gt;[2]&lt;/a&gt;:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/c605365120049d7ca728477757b12b12efe13fdd.svg" style="height: 46px;" type="image/svg+xml"&gt;\[\begin{align*}
Bcos(\theta)&amp;amp;=A_1 cos(\phi_1)+A_2 cos(\phi_2) \hspace{2cm} (1)\\
Bsin(\theta)&amp;amp;=A_1 sin(\phi_1)+A_2 sin(\phi_2) \hspace{2cm} (2)\\
\end{align*}\]&lt;/object&gt;
&lt;p&gt;To find &lt;img alt="B" class="valign-0" src="https://eli.thegreenplace.net/images/math/ae4f281df5a5d0ff3cad6371f76d5c29b6d953ec.png" style="height: 12px;" /&gt;, we can square each of (1) and (2) and then add the
squares together:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/4fdeb60073659f55fa75878ec2f0867f9cbe7fd6.svg" style="height: 22px;" type="image/svg+xml"&gt;\[B^2 cos^2 (\theta)+B^2 sin^2 (\theta)=(A_1 cos(\phi_1)+A_2 cos(\phi_2))^2 + (A_1 sin(\phi_1)+A_2 sin(\phi_2))^2\]&lt;/object&gt;
&lt;p&gt;Using the fact that &lt;object class="valign-m5" data="https://eli.thegreenplace.net/images/math/e188aa0292a1c0d17344548fdcc38dc26faf3429.svg" style="height: 20px;" type="image/svg+xml"&gt;cos^2(a)+sin^2(a)=1&lt;/object&gt;, we get:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/28f6325da1ceee1767cdc9508fbc85b90427b1b0.svg" style="height: 23px;" type="image/svg+xml"&gt;\[B=\sqrt{(A_1 cos(\phi_1)+A_2 cos(\phi_2))^2 + (A_1 sin(\phi_1)+A_2 sin(\phi_2))^2}\]&lt;/object&gt;
&lt;p&gt;To solve for &lt;img alt="\theta" class="valign-0" src="https://eli.thegreenplace.net/images/math/cb005d76f9f2e394a770c2562c2e150a413b3216.png" style="height: 12px;" /&gt;, we can divide equation (2) by (1), getting:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/a0ecd0ee8c1f85d0ddb6b1224f48f5a8f2c469de.svg" style="height: 43px;" type="image/svg+xml"&gt;\[\frac{sin(\theta)}{cos(\theta)}=tan(\theta)=\frac{A_1 sin(\phi_1)+A_2 sin(\phi_2)}{A_1 cos(\phi_1)+A_2 cos(\phi_2)}\]&lt;/object&gt;
&lt;p&gt;Meaning that:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/b66eb0f8ef309c637f017134d8c66368452594c8.svg" style="height: 43px;" type="image/svg+xml"&gt;\[\theta = atan{\frac{A_1 sin(\phi_1)+A_2 sin(\phi_2)}{A_1 cos(\phi_1)+A_2 cos(\phi_2)}}\]&lt;/object&gt;
&lt;p&gt;Now that we have the values of &lt;img alt="B" class="valign-0" src="https://eli.thegreenplace.net/images/math/ae4f281df5a5d0ff3cad6371f76d5c29b6d953ec.png" style="height: 12px;" /&gt; and &lt;img alt="\theta" class="valign-0" src="https://eli.thegreenplace.net/images/math/cb005d76f9f2e394a770c2562c2e150a413b3216.png" style="height: 12px;" /&gt;, let's put them aside
for a bit and get back to the final line of our sum of sinusoids equation:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/921c17b6fb04e7cb8cc10d3f5652ed28d6f508ed.svg" style="height: 19px;" type="image/svg+xml"&gt;\[A_1 sin(wt+\phi_1)+A_2 sin(wt+\phi_2)=\left [A_1 cos(\phi_1) + A_2 cos(\phi_2) \right ]sin(wt)+\left [ A_1 sin(\phi_1) + A_2 sin(\phi_2)\right ]cos(wt)\]&lt;/object&gt;
&lt;p&gt;On the right-hand side, we can apply equations (1) and (2) to get:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/580c6c30e3caaf5ab9bb0472620c46f53266a5a2.svg" style="height: 19px;" type="image/svg+xml"&gt;\[A_1 sin(wt+\phi_1)+A_2 sin(wt+\phi_2)=B cos(\theta) sin(wt)+ B sin(\theta) cos(wt)\]&lt;/object&gt;
&lt;p&gt;Applying (id.1) again, we get:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/042c3173428218fb7a3410884288a540ecc78cd1.svg" style="height: 19px;" type="image/svg+xml"&gt;\[A_1 sin(wt+\phi_1)+A_2 sin(wt+\phi_2)=B sin(wt + \theta)\]&lt;/object&gt;
&lt;p&gt;We've just shown that the sum of sinusoids with the same frequency &lt;img alt="w" class="valign-0" src="https://eli.thegreenplace.net/images/math/aff024fe4ab0fece4091de044c58c9ae4233383a.png" style="height: 8px;" /&gt;
is another sinusoid with frequency &lt;img alt="w" class="valign-0" src="https://eli.thegreenplace.net/images/math/aff024fe4ab0fece4091de044c58c9ae4233383a.png" style="height: 8px;" /&gt;, and we've calculated &lt;img alt="B" class="valign-0" src="https://eli.thegreenplace.net/images/math/ae4f281df5a5d0ff3cad6371f76d5c29b6d953ec.png" style="height: 12px;" /&gt; and
&lt;img alt="\theta" class="valign-0" src="https://eli.thegreenplace.net/images/math/cb005d76f9f2e394a770c2562c2e150a413b3216.png" style="height: 12px;" /&gt; from the other parameters (&lt;object class="valign-m3" data="https://eli.thegreenplace.net/images/math/86684571efbdc2d7a49562ba00dd15056c517135.svg" style="height: 16px;" type="image/svg+xml"&gt;A_1&lt;/object&gt;, &lt;object class="valign-m3" data="https://eli.thegreenplace.net/images/math/dfcd56bce194520e6f50a8f821c98f338cb9d65c.svg" style="height: 16px;" type="image/svg+xml"&gt;A_2&lt;/object&gt;,
&lt;object class="valign-m4" data="https://eli.thegreenplace.net/images/math/3d9f2f00378f60e70beb5531aa2169a534bffe40.svg" style="height: 16px;" type="image/svg+xml"&gt;\phi_1&lt;/object&gt; and &lt;object class="valign-m4" data="https://eli.thegreenplace.net/images/math/f80876d413b14edaee0aa2678ab67346f6da633c.svg" style="height: 16px;" type="image/svg+xml"&gt;\phi_2&lt;/object&gt;) &lt;object class="valign-0" data="https://eli.thegreenplace.net/images/math/4a4e9e431da45a27bc880a8a1ca44d8b1b9bc143.svg" style="height: 12px;" type="image/svg+xml"&gt;\blacksquare&lt;/object&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="proof-using-complex-numbers"&gt;
&lt;h2&gt;Proof using complex numbers&lt;/h2&gt;
&lt;p&gt;The second proof uses a bit more advanced math, but overall feels more elegant
to me. The plan is to use Euler's equation and prove a more general statement
on the complex plane.&lt;/p&gt;
&lt;p&gt;Instead of looking at the sum of real sinusoids, we'll first look at the sum
of two complex exponential functions:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/ae18a24d9752babf28d9472d59bdc1e67bdb2074.svg" style="height: 20px;" type="image/svg+xml"&gt;\[A_1 e^{j(wt + \phi_1)} + A_2 e^{j(wt + \phi_2)}\]&lt;/object&gt;
&lt;p&gt;Reminder: Euler's equation for a complex exponential is&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/0741c35664a1df4373bf777ddecce046f75eb386.svg" style="height: 21px;" type="image/svg+xml"&gt;\[e^{jx}=cosx+jsinx\]&lt;/object&gt;
&lt;p&gt;Regrouping our sum of exponentials a bit and then applying this equation:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/12458dd213e9b9f3ef8ee7b9d34094410fcd3fbb.svg" style="height: 88px;" type="image/svg+xml"&gt;\[\begin{align*}
A_1 e^{j(wt + \phi_1)} + A_2 e^{j(wt + \phi_2)}&amp;amp;=e^{jwt}\left (A_1 e^{j\phi_1} + A_2 e^{j\phi_2}\right )\\
&amp;amp;=e^{jwt}\left ( A_1 cos(\phi_1) + jA_1 sin(\phi_1) + A_2 cos(\phi_2) + jA_2 sin(\phi_2)\right )\\
&amp;amp;=e^{jwt}\left [\left (A_1 cos(\phi_1) + A_2 cos(\phi_2) \right ) + j\left(A_1 sin(\phi_1) + A_2 sin(\phi_2) \right ) \right ]
\end{align*}\]&lt;/object&gt;
&lt;p&gt;The value inside the square brackets can be viewed as a complex number in its
rectangular form: &lt;object class="valign-m4" data="https://eli.thegreenplace.net/images/math/8e2a949b46783cd572f79c9ad9d6a3887f0fb462.svg" style="height: 16px;" type="image/svg+xml"&gt;x + jy&lt;/object&gt;. We can convert it to its polar form:
&lt;object class="valign-0" data="https://eli.thegreenplace.net/images/math/14073811ee769d485ac4495503a1d32292b73f45.svg" style="height: 15px;" type="image/svg+xml"&gt;re^{j\theta}&lt;/object&gt;, by calculating:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/dd1d145174f17f82bfcffce4c658ac249025aaf2.svg" style="height: 62px;" type="image/svg+xml"&gt;\[\begin{align*}
r&amp;amp;=\sqrt{x^2+y^2}\\
\theta&amp;amp;=atan(\frac{y}{x})
\end{align*}\]&lt;/object&gt;
&lt;p&gt;In our case:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/18a842fb6ac23aa16c0c4b4fe8c974c064933509.svg" style="height: 23px;" type="image/svg+xml"&gt;\[r=\sqrt{(A_1 cos(\phi_1)+A_2 cos(\phi_2))^2 + (A_1 sin(\phi_1)+A_2 sin(\phi_2))^2}\]&lt;/object&gt;
&lt;p&gt;And:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/b66eb0f8ef309c637f017134d8c66368452594c8.svg" style="height: 43px;" type="image/svg+xml"&gt;\[\theta = atan{\frac{A_1 sin(\phi_1)+A_2 sin(\phi_2)}{A_1 cos(\phi_1)+A_2 cos(\phi_2)}}\]&lt;/object&gt;
&lt;p&gt;Therefore, the sum of complex exponentials is another complex exponential with
the same frequency, but a different magnitude and phase:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/a5028bcfc1af3517f2e52448e4b51f25c80ade80.svg" style="height: 20px;" type="image/svg+xml"&gt;\[A_1 e^{j(wt + \phi_1)} + A_2 e^{j(wt + \phi_2)}= e^{jwt} r e^{j \theta}=r e^{j(wt + \theta)}\]&lt;/object&gt;
&lt;p&gt;From here, we can use Euler's equation again to see the equivalence in terms
of sinusoidal functions:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/dc5490843cd4fc3676a1bcf8fcdf0002ae0f227a.svg" style="height: 45px;" type="image/svg+xml"&gt;\[\begin{align*}
A_1 cos(wt+\phi_1)+jA_1 sin(wt+\phi_1)&amp;amp;+\\
A_2 cos(wt+\phi_2)+jA_2 sin(wt+\phi_2)&amp;amp;=r cos(wt+\theta) + jr sin(wt+\theta)
 \end{align*}\]&lt;/object&gt;
&lt;p&gt;If we only compare the imaginary parts of this equation, we get:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/e1ef66dd4f3ec1496cb94bae8f52acf5f77229da.svg" style="height: 19px;" type="image/svg+xml"&gt;\[A_1 sin(wt+\phi_1)+A_2 sin(wt+\phi_2)=r sin(wt+\theta)\]&lt;/object&gt;
&lt;p&gt;With known &lt;object class="valign-0" data="https://eli.thegreenplace.net/images/math/4dc7c9ec434ed06502767136789763ec11d2c4b7.svg" style="height: 8px;" type="image/svg+xml"&gt;r&lt;/object&gt; and &lt;img alt="\theta" class="valign-0" src="https://eli.thegreenplace.net/images/math/cb005d76f9f2e394a770c2562c2e150a413b3216.png" style="height: 12px;" /&gt; we've calculated earlier from the other
constants &lt;object class="valign-0" data="https://eli.thegreenplace.net/images/math/4a4e9e431da45a27bc880a8a1ca44d8b1b9bc143.svg" style="height: 12px;" type="image/svg+xml"&gt;\blacksquare&lt;/object&gt;&lt;/p&gt;
&lt;p&gt;Note that by comparing the real parts of the equation, we can trivially prove a
similar statement about the sum of cosines (which should surprise no one, since
a cosine is just a phase-shifted sine).&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-1" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;p class="first"&gt;Electrical engineers prefer their signal frequencies in units of
radian per second.&lt;/p&gt;
&lt;p class="last"&gt;We also like calling the imaginary unit &lt;em&gt;j&lt;/em&gt; instead of &lt;em&gt;i&lt;/em&gt;, because
the latter is used for electrical current.&lt;/p&gt;
&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-2" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-2"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;If you're wondering &amp;quot;hold on, why would this work?&amp;quot;, recall that
any point &lt;em&gt;(x,y)&lt;/em&gt; on the Cartesian plane can be represented using
&lt;em&gt;polar coordinates&lt;/em&gt; with magnitude &lt;img alt="B" class="valign-0" src="https://eli.thegreenplace.net/images/math/ae4f281df5a5d0ff3cad6371f76d5c29b6d953ec.png" style="height: 12px;" /&gt; and angle &lt;img alt="\theta" class="valign-0" src="https://eli.thegreenplace.net/images/math/cb005d76f9f2e394a770c2562c2e150a413b3216.png" style="height: 12px;" /&gt;.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</content><category term="misc"></category><category term="Math"></category><category term="EE &amp; Embedded"></category></entry><entry><title>Some notes on Luz - an assembler, linker and CPU simulator</title><link href="https://eli.thegreenplace.net/2017/some-notes-on-luz-an-assembler-linker-and-cpu-simulator/" rel="alternate"></link><published>2017-01-05T06:27:00-08:00</published><updated>2024-05-04T19:46:23-07:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2017-01-05:/2017/some-notes-on-luz-an-assembler-linker-and-cpu-simulator/</id><summary type="html">&lt;p&gt;A few years ago I &lt;a class="reference external" href="https://eli.thegreenplace.net/2010/05/05/introducing-luz"&gt;wrote about Luz&lt;/a&gt; - a
self-educational project to implement a CPU simulator and a toolchain for it,
consisting of an assembler and a linker. Since then, I received some questions
by email that made me realize I could do a better job explaining what the
project …&lt;/p&gt;</summary><content type="html">&lt;p&gt;A few years ago I &lt;a class="reference external" href="https://eli.thegreenplace.net/2010/05/05/introducing-luz"&gt;wrote about Luz&lt;/a&gt; - a
self-educational project to implement a CPU simulator and a toolchain for it,
consisting of an assembler and a linker. Since then, I received some questions
by email that made me realize I could do a better job explaining what the
project is and what one can learn from it.&lt;/p&gt;
&lt;p&gt;So I went back to the &lt;a class="reference external" href="https://github.com/eliben/luz-cpu"&gt;Luz repository&lt;/a&gt; and
fixed it up to be more modern, in-line with current documentation standards on
GitHub. The landing &lt;cite&gt;README&lt;/cite&gt; page should now provide a good overview, but I also
wanted to write up some less formal documentation I could point to - a place to
show-off some of the more interesting features in Luz; a blog post seemed like
the perfect medium for this.&lt;/p&gt;
&lt;p&gt;As before, it makes sense to start with the Luz toplevel diagram:&lt;/p&gt;
&lt;img alt="Luz toplevel diagram" class="align-center" src="https://eli.thegreenplace.net/images/2010/05/luz_proj_toplevel.png" /&gt;
&lt;p&gt;Luz is a collection of related libraries and programs written in Python,
implementing all the stages shown in the diagram above.&lt;/p&gt;
&lt;div class="section" id="the-cpu-simulator"&gt;
&lt;h2&gt;The CPU simulator&lt;/h2&gt;
&lt;p&gt;The Luz CPU is inspired by MIPS (for the instruction set), by Altera Nios II
(for the way &amp;quot;peripherals&amp;quot; are attached to the CPU), and by MPC 555 (for the
memory controller) and is aimed at embedded uses, like Nios II. The &lt;a class="reference external" href="https://github.com/eliben/luz-cpu/blob/main/doc/luz_user_manual.rst"&gt;Luz user
manual&lt;/a&gt;
lists the complete instruction set explaining what each instructions means.&lt;/p&gt;
&lt;p&gt;The simulator itself is functional only - it performs the instructions one after
the other, without trying to simulate how long their execution takes. It's not
very remarkable and is designed to be simple and readable. The most interesting
feature it has, IMHO, is how it maps &amp;quot;peripherals&amp;quot; and even CPU control
registers into memory. Rather than providing special instructions or traps for
OS system calls, Luz facilitates &amp;quot;bare-metal&amp;quot; programming (by which I mean,
without an OS) by mapping &amp;quot;peripherals&amp;quot; into memory, allowing the programmer to
access them by reading and writing special memory locations.&lt;/p&gt;
&lt;p&gt;My inspiration here was soft-core embeddable CPUs like Nios II, which let you
configure what peripherals to connect and how to map them. The CPU can be
configured before it's loaded onto real HW, for example to attach as many SPI
interfaces as needed. For Luz, to create a new peripheral and attach it to the
simulator one implements the &lt;tt class="docutils literal"&gt;Peripheral&lt;/tt&gt; interface:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Peripheral&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot; An abstract memory-mapped perhipheral interface.&lt;/span&gt;
&lt;span class="sd"&gt;        Memory-mapped peripherals are accessed through memory&lt;/span&gt;
&lt;span class="sd"&gt;        reads and writes.&lt;/span&gt;

&lt;span class="sd"&gt;        The address given to reads and writes is relative to the&lt;/span&gt;
&lt;span class="sd"&gt;        peripheral&amp;#39;s memory map.&lt;/span&gt;
&lt;span class="sd"&gt;        Width is 1, 2, 4 for byte, halfword and word accesses.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;read_mem&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;addr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;NotImplementedError&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;write_mem&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;addr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;NotImplementedError&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Luz implements some built-in features as peripherals as well; for example, the
&lt;a class="reference external" href="https://github.com/eliben/luz-cpu/blob/main/luz_asm_sim/lib/simlib/peripheral/coreregisters.py"&gt;core registers&lt;/a&gt;
(interrupt control, exception control, etc). The idea here is that embedded CPUs
can have multiple custom &amp;quot;registers&amp;quot; to control various features, and creating
dedicated names for them bloats instruction encoding (you need 5 bits to encode
one of 32 registers, etc.); it's better to just map them to memory.&lt;/p&gt;
&lt;p&gt;Another example is the &lt;a class="reference external" href="https://github.com/eliben/luz-cpu/blob/main/luz_asm_sim/lib/simlib/peripheral/debugqueue.py"&gt;debug queue&lt;/a&gt;
- a peripheral useful for testing and debugging. It's a single word mapped to
address &lt;tt class="docutils literal"&gt;0xF0000&lt;/tt&gt; in the simulator. When the peripheral gets a write, it
stores it in a special queue and optionally emits the value to stdout. The
queue can later be examined. Here is a simple Luz assembly program that makes
use of it:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# Counts from 0 to 9 [inclusive], pushing these numbers into the debug queue

    .segment code
    .global asm_main

    .define ADDR_DEBUG_QUEUE, 0xF0000

asm_main:
    li $k0, ADDR_DEBUG_QUEUE

    li $r9, 10                          # r9 is the loop limit
    li $r5, 0                           # r5 is the loop counter

loop:
    sw $r5, 0($k0)                      # store loop counter to debug queue
    addi $r5, $r5, 1                    # increment loop counter
    bltu $r5, $r9, loop                 # loop back if not reached limit

    halt
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Using the interactive runner to run this program we get:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ python run_test_interactive.py loop_simple_debugqueue
DebugQueue: 0x0
DebugQueue: 0x1
DebugQueue: 0x2
DebugQueue: 0x3
DebugQueue: 0x4
DebugQueue: 0x5
DebugQueue: 0x6
DebugQueue: 0x7
DebugQueue: 0x8
DebugQueue: 0x9
Finished successfully...
Debug queue contents:
[&amp;#39;0x0&amp;#39;, &amp;#39;0x1&amp;#39;, &amp;#39;0x2&amp;#39;, &amp;#39;0x3&amp;#39;, &amp;#39;0x4&amp;#39;, &amp;#39;0x5&amp;#39;, &amp;#39;0x6&amp;#39;, &amp;#39;0x7&amp;#39;, &amp;#39;0x8&amp;#39;, &amp;#39;0x9&amp;#39;]
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="assembler"&gt;
&lt;h2&gt;Assembler&lt;/h2&gt;
&lt;p&gt;There's a small snippet of Luz assembly shown above. It's your run-of-the-mill
RISC assembly, with the familiar set of instructions, fairly simple addressing
modes and almost every instruction requiring registers (note how we can't store
into the debug queue directly, for example, without dereferencing a register
that holds its address).&lt;/p&gt;
&lt;p&gt;The &lt;a class="reference external" href="https://github.com/eliben/luz-cpu/blob/main/doc/luz_user_manual.rst"&gt;Luz user manual&lt;/a&gt;
contains a complete reference for the instructions, including their encodings.
Every instruction is a 32-bit word, with the 6 high bits for the opcode (meaning
up to 64 distinct instructions are supported).&lt;/p&gt;
&lt;p&gt;The code snippet also shows off some special features of the full Luz toolchain,
like the special label &lt;tt class="docutils literal"&gt;asm_main&lt;/tt&gt;. I'll discuss these later on in the section
about linking.&lt;/p&gt;
&lt;p&gt;Assembly languages are usually fairly simple to parse, and Luz is no exception.
When I started working on Luz, I decided to use the &lt;a class="reference external" href="http://www.dabeaz.com/ply/"&gt;PLY&lt;/a&gt; library for the lexer and parser mainly because I
wanted to play with it. These days I'd probably just hand-roll a parser.&lt;/p&gt;
&lt;p&gt;Luz takes another cool idea from MIPS - &lt;a class="reference external" href="https://www.cs.umd.edu/class/sum2003/cmsc311/Notes/Mips/altReg.html"&gt;register aliases&lt;/a&gt;. While
the assembler doesn't enforce any specific ABI on the coder, some conventions are
very important when writing large assembly programs, and especially when
interfacing with routines written by other programmers. To facilitate this, Luz
designates register aliases for callee-saved registers and temporary registers.&lt;/p&gt;
&lt;p&gt;For example, the general-purpose register number 19 can be referred to in Luz
assembly as &lt;tt class="docutils literal"&gt;$r19&lt;/tt&gt; but also as &lt;tt class="docutils literal"&gt;$s1&lt;/tt&gt; - the callee-saved register 1. When
writing standalone Luz programs, one is free to ignore these conventions. To
get a taste of how ABI-conformant Luz assembly would look, take a look at
&lt;a class="reference external" href="https://github.com/eliben/luz-cpu/tree/main/luz_asm_sim/tests_full/procedure_call_stack_convention"&gt;this example&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To be honest, ABI was on my mind because I was initially envisioning a full
programming environment for Luz, including a C compiler. When you have a
compiler, you must have some set of conventions for generated code like
procedure parameter passing, saved registers and so on; in other words, the
platform ABI.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="linker"&gt;
&lt;h2&gt;Linker&lt;/h2&gt;
&lt;p&gt;In my view, one of the distinguishing features of Luz from other assembler
projects out there is the linker. Luz features a full linker that supports
creating single &amp;quot;binaries&amp;quot; from multiple assembly files, handling all the dirty
work necessary to make that happen. Each assembly file is first &amp;quot;assembled&amp;quot; into
a position-independent object file; these are glued together by the linker which
applies the necessary relocations to resolve symbols across object files. The
&lt;a class="reference external" href="https://github.com/eliben/luz-cpu/tree/main/luz_asm_sim/tests_full/prime_sieve"&gt;prime sieve example&lt;/a&gt;
shows this in action - the program is divided into three &lt;tt class="docutils literal"&gt;.lasm&lt;/tt&gt; files: two
for subroutines and one for &amp;quot;main&amp;quot;.&lt;/p&gt;
&lt;p&gt;As we've seen above, the main subroutine in Luz is called &lt;tt class="docutils literal"&gt;asm_main&lt;/tt&gt;. This is
a special name for the linker (not unlike the &lt;tt class="docutils literal"&gt;_start&lt;/tt&gt; symbol for &lt;a class="reference external" href="https://eli.thegreenplace.net/2012/08/13/how-statically-linked-programs-run-on-linux"&gt;modern
Linux assemblers&lt;/a&gt;).
The linker collects a set of object files produced by assembly, and makes sure
to invoke &lt;tt class="docutils literal"&gt;asm_main&lt;/tt&gt; from the special location &lt;tt class="docutils literal"&gt;0x100000&lt;/tt&gt;. This is where
the simulator starts execution.&lt;/p&gt;
&lt;p&gt;Luz also has the concept of &lt;a class="reference external" href="https://github.com/eliben/luz-cpu/blob/main/luz_asm_sim/lib/asmlib/objectfile.py"&gt;object files&lt;/a&gt;.
They are not unlike ELF images in nature: there's a segment table, an export
table and a relocation table for each object, serving the expected roles. It is
the job of the linker to make sense in this list of objects and correctly
connect all call sites to final subroutine addresses.&lt;/p&gt;
&lt;p&gt;Luz's &lt;a class="reference external" href="https://github.com/eliben/luz-cpu/blob/main/luz_asm_sim/luz_asm.py"&gt;standalone assembler&lt;/a&gt; can
write an assembled image into a file in &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Intel_HEX"&gt;Intel HEX format&lt;/a&gt;, a popular format used in embedded
systems to encode binary images or data in ASCII.&lt;/p&gt;
&lt;p&gt;The linker was quite a bit of effort to develop. Since all real Luz programs are
small I didn't really need to break them up into multiple assembly files; but
I really wanted to learn how to write a real linker :) Moreover, as already
mentioned my original plans for Luz included a C compiler, and that would make a
linker very helpful, since I'd need to link some &amp;quot;system&amp;quot; code into the user's
program. Even today, Luz has some &amp;quot;startup code&amp;quot; it links into every image:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# The special segments added by the linker.
# __startup: 3 words
# __heap: 1 word
#
LINKER_STARTUP_CODE = string.Template(r&amp;#39;&amp;#39;&amp;#39;
        .segment __startup

    LI      $$sp, ${SP_POINTER}
    CALL    asm_main

        .segment __heap
        .global __heap
    __heap:
        .word 0
&amp;#39;&amp;#39;&amp;#39;)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This code sets up the stack pointer to the initial address allocated for the
stack, and calls the user's &lt;tt class="docutils literal"&gt;asm_main&lt;/tt&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="debugger-and-disassembler"&gt;
&lt;h2&gt;Debugger and disassembler&lt;/h2&gt;
&lt;p&gt;Luz comes with a simple program runner that will execute a Luz program
(consisting of multiple assembly files); it also has an interactive mode - a
debugger. Here's a sample session with the simple loop example shown above:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ python run_test_interactive.py -i loop_simple_debugqueue

LUZ simulator started at 0x00100000

[0x00100000] [lui $sp, 0x13] &amp;gt;&amp;gt; set alias 0
[0x00100000] [lui $r29, 0x13] &amp;gt;&amp;gt; s
[0x00100004] [ori $r29, $r29, 0xFFFC] &amp;gt;&amp;gt; s
[0x00100008] [call 0x40003 [0x10000C]] &amp;gt;&amp;gt; s
[0x0010000C] [lui $r26, 0xF] &amp;gt;&amp;gt; s
[0x00100010] [ori $r26, $r26, 0x0] &amp;gt;&amp;gt; s
[0x00100014] [lui $r9, 0x0] &amp;gt;&amp;gt; s
[0x00100018] [ori $r9, $r9, 0xA] &amp;gt;&amp;gt; s
[0x0010001C] [lui $r5, 0x0] &amp;gt;&amp;gt; s
[0x00100020] [ori $r5, $r5, 0x0] &amp;gt;&amp;gt; s
[0x00100024] [sw $r5, 0($r26)] &amp;gt;&amp;gt; s
[0x00100028] [addi $r5, $r5, 0x1] &amp;gt;&amp;gt; s
[0x0010002C] [bltu $r5, $r9, -2] &amp;gt;&amp;gt; s
[0x00100024] [sw $r5, 0($r26)] &amp;gt;&amp;gt; s
[0x00100028] [addi $r5, $r5, 0x1] &amp;gt;&amp;gt; s
[0x0010002C] [bltu $r5, $r9, -2] &amp;gt;&amp;gt; s
[0x00100024] [sw $r5, 0($r26)] &amp;gt;&amp;gt; s
[0x00100028] [addi $r5, $r5, 0x1] &amp;gt;&amp;gt; r
$r0   = 0x00000000   $r1   = 0x00000000   $r2   = 0x00000000   $r3   = 0x00000000
$r4   = 0x00000000   $r5   = 0x00000002   $r6   = 0x00000000   $r7   = 0x00000000
$r8   = 0x00000000   $r9   = 0x0000000A   $r10  = 0x00000000   $r11  = 0x00000000
$r12  = 0x00000000   $r13  = 0x00000000   $r14  = 0x00000000   $r15  = 0x00000000
$r16  = 0x00000000   $r17  = 0x00000000   $r18  = 0x00000000   $r19  = 0x00000000
$r20  = 0x00000000   $r21  = 0x00000000   $r22  = 0x00000000   $r23  = 0x00000000
$r24  = 0x00000000   $r25  = 0x00000000   $r26  = 0x000F0000   $r27  = 0x00000000
$r28  = 0x00000000   $r29  = 0x0013FFFC   $r30  = 0x00000000   $r31  = 0x0010000C

[0x00100028] [addi $r5, $r5, 0x1] &amp;gt;&amp;gt; s 100
[0x00100030] [halt] &amp;gt;&amp;gt; q
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;There are many interesting things here demonstrating how Luz works:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Note the start up at &lt;tt class="docutils literal"&gt;0x1000000&lt;/tt&gt; - this is where Luz places the start-up
segment - three instructions that set up the stack pointer and then &lt;tt class="docutils literal"&gt;call&lt;/tt&gt;
the user's code (&lt;tt class="docutils literal"&gt;asm_main&lt;/tt&gt;). The user's &lt;tt class="docutils literal"&gt;asm_main&lt;/tt&gt; starts running at
the fourth instruction executed by the simulator.&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;li&lt;/tt&gt; is a pseudo-instruction, broken into two real instructions: &lt;tt class="docutils literal"&gt;lui&lt;/tt&gt;
for the upper half of the register, followed by &lt;tt class="docutils literal"&gt;ori&lt;/tt&gt; for the lower half of
the register. The reason for this is &lt;tt class="docutils literal"&gt;li&lt;/tt&gt; having a 32-bit immediate, which
can't fit in a Luz instruction. Therefore, it's broken into two parts which
only need 16-bit immediates. This trick is common in RISC ISAs.&lt;/li&gt;
&lt;li&gt;Jump labels are resolved to be relative by the assembler: the jump to &lt;tt class="docutils literal"&gt;loop&lt;/tt&gt;
is replaced by &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-2&lt;/span&gt;&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;Disassembly! The debugger shows the instruction decoded from every word where
execution stops. Note how this exposes pseudo-instructions.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="the-in-progress-rtl-implementation"&gt;
&lt;h2&gt;The in-progress RTL implementation&lt;/h2&gt;
&lt;p&gt;Luz was a hobby project, but an ambitious one :-) Even before I wrote the first
line of the assembler or simulator, I started working on an actual CPU
implementation in synthesizable VHDL, meaning to get a complete RTL image to run
on FPGAs. Unfortunately, I didn't finish this part of the project
and what you find in Luz's &lt;tt class="docutils literal"&gt;experimental/luz_uc&lt;/tt&gt; directory is only 75%
complete. The ALU is there, the registers, the hookups to peripherals, even
parts of the control path - dealing with instruction fetching, decoding, etc. My
original plan was to implement a pipelined CPU (a RISC ISA makes this relatively
simple), which perhaps was a bit too much. I should have started simpler.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Luz was an extremely educational project for me. When I started working on it,
I mostly had embedded programming experience and was just starting to get
interested in systems programming. Luz flung me into the world of assemblers,
linkers, binary images, calling conventions, and so on. Besides, Python was
a new language for me at the time - Luz started just months after
&lt;a class="reference external" href="https://eli.thegreenplace.net/2008/05/14/python"&gt;I first got into Python&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Its ~8000 lines of Python code are thus likely not my best Python code, but they
should be readable and well commented. I did modernize it a bit over the years,
for example to make it run on both Python 2 and 3.&lt;/p&gt;
&lt;p&gt;I still hope to get back to the RTL implementation project one day. It's really
very close to being able to run realistic assembly programs on &lt;em&gt;real hardware&lt;/em&gt;
(FPGAs). My dream back then was to fully close the loop by adding a Luz code
generation backend to &lt;a class="reference external" href="https://github.com/eliben/pycparser"&gt;pycparser&lt;/a&gt;. Maybe
I'll still fulfill it one day :-)&lt;/p&gt;
&lt;/div&gt;
</content><category term="misc"></category><category term="Assembly"></category><category term="EE &amp; Embedded"></category><category term="Linkers and Loaders"></category><category term="Python"></category></entry><entry><title>Introducing Luz</title><link href="https://eli.thegreenplace.net/2010/05/05/introducing-luz" rel="alternate"></link><published>2010-05-05T19:43:38-07:00</published><updated>2023-02-04T13:41:52-08:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2010-05-05:/2010/05/05/introducing-luz</id><summary type="html">
&lt;p&gt;
OK, so the documentation still isn't complete, but I can't wait to introduce my newest concoction - &lt;a href="https://github.com/eliben/luz-cpu/"&gt;Luz&lt;/a&gt;. Luz is a pure-Python implementation of a MIPS-like CPU (as a simulator, of course). This CPU is programmable in an assembly language, a complete assembler for which has been implemented, along with a …&lt;/p&gt;</summary><content type="html">
&lt;p&gt;
OK, so the documentation still isn't complete, but I can't wait to introduce my newest concoction - &lt;a href="https://github.com/eliben/luz-cpu/"&gt;Luz&lt;/a&gt;. Luz is a pure-Python implementation of a MIPS-like CPU (as a simulator, of course). This CPU is programmable in an assembly language, a complete assembler for which has been implemented, along with a linker that takes together several object files and creates an executable image to run on the simulator. Oh, and did I mention that it also includes a rudimentary debugger and disassembler? All of this is Luz:
&lt;/p&gt;

&lt;p&gt;
&lt;center&gt;
&lt;img src="https://eli.thegreenplace.net/images/2010/05/luz_proj_toplevel.png" title="luz_proj_toplevel" width="437" height="952" class="aligncenter size-full wp-image-2165" /&gt;
&lt;/center&gt;
&lt;/p&gt;

&lt;p&gt;
To call Luz new is a bit of a stretch, because I started working on it more than two years ago. It has been a jagged road, with occasional spurts of productivity, but now Luz is finally in a presentable form.
&lt;/p&gt;&lt;p&gt;

&lt;/p&gt;&lt;p&gt;
I'll paste from its "getting started guide":
&lt;/p&gt;

&lt;blockquote&gt;
&lt;strong&gt;What is Luz useful for?&lt;/strong&gt;
I don't know yet. It's a self-educational project of mine, and I learned a lot by working on it. I suppose that Luz's main value is as an educational tool. Its implementation focuses on simplicity and modularity, and is done in Python, which is a portable and very readable high-level language.
Luz can serve as a sample of implementing a complete assembler, a complete linker, a complete CPU simulator. Other such tools exist, but usually not in the clean and self-contained form offered by Luz. In any case, if you've found Luz iseful, I'd love to receive feedback.
&lt;/blockquote&gt;

&lt;p&gt;
This summarizes it, really. Not much more to add, except that Luz is available in source-only form for now, so you'll have to check it out from SVN or just look at the sources in the online browser. Checking the source out is recommended because it allows one to view the documentation in nice HTML format. A few example programs in Luz assembly are available. Luz requires Python 2.6 or higher and the PLY module installed. I tested it on Windows XP and Ubuntu.
&lt;/p&gt;&lt;p&gt;

I've written &lt;a href="https://eli.thegreenplace.net/2005/02/20/mix-implementation-in-perl-completed/"&gt;an assembler and a CPU simulator before&lt;/a&gt;, but that was for a very weird architecture (Knuth's MIX from TAOCP). Luz is a much more useful beast - the CPU is not far from real modern CPUs (the embedded kind, mostly), the assembly language is familiar and best of all, Luz also includes a linker, which will make it much easier to compile C for it in the future.
&lt;/p&gt;&lt;p&gt;

I'll write more about Luz in sometime later, when I find the time to work on its documentation.
&lt;/p&gt;


    </content><category term="misc"></category><category term="Assembly"></category><category term="EE &amp; Embedded"></category><category term="Linkers and loaders"></category></entry><entry><title>Framing in serial communications</title><link href="https://eli.thegreenplace.net/2009/08/12/framing-in-serial-communications" rel="alternate"></link><published>2009-08-12T05:16:47-07:00</published><updated>2023-06-30T23:16:27-07:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2009-08-12:/2009/08/12/framing-in-serial-communications</id><summary type="html">
        &lt;div class="section" id="introduction"&gt;
&lt;h3&gt;Introduction&lt;/h3&gt;
&lt;p&gt;In the &lt;a class="reference external" href="https://eli.thegreenplace.net/2009/08/07/a-live-data-monitor-with-python-pyqt-and-pyserial/"&gt;previous post&lt;/a&gt; we've seen how to send and receive data on the serial port with Python and plot it live using a pretty GUI.&lt;/p&gt;
&lt;p&gt;Notice that the sender script (sender_sim.py) is just sending one byte at a time. The &amp;quot;chunks&amp;quot; of data in the protocol between …&lt;/p&gt;&lt;/div&gt;</summary><content type="html">
        &lt;div class="section" id="introduction"&gt;
&lt;h3&gt;Introduction&lt;/h3&gt;
&lt;p&gt;In the &lt;a class="reference external" href="https://eli.thegreenplace.net/2009/08/07/a-live-data-monitor-with-python-pyqt-and-pyserial/"&gt;previous post&lt;/a&gt; we've seen how to send and receive data on the serial port with Python and plot it live using a pretty GUI.&lt;/p&gt;
&lt;p&gt;Notice that the sender script (sender_sim.py) is just sending one byte at a time. The &amp;quot;chunks&amp;quot; of data in the protocol between the sender and receiver are single bytes. This is simple and convenient, but hardly sufficient in the general sense. We want to be able to send multiple-byte data frames between the communicating parties.&lt;/p&gt;
&lt;p&gt;However, there are some challenges that arise immediately:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The receiver is just receiving a stream of bytes from the serial port. How does it know when a message begins or ends? How does it know how long the message is?&lt;/li&gt;
&lt;li&gt;Even more seriously, we can not assume a noise-free channel. This is real, physical hardware stuff. Bytes and whole chunks can and will be lost due to electrical noise. Worse, other bytes will be distorted (say, a single bit can be flipped due to noise).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To see how this can be done in a safe and tested manner, we first have to learn about the basics of the Data Link Layer in computer networks.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="data-link-layer"&gt;
&lt;h3&gt;Data Link Layer&lt;/h3&gt;
&lt;p&gt;Given a physical layer that can transmit signals between devices, the job of the Data Link Layer &lt;a class="footnote-reference" href="#id9" id="id1"&gt;[1]&lt;/a&gt; is (roughly stated) to transmit whole frames of data, with some means of assuring the integrity of the data (lack of errors). When we use sockets to communicate over TCP or UDP on the internet, the framing is taken care of deep in the hardware, and we don't even feel it. On the serial port, however, we must take care of the framing and error handling ourselves &lt;a class="footnote-reference" href="#id10" id="id2"&gt;[2]&lt;/a&gt;.&lt;/p&gt;
&lt;div class="section" id="framing"&gt;
&lt;h4&gt;Framing&lt;/h4&gt;
&lt;p&gt;In chapter 3 of his &lt;a class="reference external" href="https://eli.thegreenplace.net/2009/08/08/book-review-computer-networks-4th-edition-by-andrew-tanenbaum/"&gt;&amp;quot;Computer Networks&amp;quot;&lt;/a&gt; textbook, Tanenbaum defines the following methods of framing:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Inserting time gaps between frames&lt;/li&gt;
&lt;li&gt;Physical layer coding violations&lt;/li&gt;
&lt;li&gt;Character count&lt;/li&gt;
&lt;li&gt;Flag bytes with byte stuffing&lt;/li&gt;
&lt;li&gt;Flag bytes with bit stuffing&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Methods (1) and (2) are only suitable for a hardware-implemented data link layer &lt;a class="footnote-reference" href="#id11" id="id3"&gt;[3]&lt;/a&gt;. It is very difficult (read: impossible) to ensure timing when multiple layers of software (running on Windows!) are involved. (2) is an interesting hardware method - but out of the scope of this article.&lt;/p&gt;
&lt;p&gt;Method (3) means specifying in the frame header the number of bytes in the frame. The trouble with this is that the count can be garbled by a transmission error. In such a case, it's very difficult to &amp;quot;resynchronize&amp;quot;. This method is rarely used.&lt;/p&gt;
&lt;p&gt;Methods (4) and (5) are somewhat similar. In this article I'll focus on (4), as (5) is not suitable for serial port communications.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="flag-bytes-with-byte-stuffing"&gt;
&lt;h4&gt;Flag bytes with byte stuffing&lt;/h4&gt;
&lt;p&gt;Let's begin with a simple idea and develop it into a full, robust scheme.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Flag bytes&lt;/em&gt; are special byte values that denote when a frame begins and ends. Suppose that we want to be able to send frames of arbitrary length. A special start flag byte will denote the beginning of the frame, and an end flag byte will denote its end.&lt;/p&gt;
&lt;img src="https://eli.thegreenplace.net/images/2009/08/flags_data.png" /&gt;
&lt;p&gt;A question arises, however. Suppose that the value of the end flag is 0x98. What if the value 0x98 appears somewhere in the data? The protocol will get confused and end the message.&lt;/p&gt;
&lt;p&gt;There is a simple solution to this problem that will be familiar to all programmers who know about escaping quotes and special characters in strings. It is called &lt;em&gt;byte stuffing&lt;/em&gt;, or &lt;em&gt;octet stuffing&lt;/em&gt;, or simply &lt;em&gt;escaping&lt;/em&gt; &lt;a class="footnote-reference" href="#id12" id="id4"&gt;[4]&lt;/a&gt;. The scheme goes as follows:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Whenever a flag (start or end) byte appears in the data, we shall insert a special escape byte (ESC) before it. When the receiver sees an ESC, it knows to ignore it and not insert it into the actual data received (de-stuffing).&lt;/li&gt;
&lt;li&gt;Whenever ESC itself has to appear in the data, another ESC is prepended to it. The receiver removes the first one but keeps the second one &lt;a class="footnote-reference" href="#id13" id="id5"&gt;[5]&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here are a few examples:&lt;/p&gt;
&lt;img src="https://eli.thegreenplace.net/images/2009/08/escaping.png" /&gt;
&lt;p&gt;Note that we didn't specify what the data is - it's arbitrary and up the the protocol to decide. The only really required part of the data is some kind of error checking - a checksum, or better yet a CRC. This is customarily the last byte (or last word) of the frame, referring to all the bytes in the frame (in its un-stuffed form).&lt;/p&gt;
&lt;p&gt;This scheme is quite robust: any lost byte (be it a flag, an escape, a data byte or a checksum byte) will cause the receiver to lose just one frame, after which it will resynchronize onto the start flag byte of the next one.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="ppp"&gt;
&lt;h4&gt;PPP&lt;/h4&gt;
&lt;p&gt;As a matter of fact, this method is a slight simplification of the &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Point-to-Point_Protocol"&gt;Point-to-Point Protocol&lt;/a&gt; (PPP) which is used by most ISPs for providing ADSL internet to home users, so there's a good chance you're using it now to surf the net and read this article! The framing of PPP is defined in &lt;a class="reference external" href="http://tools.ietf.org/html/rfc1662"&gt;RFC 1662&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In particular, PPP does the following:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Both the start and end flag bytes are 0x7E (they shouldn't really be different, if you think about it)&lt;/li&gt;
&lt;li&gt;The escape byte is 0x7D&lt;/li&gt;
&lt;li&gt;Whenever a flag or escape byte appears in the message, it is escaped by 0x7D and the byte itself is XOR-ed with 0x20. So, for example 0x7E becomes 0x7D 0x5E. Similarly 0x7D becomes 0x7D 0x5D. The receiver unsuffs the escape byte and XORs the next byte with 0x20 again to get the original &lt;a class="footnote-reference" href="#id14" id="id6"&gt;[6]&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="an-example"&gt;
&lt;h3&gt;An example&lt;/h3&gt;
&lt;p&gt;Let's now see a completely worked-out example that demonstrates how this works.&lt;/p&gt;
&lt;p&gt;Suppose we define the following protocol:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Start flag: 0x12&lt;/li&gt;
&lt;li&gt;End flag: 0x13&lt;/li&gt;
&lt;li&gt;Escape (DLE): 0x7D&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And the sender wants to send the following data message (let's ignore its contents for the sake of the example - they're really not that important). The original data is in &lt;strong&gt;(a)&lt;/strong&gt;:&lt;/p&gt;
&lt;img src="https://eli.thegreenplace.net/images/2009/08/example1.png" /&gt;
&lt;p&gt;The data contains two flags that need to be escaped - an end flag at position 2 (counting from 0, of course!), and a DLE at position 4.&lt;/p&gt;
&lt;p&gt;The sender's data link layer &lt;a class="footnote-reference" href="#id15" id="id7"&gt;[7]&lt;/a&gt; turns the data into the frame shown in &lt;strong&gt;(b)&lt;/strong&gt; - start and end flags are added, and in-message flags are escaped.&lt;/p&gt;
&lt;p&gt;Let's see how the receiver handles such a frame. For demonstration, assume that the first byte the receiver draws from the serial port is not a real part of the message (we want to see how it handles this). In the following diagram, 'Receiver state' is the state of the receiver &lt;em&gt;after&lt;/em&gt; the received byte. 'Data buffer' is the currently accumulated message buffer to pass to an upper level:&lt;/p&gt;
&lt;img src="https://eli.thegreenplace.net/images/2009/08/example1_rcv.png" /&gt;
&lt;p&gt;A few things to note:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The &amp;quot;stray&amp;quot; byte before the header is ignored: according to the protocol each frame has to start with a header, so this isn't part of the frame.&lt;/li&gt;
&lt;li&gt;The start and end flags are not inserted into the data buffer&lt;/li&gt;
&lt;li&gt;Escapes (DLEs) are correctly handled by a special state&lt;/li&gt;
&lt;li&gt;When the frame is finished with an end flag, the receiver has a frame ready to pass to an upper level, and comes back waiting for a header - a new frame.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Finally, we see that the message received is exactly the message sent. All the protocol details (flags, escapes and so on) were transparently handled by the data link layer &lt;a class="footnote-reference" href="#id16" id="id8"&gt;[8]&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;There are several methods of handling framing in communications, although most are unsuitable to be used on top of the serial port. Among the ones that are suitable, the most commonly used is &lt;em&gt;byte stuffing&lt;/em&gt;. By defining a couple of &amp;quot;magic value&amp;quot; flags and careful rules of escaping, this framing methods is both robust and easy to implement as a software layer. It is also widely used as PPP depends on it.&lt;/p&gt;
&lt;p&gt;Finally, it's important to remember that for a high level of robustness, it's required to add some kind of error checking into the protocol - such as computing a CRC on the message and appending it as the last word of the message, which the receiver can verify before deciding that the message is valid.&lt;/p&gt;
&lt;div align="center" class="align-center"&gt;&lt;img class="align-center" src="https://eli.thegreenplace.net/images/hline.jpg" style="width: 320px; height: 5px;" /&gt;&lt;/div&gt;
&lt;table class="docutils footnote" frame="void" id="id9" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;The Data Link Layer is layer 2 in the &lt;a class="reference external" href="http://en.wikipedia.org/wiki/OSI_model"&gt;OSI model&lt;/a&gt;. In the &lt;a class="reference external" href="http://en.wikipedia.org/wiki/TCP/IP_model"&gt;TCP/IP model&lt;/a&gt; it's simply called the &amp;quot;link layer&amp;quot;.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id10" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id2"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;The serial port can be configured to add parity bits to bytes. These days, this option is rarely used, because:&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;A single parity bit isn't a very strong means of detecting errors. 2-bit errors fool it.&lt;/li&gt;
&lt;li&gt;Error handling is usually done by stronger means at a higher level.&lt;/li&gt;
&lt;/ul&gt;
&lt;table class="docutils footnote" frame="void" id="id11" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id3"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;For example Ethernet (802.3) uses 12 octets of idle characters between frames.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id12" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id4"&gt;[4]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;You might run into the term DLE - Data Link Escape, which means the same thing. I will use the acronyms DLE and ESC interchangeably.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id13" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id5"&gt;[5]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Just like quotes and escape characters in strings! In C: &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;&amp;quot;I&lt;/span&gt; &lt;span class="pre"&gt;say&lt;/span&gt; &lt;span class="pre"&gt;\&amp;quot;Hello\&amp;quot;&amp;quot;&lt;/span&gt;&lt;/tt&gt;. To escape the escape, repeat it: &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;&amp;quot;Here&lt;/span&gt; &lt;span class="pre"&gt;comes&lt;/span&gt; &lt;span class="pre"&gt;the&lt;/span&gt; &lt;span class="pre"&gt;backslash:&lt;/span&gt; &lt;span class="pre"&gt;\\&lt;/span&gt; &lt;span class="pre"&gt;-&lt;/span&gt; &lt;span class="pre"&gt;seen&lt;/span&gt; &lt;span class="pre"&gt;it?&amp;quot;&lt;/span&gt;&lt;/tt&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id14" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id6"&gt;[6]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;I'd love to hear why this XOR-ing is required. One simple reason I can think of is to prevent the flag and escape bytes appearing &amp;quot;on the line&amp;quot; even after they're escaped. Presumably this improves resynchronization if the escape byte is lost?&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id15" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id7"&gt;[7]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Which is just a fancy way to say &amp;quot;a protocol wrapping function&amp;quot;, since the layer is implemented in software.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id16" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id8"&gt;[8]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Such transparency is one of the greatest ideas of layered network protocols. So when we implement protocols in software, it's a good thing to keep in mind - transparency aids modularity and decoupling, it's a &lt;em&gt;good thing&lt;/em&gt;.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

    </content><category term="misc"></category><category term="EE &amp; Embedded"></category><category term="Serial port"></category></entry><entry><title>Book review: "Tab electronics guide to understanding Electricity and Electronics" by G. Randy Slone</title><link href="https://eli.thegreenplace.net/2009/07/10/book-review-tab-electronics-guide-to-understanding-electricity-and-electronics-by-g-randy-slone" rel="alternate"></link><published>2009-07-10T10:28:41-07:00</published><updated>2022-10-04T14:08:24-07:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2009-07-10:/2009/07/10/book-review-tab-electronics-guide-to-understanding-electricity-and-electronics-by-g-randy-slone</id><summary type="html">
        This book has two main aims. One is to teach the basics of electronics. The other is to serve as a guide to electronics hobbyists for setting up a lab to build stuff and experiment with circuits. It is the second aim which spurred me to purchase it. 

I think …</summary><content type="html">
        This book has two main aims. One is to teach the basics of electronics. The other is to serve as a guide to electronics hobbyists for setting up a lab to build stuff and experiment with circuits. It is the second aim which spurred me to purchase it. 

I think the best way to present this review is as a list of pros and cons of the book. Pros:

&lt;ol&gt;
	&lt;li&gt;As far as I can tell (mainly from work experience) without actually building anything following the book's directions, the advice given on setting up a workbench is correct, interesting and easy to follow. Since this is one of the main goals of the book, it's an important point in its favor.&lt;/li&gt;
	&lt;li&gt;Basic electronics, up to and including BJTs are explained quite well - I think that any intelligent beginner can learn a lot from this book, even without prior experience. The author manages to leverage intuition in useful ways whenever possible, and doesn't get into the complex math you often see in textbooks on the subject.&lt;/li&gt;
	&lt;li&gt;The book contains a lot of interesting and useful circuits to build, in specially designated "Circuit Porpourri" sections. After some point in the book, the author presents several circuits at the end of each chapter, explaining in brief what they do and specifying which components to purchase, and how to connect everything together.&lt;/li&gt;
&lt;/ol&gt;

Cons:

&lt;ol&gt;
	&lt;li&gt;The author has made an unfortunate decision to use electron current flow (current flows from negative to positive) instead of the conventional current flow used almost universally throughout the industry. While electron flow is admittedly more correct in most cases, convention plays a strong role here, and the author should've followed it. Doesn't it feel funny for a beginner to read that "in the transistor, the current goes against the arrow"? Why against?
&lt;/li&gt;
	&lt;li&gt;Although the second edition is from 1990, the book is dated. This is clearly seen in the equipment photographs the author uses, as well as in some advice. For instance, AFAIK, no one uses paper catalogs for components these days - datasheets are downloaded from the web and catalogs are online too.
&lt;/li&gt;

	&lt;li&gt;After the chapter on BJTs, the wind ran out in the author's sails for clear explanations. MOSFETs are explained in a very sketchy way, and op-amps are left practically without any explanation at all. Nevertheless the author keeps piling up circuits assuming the reader will just learn this stuff in some other place?
&lt;/li&gt;
&lt;/ol&gt;

That said, for $16 (darn cheap for books on Electronics) the book isn't a bad deal. Especially if you're looking into setting up your own electronics lab, this book can be a valuable first guide. I wouldn't recommend seriously attempting to learn electronics with it as the only source, though. In this aspect, this book can serve as only a basic introduction, with more serious texts being a must for deeper understanding of the more advanced concepts circuits.






    </content><category term="misc"></category><category term="Book reviews"></category><category term="EE &amp; Embedded"></category></entry><entry><title>Solution to the RC circuit puzzle</title><link href="https://eli.thegreenplace.net/2008/12/26/solution-to-the-rc-circuit-puzzle" rel="alternate"></link><published>2008-12-26T11:21:45-08:00</published><updated>2023-02-04T13:41:52-08:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2008-12-26:/2008/12/26/solution-to-the-rc-circuit-puzzle</id><summary type="html">
        Here, as promised, is the solution to the &lt;a href="https://eli.thegreenplace.net/2008/12/22/an-rc-circuit-puzzle"&gt;RC circuit puzzle&lt;/a&gt; I posted earlier this week.

Let's look at the circuit again:

&lt;p&gt;&lt;img src="https://eli.thegreenplace.net/images/2008/12/cap_resistor.png" /&gt;&lt;/p&gt;

The problem with my reasoning was the direction of current in the capacitor. I've quietly assumed that:


&lt;p&gt;&lt;img src="https://eli.thegreenplace.net/images/math/bbdc708e5df1d3ca3312149e15dbecc98b8fea5a.gif" class="align-center" /&gt;&lt;/p&gt;


But this is wrong for the circuit above. Why? Because we …</summary><content type="html">
        Here, as promised, is the solution to the &lt;a href="https://eli.thegreenplace.net/2008/12/22/an-rc-circuit-puzzle"&gt;RC circuit puzzle&lt;/a&gt; I posted earlier this week.

Let's look at the circuit again:

&lt;p&gt;&lt;img src="https://eli.thegreenplace.net/images/2008/12/cap_resistor.png" /&gt;&lt;/p&gt;

The problem with my reasoning was the direction of current in the capacitor. I've quietly assumed that:


&lt;p&gt;&lt;img src="https://eli.thegreenplace.net/images/math/bbdc708e5df1d3ca3312149e15dbecc98b8fea5a.gif" class="align-center" /&gt;&lt;/p&gt;


But this is wrong for the circuit above. Why? Because we must obey the voltage &amp; current directions we've chosen. In passive elements, the positive current flows from the higher voltage to the lower voltage, meaning that in our circuit:


&lt;p&gt;&lt;img src="https://eli.thegreenplace.net/images/math/31dd3853efeb2e16318323bc12736da4de1277fa.gif" class="align-center" /&gt;&lt;/p&gt;


This small minus sign makes all the difference, and now the solution will be correct.

Physically, the intuition is that the current here flows from a discharging capacitor, hence it's "against" the voltage direction. Had it been a capacitor-charging circuit, there would be no confusion.



    </content><category term="misc"></category><category term="EE &amp; Embedded"></category><category term="Math"></category></entry><entry><title>An RC circuit puzzle</title><link href="https://eli.thegreenplace.net/2008/12/22/an-rc-circuit-puzzle" rel="alternate"></link><published>2008-12-22T22:16:05-08:00</published><updated>2022-10-04T14:08:24-07:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2008-12-22:/2008/12/22/an-rc-circuit-puzzle</id><summary type="html">
        If you're interested in electronics, you'll find the following simple "paradox" amusing. It's the usual case of "proving that 2+2=5". The fun is finding where the mistake in the reasoning is.

Consider the following circuit:

&lt;p&gt;&lt;img src="https://eli.thegreenplace.net/images/2008/12/cap_resistor.png" /&gt;&lt;/p&gt;

Assume that the capacitor is charged to some initial voltage before the switch …</summary><content type="html">
        If you're interested in electronics, you'll find the following simple "paradox" amusing. It's the usual case of "proving that 2+2=5". The fun is finding where the mistake in the reasoning is.

Consider the following circuit:

&lt;p&gt;&lt;img src="https://eli.thegreenplace.net/images/2008/12/cap_resistor.png" /&gt;&lt;/p&gt;

Assume that the capacitor is charged to some initial voltage before the switch is closed. At  time 0, the switch is closed. What is the current in the circuit as a function of time ? 

Let's solve it using the familiar RC circuit methods. We know that &lt;img src="https://eli.thegreenplace.net/images/math/5e23343bb687c00a0eb8ce9ef60e95b356568127.gif" /&gt; because of Kirchoff's voltage law. We'll differentiate both sides by time:

$\dot{V}_{c}(t) = \dot{V}_{R}(t)$

We know that for a capacitor, the relation between current and voltage is:


&lt;p&gt;&lt;img src="https://eli.thegreenplace.net/images/math/928acbef4f8f2eeb39d3c51ca68ab3e08279393f.gif" class="align-center" /&gt;&lt;/p&gt;


Substituting it into the equation above and also recalling that &lt;img src="https://eli.thegreenplace.net/images/math/6809dfc8324feb51c746bc469c8bd7dbbe3ea32e.gif" /&gt;, we get:


&lt;p&gt;&lt;img src="https://eli.thegreenplace.net/images/math/73fa9296a1e93050c9ba41b7bd8d5ddeaa1d84a6.gif" class="align-center" /&gt;&lt;/p&gt;


But the current through the capacitor and resistor is the same current, so this can be rewritten simply as:


&lt;p&gt;&lt;img src="https://eli.thegreenplace.net/images/math/eba020de23be652ba084b91a27aa173aade8a360.gif" class="align-center" /&gt;&lt;/p&gt;


This is a simple first order differential equation, the solution of which is:


&lt;p&gt;&lt;img src="https://eli.thegreenplace.net/images/math/46c7da1f88d1806982454f784d37742fbfa0c332.gif" class="align-center" /&gt;&lt;/p&gt;


For some initial current &lt;img src="https://eli.thegreenplace.net/images/math/7dd1d81670e79a2861ab8214c079d2f03ee310a0.gif" /&gt;. But wait a second, how can the exponent be positive, won't it grow to infinity with time ? There's obviously a mistake here, somewhere. Can you find it ?

This problem gave me some headache last night, and today I've successfully stumped a few co-workers with it. I'll post a solution in a couple of days.




    </content><category term="misc"></category><category term="EE &amp; Embedded"></category><category term="Math"></category></entry><entry><title>memmgr - a fixed-pool memory allocator</title><link href="https://eli.thegreenplace.net/2008/10/17/memmgr-a-fixed-pool-memory-allocator" rel="alternate"></link><published>2008-10-17T12:44:17-07:00</published><updated>2024-05-04T19:46:23-07:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2008-10-17:/2008/10/17/memmgr-a-fixed-pool-memory-allocator</id><summary type="html">
        In embedded systems, it is common to write code that runs on "bare metal", i.e. without an operating system. On one hand, it is very empowering. When you write your &lt;code&gt;main&lt;/code&gt; function (assuming it's C, of course, but that's a safe assumption for 95% of embedded code), you know …</summary><content type="html">
        In embedded systems, it is common to write code that runs on "bare metal", i.e. without an operating system. On one hand, it is very empowering. When you write your &lt;code&gt;main&lt;/code&gt; function (assuming it's C, of course, but that's a safe assumption for 95% of embedded code), you know it has the full control of the processor. Your program is the brains of the chip - whatever you write, the chip performs, without any external code getting in your way.

On the other hand, code running this way misses many of the benefits operating systems provide. Process control, memory management, file system, and so on.

When writing code to run on bare metal, there are some special precautions one must take. One important point to consider is the heap - dynamic memory allocation. An embedded system (think of the safety controller of a Boeing plane) can't just fail because the heap runs out. When &lt;code&gt;malloc&lt;/code&gt; returns 0 to your desktop-application code, in most cases you will just bail out, because most probably it's the system's fault, and you don't have much choice. In an embedded controller, this is not an option. There is nowhere to bail out to, and in any case, that heap memory ran out is &lt;em&gt;your fault&lt;/em&gt;, a bug in your design or code.

To help managing these complications, embedded programmers often avoid heap allocation altogether, and only use static allocation (i.e. arrays allocated at compile (or more accurately - link/load) time). However, sometimes this is less than optimal, because:

&lt;ol&gt;
	&lt;li&gt;Dynamic allocation helps write code in a more convenient and reusable way.&lt;/li&gt;
	&lt;li&gt;You may be using some 3rd party code that uses dynamic allocation&lt;/li&gt;
&lt;/ol&gt;

The solutions to this problem are numerous, but as any self-respecting embedded programmer, I wrote my own fixed-pool memory allocator. It provides a pair of functions:

&lt;pre&gt;&lt;code&gt;
// 'malloc' clone
//
void* memmgr_alloc(ulong nbytes);

// 'free' clone
//
void memmgr_free(void* ap);
&lt;/code&gt;&lt;/pre&gt;

That can be used as a drop-in replacement for &lt;code&gt;malloc&lt;/code&gt; and &lt;code&gt;free&lt;/code&gt;, but with a twist. There is no heap involved. All the memory is allocated from, and returned to, a fixed pool of memory that's allocated at link time (in simpler terms: a static array). This way, you know the maximal amount of space your heap will take even before running the program, and can use these functions to test that your program indeed doesn't allocate more than you assumed.

Moreover, the library allows a printout of allocation statistics (which you can enhance, the code is open) that will help diagnose allocation problems and memory leaks.

The library (350 LOC of ANSI C) can be downloaded &lt;a href="https://github.com/eliben/code-for-blog/tree/main/2008/memmgr"&gt;from here&lt;/a&gt;. Let me know if you've found it useful.





    </content><category term="misc"></category><category term="C &amp; C++"></category><category term="EE &amp; Embedded"></category></entry><entry><title>TFTP</title><link href="https://eli.thegreenplace.net/2007/04/03/tftp" rel="alternate"></link><published>2007-04-03T12:42:39-07:00</published><updated>2022-10-04T14:08:24-07:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2007-04-03:/2007/04/03/tftp</id><summary type="html">
      &lt;p&gt;
        Some time ago I heard about TFTP - something I've never encountered
        before. TFTP is an acronym for Trivial File Transfer Protocol. Yes, like
        FTP, just Trivial. TFTP is a much watered down version of FTP - its only
        command is to transfer a file from a place to a place - no …&lt;/p&gt;</summary><content type="html">
      &lt;p&gt;
        Some time ago I heard about TFTP - something I've never encountered
        before. TFTP is an acronym for Trivial File Transfer Protocol. Yes, like
        FTP, just Trivial. TFTP is a much watered down version of FTP - its only
        command is to transfer a file from a place to a place - no directory
        listing, deleting, renaming, user authentication. What is it useful for,
        one may wonder.
      &lt;/p&gt;&lt;p&gt;

Well, not every computer is a PC. In recent years more and more small embedded
devices are becoming networked, and one of the best forms of networking is TCP /
UDP / IP - the same set of protocols the Internet works on. 
      &lt;/p&gt;&lt;p&gt;

TFTP works on top of UDP, as opposed to FTP which works on TCP. UDP is a far
simpler protocol than TCP, since it is a "send and forget" concept, without
ensuring the correct arrival of data, in order, like TCP does. As a result, it
is much easier to implement which leads to an implementation with a smaller
footprint, and this is important for embedded devices. TFTP itself is also much
simpler than FTP. It ensures the correct transfer of data by employing a simple
&lt;a href="http://www.erg.abdn.ac.uk/users/gorry/course/arq-pages/saw.html"&gt;stop
and wait&lt;/a&gt; protocol on top of UDP. I assume that it also makes it slower than
FTP on non-congested networks, since FTP's reliability is achieved on the TCP
level which works in &lt;a href="http://www.erg.abdn.ac.uk/users/gorry/course/arq-pages/sr.html"&gt;selective
                       repeat&lt;/a&gt;. However, simplicity is often more important
                     than performance, especially for embedded devices with
                     small amounts of ROM. 
      &lt;/p&gt;&lt;p&gt;

So TFTP is perfect for embedded devices to transfer data to and from each other
(and PCs) in a reliable, quick way (UDP / IP on Ethernet is far faster than
serial RS232 / RS485 communication, the most common interconnection method of
embedded devices).
      &lt;/p&gt;&lt;p&gt;

The research into TFTP led me through a few interesting sources of information,
on Wikipedia, HowStuffWorks and RFCs. &lt;a href="http://tools.ietf.org/html/rfc1180"&gt;RFC 1180&lt;/a&gt; is especially helpful -
it's a tutorial written in a very readable style that explains the basics of IP,
ARP, routing tables and TCP / UDP. &lt;a href="http://tools.ietf.org/html/rfc1350"&gt;RFC 1350&lt;/a&gt; describes TFTP. &lt;a href="http://tools.ietf.org/html/rfc1123"&gt;RFC 1123&lt;/a&gt; is a thorough collection
of all Internet related protocols with cross references to other relevant RFCs.
      &lt;/p&gt;&lt;p&gt;

The TCP / UDP / IP network stack is one of the nicest examples of sound
engineering, and IMHO it is beneficial to get at least a superficial
understanding of how these things work under the hood.
      &lt;/p&gt;

    </content><category term="misc"></category><category term="EE &amp; Embedded"></category><category term="Internet"></category></entry><entry><title>Antialiasing filters and multirate systems</title><link href="https://eli.thegreenplace.net/2006/05/10/antialiasing-filteres-and-multirate-systems" rel="alternate"></link><published>2006-05-10T17:27:30-07:00</published><updated>2023-06-30T23:16:27-07:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2006-05-10:/2006/05/10/antialiasing-filteres-and-multirate-systems</id><summary type="html">
        &lt;h4&gt;What is this about ?&lt;/h4&gt;

Antialiasing is an important topic to understand when dealing with digital processing of data. In this article I concentrate on the various methods used to combat this phenomenon, and try to explain what is multirate filtering and how it is related to antialiasing.

&lt;h4&gt;Sampling&lt;/h4&gt;

Both analog …</summary><content type="html">
        &lt;h4&gt;What is this about ?&lt;/h4&gt;

Antialiasing is an important topic to understand when dealing with digital processing of data. In this article I concentrate on the various methods used to combat this phenomenon, and try to explain what is multirate filtering and how it is related to antialiasing.

&lt;h4&gt;Sampling&lt;/h4&gt;

Both analog and digital signals can be sampled. If we use an ADC that runs at 10^6 samples per second, then we can say that the analog signal on the ADCs input is sampled at frequency Fs = 1 MHz. Each digital signal has some sampling frequency tied to it - the frequency at which it was sampled &lt;a href="#note1"&gt;[1]&lt;/a&gt;. If we take a digital signal that was sampled at frequency Fs, and grab each 4th sample discarding the others, we get a digital signal sampled at Fs/4.

&lt;h4&gt;What is aliasing ?&lt;/h4&gt;

I won't go too much into mathematical details here, as I assume that the basics are well known. Whenever some signal (either analog or digital) is sampled at frequency Fs, aliasing will occur if the original signal had harmonics at Fs/2 or higher (that is, if the sampling frequency was below the Nyquist frequency of the signal). See the links section in the end of this articles for more details. Aliasing is "bad for you", it distorts a signal in a way that can't really be fixed, so engineers to their best to avoid it. Fortunately, it is quite simple, using antialias filters.

&lt;h4&gt;Antialias filters&lt;/h4&gt;

So, we have a signal we want to sample, and we want to avoid aliasing. What should be done ? Generally, given that our sampling rate is Fs, we just need to make sure that there are no harmonics faster than Fs/2 in the signal. How can we assure this ? By using a lowpass filter that cuts all the harmonics above Fs/2. Such a lowpass filter is called an "antialias filter".
&lt;p /&gt;
Say that the input to your system is an analog signal. You know that it has no "important" information at harmonics above 10 KHz, so you can safely sample it with an ADC at 20 KHz. However, although nothing above 10 KHz interests you, the signal might (and &lt;b&gt;will&lt;/b&gt;, in a real-world system) have some power at harmonics above 10 KHz, mostly because of noise and the imperfect nature of analog signals. So, how do you avoid aliasing ? Right, by using an antialias filter. And how is that done ? Exactly - just prepend a lowpass filter to the ADC, which cuts off at 10 KHz, and viola, you'll have a clean sampled signal.

&lt;h4&gt;Analog antialias filters&lt;/h4&gt;

This is nice in theory, but in the real world, such an implementation poses some serious difficulties. To get a clean signal, you must use a very accurate lowpass filter, one that passes everything below 10 KHz and nothing above 10 KHz. In the DSP jargon such a filter is called a "brick-wall" filter, since it looks like a brick wall with completely right angles. 
&lt;p /&gt;
The sad truth is that such filters are impossible. They are unreal - a theoretical delirium. We can get quite close though, but constructing an analog filter that is close to a brick wall requires an accurate, high-order filtering circuitry, which is difficult and quite expensive. Fortunately, there is hope - multirate filtering to the rescue !

&lt;h4&gt;Digital antialias filters&lt;/h4&gt;

I will discuss the general topic of multirate filtering below, but for now I want to explain how it helps with digital antialias filtering.
&lt;p /&gt;
Consider the following solution to the problem presented in the last section: We know that there's interesting information at up to 10 KHz, so we should sample the signal at &lt;i&gt;at least&lt;/i&gt; 20 KHz, according to the sampling theorem &lt;a href="#note2"&gt;[2]&lt;/a&gt;. But nothing prevents us from sampling it at a much higher frequency, and gain an important advantage by doing so.
&lt;p /&gt;
Suppose we sample the signal at 100 KHz instead of 20 KHz. Now, to avoid antialiasing in this sampling, we must attach a lowpass filter before the ADC that cuts off at 50 KHz. Note, however, that it is not obliged to be a brick wall filter, since 50 KHz is very far from 10 KHz where the information is, so we don't mind for some useless frequencies at 40+KHz to be attenuated. Hence, we can attach a very simple analog filter before the ADC - a RC for example, tuned to 50 KHz. This helps with the antialiasing of the 100 KHz sample, but it doesn't ensure a clean signal, since frequencies between 10 and 50 KHz still pass through, disrupting information that is stored at below 10 KHz.
&lt;p /&gt;
To solve this problem, we now apply another antialias filter on the sampled data. We can now apply a digital lowpass filter tuned to cut-off at 10 KHz. Digital filters also can't be brick wall, but they can easily approach it, at a fraction of the cost of an analog filter with the same specification !
&lt;p /&gt;
So, the full solution is: sample the input signal at 100 KHz with an ADC, which has a simple RC filter at its input configured to cut off at 50 KHz. Next, we apply an "almost brick wall" digital lowpass filter configured to cut off at 10 KHz. Then, we can resample our 100 KHz signal to 20 KHz (by simply discarding 4 out of each 5 samples) and yay - we have a clean 10 KHz signal sampled at 20 KHz, no aliasing and no noise disrupting the information.

&lt;h4&gt;Multirate systems&lt;/h4&gt;

"Multirate" simply means &lt;i&gt;multiple sampling rates&lt;/i&gt;. A multirate DSP system uses multiple sampling rates within the system. In the example above, we have a multirate system because the signal is first sampled at 100 KHz and later re-sampled at 20 KHz. Generally, if we can allow to increase the initial sampling frequency of the analog signal (which is called &lt;i&gt;oversampling the signal&lt;/i&gt;), we can lower the overall cost of the system because the analog part becomes much simpler.

&lt;h4&gt;Decimation, Interpolation and Resampling&lt;/h4&gt;

&lt;i&gt;Decimation&lt;/i&gt; is decreasing the sampling rate of a signal. In our example, after the digital antialias filter is applied, the signal is decimated by a factor of 5 from 100 KHz to 20 KHz. Another common use for decimation is decreasing the sampling rate to ease on the computation. Suppose you just need to sample an audio signal, for which 44 KHz is usually enough, but you only have a 10 MHz ADC. Why overwhelm your processor with so much samples, when decimating by a factor of 100 would be just fine.
&lt;p /&gt;
&lt;i&gt;Interpolation&lt;/i&gt; is the reverse process - increasing the sampling rate of a signal. This is usually done by inserting a certain amount of zeros between each sample of a signal (inserting N zeros means a N + 1 times increase in the signal's frequency) and passing the signal through a digital lowpass filter. The aim is often to generate an input for a system with a faster sampling rate.
&lt;p /&gt;
&lt;i&gt;Resampling&lt;/i&gt; is a combination of Decimation and Interpolation. If you have a signal with sampling frequency Fs and you want to have a signal with a sampling frequency of 2.5 * Fs, you can first interpolate the signal by a factor of 5 and then decimate it by a factor of 2.
&lt;p /&gt;
Note: in some digital FIR filter generation tools, it is often possible to combine a FIR with decimation and / or interpolation. This is because the combination allows for a more efficient implementation than separate stages of filtering and resampling.

&lt;h4&gt;Digital-only antialias filtering&lt;/h4&gt;

A common misconception seems to be that it is possible to implement antialias filtering without analog circuitry. This is false. Between a real world analog signal and a digital system there must, somewhere, lie the brink where the analog signal is sampled to turn it into the digital signal. And in real physical signals, wherever there is sampling, there is aliasing. So analog filtering is essential, unless you are very sure that your analog signal really doesn't have any power at above Fs/2, which is rarely the case.
&lt;p /&gt;
A good rule of thumb is: whenever you sample an analog signal for digital processing with an ADC at rate Fs, attach a simple RC lowpass filter configured to cut off at Fs/2 before the ADC (it is best to make is a little less than Fs/2 to account for the very imperfect performance of a RC filter). This assures that the sampled signal is free of aliases. Later, you can apply multirate techniques with digital filters to further shape your digital signal.
&lt;p /&gt;
So remember, digital antialias filtering works only for digital signals.


&lt;h4&gt;Links&lt;/h4&gt;

These links were active at the time I wrote the article. If you find a dead link, let me know. In any case, Googling for the link's title may bring you to its new location and other related sources.
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://en.wikipedia.org/wiki/Aliasing"&gt;Wikipedia entry on aliasing&lt;/a&gt;
&lt;li&gt;&lt;a href="http://www.bores.com/courses/intro/basics/1_alias.htm"&gt;Introduction to DSP - aliasing&lt;/a&gt;
&lt;li&gt;&lt;a href="http://www.netrino.com/Publications/Glossary/Filters.html"&gt;Introduction to digital filters&lt;/a&gt;
&lt;li&gt;&lt;a href="http://en.wikipedia.org/wiki/Nyquist-Shannon_sampling_theorem"&gt;Wikipedia entry on the Nyquist-Shannon sampling theorem&lt;/a&gt;
&lt;li&gt;&lt;a href="http://www.dspguru.com/info/faqs/mrfaq.htm"&gt;Multirate FAQ&lt;/a&gt;
&lt;li&gt;&lt;a href="http://www.dspguide.com/pdfbook.htm"&gt;The Scientist and Engineer's Guide to Digital Signal Processing&lt;/a&gt; - A free book
&lt;/ol&gt;
&lt;p /&gt;

&lt;h4&gt;Notes&lt;/h4&gt;

&lt;a name="note1"&gt;[1]&lt;/a&gt; - For simplicity it is sometimes useful to assume that an analog signal is just a digital signal sampled at a very high frequency, say 10^50 Hz. 
&lt;p /&gt;
&lt;a name="note2"&gt;[2]&lt;/a&gt; - The sampling theorem states that in order for a band limited (at Fv) signal to be reconstructed fully, it must be sampled at a rate Fs &gt;= 2*Fv. 

    </content><category term="misc"></category><category term="EE &amp; Embedded"></category></entry></feed>