<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Eli Bendersky's website - Python</title><link href="https://eli.thegreenplace.net/" rel="alternate"></link><link href="https://eli.thegreenplace.net/feeds/python.atom.xml" rel="self"></link><id>https://eli.thegreenplace.net/</id><updated>2025-02-14T13:49:31-08:00</updated><entry><title>Decorator JITs - Python as a DSL</title><link href="https://eli.thegreenplace.net/2025/decorator-jits-python-as-a-dsl/" rel="alternate"></link><published>2025-02-03T06:22:00-08:00</published><updated>2025-02-14T13:49:31-08:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2025-02-03:/2025/decorator-jits-python-as-a-dsl/</id><summary type="html">&lt;p&gt;Spend enough time looking at Python programs and packages for machine learning,
and you'll notice that the &amp;quot;JIT decorator&amp;quot; pattern is pretty popular. For
example, this JAX snippet:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;jax.numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;jnp&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;jax&lt;/span&gt;

&lt;span class="nd"&gt;@jax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jit&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;jnp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Use &amp;quot;add&amp;quot; as a â€¦&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;Spend enough time looking at Python programs and packages for machine learning,
and you'll notice that the &amp;quot;JIT decorator&amp;quot; pattern is pretty popular. For
example, this JAX snippet:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;jax.numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;jnp&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;jax&lt;/span&gt;

&lt;span class="nd"&gt;@jax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jit&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;jnp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Use &amp;quot;add&amp;quot; as a regular Python function&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Or the &lt;a class="reference external" href="https://triton-lang.org/main/index.html"&gt;Triton language&lt;/a&gt;
for writing GPU kernels directly in Python:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;triton&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;triton.language&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;tl&lt;/span&gt;

&lt;span class="nd"&gt;@triton&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jit&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;add_kernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_ptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="n"&gt;y_ptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="n"&gt;output_ptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="n"&gt;n_elements&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;tl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constexpr&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;pid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;program_id&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;block_start&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pid&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt;
    &lt;span class="n"&gt;offsets&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;block_start&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;tl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;offsets&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;n_elements&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_ptr&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;offsets&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_ptr&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;offsets&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
    &lt;span class="n"&gt;tl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;store&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output_ptr&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;offsets&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In both cases, the function decorated with &lt;tt class="docutils literal"&gt;jit&lt;/tt&gt; doesn't get executed by the
Python interpreter in the normal sense. Instead, the code inside is more like
a DSL (Domain Specific Language) processed by a special purpose compiler built
into the library (JAX or Triton). Another way to think about it is that Python
is used as a &lt;em&gt;meta language&lt;/em&gt; to describe computations.&lt;/p&gt;
&lt;p&gt;In this post I will describe some implementation strategies used by libraries to
make this possible.&lt;/p&gt;
&lt;div class="section" id="preface-where-we-re-going"&gt;
&lt;h2&gt;Preface - where we're going&lt;/h2&gt;
&lt;p&gt;The goal is to explain how different kinds of &lt;tt class="docutils literal"&gt;jit&lt;/tt&gt; decorators work by using
a simplified, educational example that implements several approaches from
scratch. All the approaches featured in this post will be using this flow:&lt;/p&gt;
&lt;img alt="Flow of Python source --&amp;gt; Expr IR --&amp;gt; LLVM IR --&amp;gt; Execution" class="align-center" src="https://eli.thegreenplace.net/images/2025/decjit-python.png" /&gt;
&lt;p&gt;These are the steps that happen when a Python function wrapped with
our educational &lt;tt class="docutils literal"&gt;jit&lt;/tt&gt; decorator is called:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;The function is translated to an &amp;quot;expression IR&amp;quot; - &lt;tt class="docutils literal"&gt;Expr&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;This expression IR is converted to LLVM IR.&lt;/li&gt;
&lt;li&gt;Finally, the LLVM IR is JIT-executed.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Steps (2) and (3) use &lt;a class="reference external" href="https://github.com/numba/llvmlite"&gt;llvmlite&lt;/a&gt;; I've
written about llvmlite before, see &lt;a class="reference external" href="https://eli.thegreenplace.net/2015/building-and-using-llvmlite-a-basic-example/"&gt;this post&lt;/a&gt;
and also the &lt;a class="reference external" href="https://github.com/eliben/pykaleidoscope"&gt;pykaleidoscope project&lt;/a&gt;.
For an introduction to JIT compilation, be sure to &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/11/05/how-to-jit-an-introduction"&gt;read this&lt;/a&gt;
and maybe also the series of posts &lt;a class="reference external" href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-1-an-interpreter/"&gt;starting here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;First, let's look at the &lt;tt class="docutils literal"&gt;Expr&lt;/tt&gt; IR. Here we'll make a big simplification -
only supporting functions that define a single expression, e.g.:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;expr2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Naturally, this can be easily generalized - after all, LLVM IR can be used to
express fully general computations.&lt;/p&gt;
&lt;p&gt;Here are the &lt;tt class="docutils literal"&gt;Expr&lt;/tt&gt; data structures:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Expr&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;pass&lt;/span&gt;

&lt;span class="nd"&gt;@dataclass&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;ConstantExpr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Expr&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;

&lt;span class="nd"&gt;@dataclass&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;VarExpr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Expr&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;
    &lt;span class="n"&gt;arg_idx&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Op&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Enum&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;ADD&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;+&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;SUB&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;-&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;MUL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;*&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;DIV&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;/&amp;quot;&lt;/span&gt;

&lt;span class="nd"&gt;@dataclass&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;BinOpExpr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Expr&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;left&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Expr&lt;/span&gt;
    &lt;span class="n"&gt;right&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Expr&lt;/span&gt;
    &lt;span class="n"&gt;op&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Op&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To convert an &lt;tt class="docutils literal"&gt;Expr&lt;/tt&gt; into LLVM IR and JIT-execute it, we'll use this function:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;llvm_jit_evaluate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Expr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Use LLVM JIT to evaluate the given expression with *args.&lt;/span&gt;

&lt;span class="sd"&gt;    expr is an instance of Expr. *args are the arguments to the expression, each&lt;/span&gt;
&lt;span class="sd"&gt;    a float. The arguments must match the arguments the expression expects.&lt;/span&gt;

&lt;span class="sd"&gt;    Returns the result of evaluating the expression.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;initialize&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;initialize_native_target&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;initialize_native_asmprinter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;initialize_native_asmparser&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="n"&gt;cg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;_LLVMCodeGenerator&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;modref&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse_assembly&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;codegen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;

    &lt;span class="n"&gt;target&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Target&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_default_triple&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;target_machine&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;create_target_machine&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;create_mcjit_compiler&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;modref&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;target_machine&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;ee&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;ee&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;finalize_object&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;cfptr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ee&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_function_address&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;func&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;cfunc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;CFUNCTYPE&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c_double&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;c_double&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;)))(&lt;/span&gt;&lt;span class="n"&gt;cfptr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;cfunc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It uses the &lt;tt class="docutils literal"&gt;_LLVMCodeGenerator&lt;/tt&gt; class to actually generate LLVM IR from &lt;tt class="docutils literal"&gt;Expr&lt;/tt&gt;.
This process is straightforward and covered extensively in the resources I
linked to earlier; take a look at &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/blob/main/2025/decjit/exprcode.py"&gt;the full code here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;My goal with this architecture is to make things simple, but &lt;em&gt;not too simple&lt;/em&gt;.
On one hand - there are several simplifications: only single expressions are
supported, very limited set of operators, etc. It's very easy to extend this!
On the other hand, we could have just trivially evaluated the &lt;tt class="docutils literal"&gt;Expr&lt;/tt&gt;
without resorting to LLVM IR; I do want to show a more complete compilation
pipeline, though, to demonstrate that an arbitrary amount of complexity can
be hidden behind these simple interfaces.&lt;/p&gt;
&lt;p&gt;With these building blocks in hand, we can review the strategies used by
&lt;tt class="docutils literal"&gt;jit&lt;/tt&gt; decorators to convert Python functions into &lt;tt class="docutils literal"&gt;Expr&lt;/tt&gt;s.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="ast-based-jit"&gt;
&lt;h2&gt;AST-based JIT&lt;/h2&gt;
&lt;p&gt;Python comes with powerful code reflection and introspection capabilities out
of the box. Here's the &lt;tt class="docutils literal"&gt;astjit&lt;/tt&gt; decorator:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;astjit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nd"&gt;@functools&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wraps&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;wrapper&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="n"&gt;ASTJITError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Keyword arguments are not supported&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;source&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;inspect&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getsource&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;tree&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ast&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="n"&gt;emitter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;_ExprCodeEmitter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;visit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tree&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;llvm_jit_evaluate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;emitter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;return_expr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;wrapper&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is a standard Python decorator. It takes a function and returns another
function that will be used in its place (&lt;tt class="docutils literal"&gt;functools.wraps&lt;/tt&gt; ensures that
function attributes like the name and docstring of the wrapper match the
wrapped function).&lt;/p&gt;
&lt;p&gt;Here's how it's used:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;astjit&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;astjit&lt;/span&gt;

&lt;span class="nd"&gt;@astjit&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;some_expr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;some_expr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After &lt;tt class="docutils literal"&gt;astjit&lt;/tt&gt; is applied to &lt;tt class="docutils literal"&gt;some_expr&lt;/tt&gt;, what &lt;tt class="docutils literal"&gt;some_expr&lt;/tt&gt; holds is the
wrapper. When &lt;tt class="docutils literal"&gt;some_expr(2, 16, 3)&lt;/tt&gt; is called, the wrapper is invoked with
&lt;tt class="docutils literal"&gt;*args = [2, 16, 3]&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;The wrapper obtains the AST of the wrapped function, and then uses
&lt;tt class="docutils literal"&gt;_ExprCodeEmitter&lt;/tt&gt; to convert this AST into an &lt;tt class="docutils literal"&gt;Expr&lt;/tt&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;_ExprCodeEmitter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ast&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;NodeVisitor&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;return_expr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;op_map&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;ast&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Add&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Op&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ADD&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;ast&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Sub&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Op&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SUB&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;ast&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Mult&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Op&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MUL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;ast&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Div&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Op&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DIV&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;visit_FunctionDef&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;arg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arg&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;arg&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;body&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;body&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;ast&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Return&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="n"&gt;ASTJITError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Function must consist of a single return statement&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;visit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;body&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;visit_Return&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;return_expr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;visit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;visit_Name&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="n"&gt;ASTJITError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Unknown variable &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;VarExpr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;visit_Constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;ConstantExpr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;visit_BinOp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;left&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;visit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;left&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;right&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;visit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;right&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;op&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;op_map&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;op&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;BinOpExpr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;left&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;right&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;op&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;KeyError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="n"&gt;ASTJITError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Unsupported operator &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;op&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When &lt;tt class="docutils literal"&gt;_ExprCodeEmitter&lt;/tt&gt; finishes visiting the AST it's given, its
&lt;tt class="docutils literal"&gt;return_expr&lt;/tt&gt; field will contain the &lt;tt class="docutils literal"&gt;Expr&lt;/tt&gt; representing the function's
return value. The wrapper then invokes &lt;tt class="docutils literal"&gt;llvm_jit_evaluate&lt;/tt&gt; with this &lt;tt class="docutils literal"&gt;Expr&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;Note how our decorator interjects into the regular Python execution process.
When &lt;tt class="docutils literal"&gt;some_expr&lt;/tt&gt; is called, instead of the standard Python compilation and
execution process (code is compiled into bytecode, which is then executed
by the VM), we translate its code to our own representation and emit LLVM from
it, and then JIT execute the LLVM IR. While it seems kinda pointless in this
artificial example, in reality this means we can execute the function's code
in any way we like.&lt;/p&gt;
&lt;div class="section" id="ast-jit-case-study-triton"&gt;
&lt;h3&gt;AST JIT case study: Triton&lt;/h3&gt;
&lt;p&gt;This approach is almost exactly how the Triton language works. The body of a
function decorated with &lt;tt class="docutils literal"&gt;&amp;#64;triton.jit&lt;/tt&gt; gets parsed to a Python AST, which then
- through a series of internal IRs - ends up in LLVM IR; this in turn is lowered
to &lt;a class="reference external" href="https://docs.nvidia.com/cuda/parallel-thread-execution/"&gt;PTX&lt;/a&gt; by the
&lt;a class="reference external" href="https://llvm.org/docs/NVPTXUsage.html"&gt;NVPTX LLVM backend&lt;/a&gt;.
Then, the code runs on a GPU using a standard CUDA pipeline.&lt;/p&gt;
&lt;p&gt;Naturally, the subset of Python that can be compiled down to a GPU is limited;
but it's sufficient to run performant kernels, in a language that's much
friendlier than CUDA and - more importantly - lives in the same file with the
&amp;quot;host&amp;quot; part written in regular Python. For example, if you want testing and
debugging, you can run Triton in &amp;quot;interpreter mode&amp;quot; which will just run the
same kernels locally on a CPU.&lt;/p&gt;
&lt;p&gt;Note that Triton lets us import names from the &lt;tt class="docutils literal"&gt;triton.language&lt;/tt&gt; package
and use them inside kernels; these serve as the &lt;em&gt;intrinsics&lt;/em&gt; for the language
- special calls the compiler handles directly.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="bytecode-based-jit"&gt;
&lt;h2&gt;Bytecode-based JIT&lt;/h2&gt;
&lt;p&gt;Python is a fairly complicated language with &lt;em&gt;a lot&lt;/em&gt; of features. Therefore,
if our JIT has to support some large portion of Python semantics, it may make
sense to leverage more of Python's own compiler. Concretely, we can have it
compile the wrapped function all the way &lt;a class="reference external" href="https://github.com/python/cpython/blob/main/InternalDocs/interpreter.md"&gt;to bytecode&lt;/a&gt;,
and start our translation from there.&lt;/p&gt;
&lt;p&gt;Here's the &lt;tt class="docutils literal"&gt;bytecodejit&lt;/tt&gt; decorator that does just this &lt;a class="footnote-reference" href="#footnote-1" id="footnote-reference-1"&gt;[1]&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;bytecodejit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nd"&gt;@functools&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wraps&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;wrapper&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="n"&gt;BytecodeJITError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Keyword arguments are not supported&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="n"&gt;expr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;_emit_exprcode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;llvm_jit_evaluate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;wrapper&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_emit_exprcode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;bc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="vm"&gt;__code__&lt;/span&gt;
    &lt;span class="n"&gt;stack&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;inst&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;dis&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_instructions&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;match&lt;/span&gt; &lt;span class="n"&gt;inst&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;opname&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;LOAD_FAST&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;inst&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arg&lt;/span&gt;
                &lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;VarExpr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;co_varnames&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;LOAD_CONST&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ConstantExpr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inst&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argval&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;BINARY_OP&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;right&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
                &lt;span class="n"&gt;left&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
                &lt;span class="k"&gt;match&lt;/span&gt; &lt;span class="n"&gt;inst&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argrepr&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;+&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                        &lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BinOpExpr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;left&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;right&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Op&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ADD&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                    &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;-&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                        &lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BinOpExpr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;left&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;right&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Op&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SUB&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                    &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;*&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                        &lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BinOpExpr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;left&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;right&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Op&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MUL&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                    &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;/&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                        &lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BinOpExpr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;left&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;right&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Op&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DIV&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                    &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="k"&gt;_&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="n"&gt;BytecodeJITError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Unsupported operator &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;inst&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argval&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;RETURN_VALUE&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="n"&gt;BytecodeJITError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Invalid stack state&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;RESUME&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;CACHE&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="c1"&gt;# Skip nops&lt;/span&gt;
                &lt;span class="k"&gt;pass&lt;/span&gt;
            &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="k"&gt;_&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="n"&gt;BytecodeJITError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Unsupported opcode &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;inst&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;opname&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The Python VM is a stack machine; so we emulate a stack to convert the
function's bytecode to &lt;tt class="docutils literal"&gt;Expr&lt;/tt&gt; IR (a bit like an &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Reverse_Polish_notation"&gt;RPN evaluator&lt;/a&gt;).
As before, we then use our &lt;tt class="docutils literal"&gt;llvm_jit_evaluate&lt;/tt&gt; utility function to lower
&lt;tt class="docutils literal"&gt;Expr&lt;/tt&gt; to LLVM IR and JIT execute it.&lt;/p&gt;
&lt;p&gt;Using this JIT is as simple as the previous one - just swap &lt;tt class="docutils literal"&gt;astjit&lt;/tt&gt;
for &lt;tt class="docutils literal"&gt;bytecodejit&lt;/tt&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;bytecodejit&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;bytecodejit&lt;/span&gt;

&lt;span class="nd"&gt;@bytecodejit&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;some_expr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;some_expr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="section" id="bytecode-jit-case-study-numba"&gt;
&lt;h3&gt;Bytecode JIT case study: Numba&lt;/h3&gt;
&lt;p&gt;&lt;a class="reference external" href="https://numba.pydata.org/"&gt;Numba&lt;/a&gt; is a compiler for Python itself. The idea
is that you can speed up specific functions in your code by slapping a
&lt;tt class="docutils literal"&gt;numba.njit&lt;/tt&gt; decorator on them. What happens next is similar in spirit to
our simple &lt;tt class="docutils literal"&gt;bytecodejit&lt;/tt&gt;, but of course much more complicated because it
supports a very large portion of Python semantics.&lt;/p&gt;
&lt;p&gt;Numba uses the Python compiler to emit bytecode, just as we did; it then
converts it into its own IR, and then to LLVM using &lt;tt class="docutils literal"&gt;llvmlite&lt;/tt&gt; &lt;a class="footnote-reference" href="#footnote-2" id="footnote-reference-2"&gt;[2]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;By starting with the bytecode, Numba makes its life easier (no need to rewrite
the entire Python compiler). On the other hand, it also makes some analyses
&lt;em&gt;harder&lt;/em&gt;, because by the time we're in bytecode, a lot of semantic information
existing in higher-level representations is lost. For example, Numba has to
sweat a bit to recover control flow information from the bytecode (by
running it through a special interpreter first).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="tracing-based-jit"&gt;
&lt;h2&gt;Tracing-based JIT&lt;/h2&gt;
&lt;p&gt;The two approaches we've seen so far are similar in many ways - both rely on
Python's introspection capabilities to compile the source code of the JIT-ed
function to some extent (one to AST, the other all the way to bytecode), and
then work on this lowered representation.&lt;/p&gt;
&lt;p&gt;The tracing strategy is very different. It doesn't analyze the source code of
the wrapped function at all - instead, it &lt;em&gt;traces&lt;/em&gt; its execution by means of
specially-boxed arguments, leveraging overloaded operators and functions, and
then works on the generated trace.&lt;/p&gt;
&lt;p&gt;The code implementing this for our smile demo is surprisingly compact:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;tracejit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nd"&gt;@functools&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wraps&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;wrapper&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="n"&gt;TraceJITError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Keyword arguments are not supported&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="n"&gt;argspec&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;inspect&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getfullargspec&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="n"&gt;argboxes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;arg&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;argspec&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="n"&gt;TraceJITError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Too many arguments&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;argboxes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;_Box&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;VarExpr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;argspec&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

        &lt;span class="n"&gt;out_box&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;argboxes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;llvm_jit_evaluate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;out_box&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;wrapper&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Each runtime argument of the wrapped function is assigned a &lt;tt class="docutils literal"&gt;VarExpr&lt;/tt&gt;, and
that is placed in a &lt;tt class="docutils literal"&gt;_Box&lt;/tt&gt;, a placeholder class which lets us
do operator overloading:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nd"&gt;@dataclass&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;_Box&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Expr&lt;/span&gt;

&lt;span class="n"&gt;_Box&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__add__&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;_Box&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__radd__&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;_register_binary_op&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Op&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ADD&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;_Box&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__sub__&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;_register_binary_op&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Op&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SUB&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;_Box&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__rsub__&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;_register_binary_op&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Op&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SUB&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;_Box&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__mul__&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;_Box&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__rmul__&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;_register_binary_op&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Op&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MUL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;_Box&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__truediv__&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;_register_binary_op&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Op&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DIV&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;_Box&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__rtruediv__&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;_register_binary_op&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Op&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DIV&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The remaining key function is &lt;tt class="docutils literal"&gt;_register_binary_op&lt;/tt&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_register_binary_op&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;opcode&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Registers a binary opcode for Boxes.&lt;/span&gt;

&lt;span class="sd"&gt;    If reverse is True, the operation is registered as arg2 &amp;lt;op&amp;gt; arg1,&lt;/span&gt;
&lt;span class="sd"&gt;    instead of arg1 &amp;lt;op&amp;gt; arg2.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_op&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arg1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;arg2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;arg1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;arg2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;arg2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;arg1&lt;/span&gt;
        &lt;span class="n"&gt;box1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;arg1&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arg1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_Box&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="n"&gt;_Box&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ConstantExpr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arg1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;box2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;arg2&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arg2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_Box&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="n"&gt;_Box&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ConstantExpr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arg2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;_Box&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BinOpExpr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;box1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;box2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;opcode&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;_op&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To understand how this works, consider this trivial example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nd"&gt;@tracejit&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After the decorated function is defined, &lt;tt class="docutils literal"&gt;add&lt;/tt&gt; holds the wrapper function
defined inside &lt;tt class="docutils literal"&gt;tracejit&lt;/tt&gt;. When &lt;tt class="docutils literal"&gt;add(1, 2)&lt;/tt&gt; is called, the wrapper runs:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;For each argument of &lt;tt class="docutils literal"&gt;add&lt;/tt&gt; itself (that is &lt;tt class="docutils literal"&gt;a&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;b&lt;/tt&gt;), it creates
a new &lt;tt class="docutils literal"&gt;_Box&lt;/tt&gt; holding a &lt;tt class="docutils literal"&gt;VarExpr&lt;/tt&gt;. This denotes a named variable in
the &lt;tt class="docutils literal"&gt;Expr&lt;/tt&gt; IR.&lt;/li&gt;
&lt;li&gt;It then calls the wrapped function, passing it the boxes as runtime
parameters.&lt;/li&gt;
&lt;li&gt;When (the wrapped) &lt;tt class="docutils literal"&gt;add&lt;/tt&gt; runs, it invokes &lt;tt class="docutils literal"&gt;a + b&lt;/tt&gt;. This is caught by the overloaded
&lt;tt class="docutils literal"&gt;__add__&lt;/tt&gt; operator of &lt;tt class="docutils literal"&gt;_Box&lt;/tt&gt;, and it creates a new &lt;tt class="docutils literal"&gt;BinOpExpr&lt;/tt&gt; with
the &lt;tt class="docutils literal"&gt;VarExpr&lt;/tt&gt;s representing &lt;tt class="docutils literal"&gt;a&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;b&lt;/tt&gt; as children. This
&lt;tt class="docutils literal"&gt;BinOpExpr&lt;/tt&gt; is then returned &lt;a class="footnote-reference" href="#footnote-3" id="footnote-reference-3"&gt;[3]&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;The wrapper unboxes the returned &lt;tt class="docutils literal"&gt;Expr&lt;/tt&gt; and passes it to
&lt;tt class="docutils literal"&gt;llvm_jit_evaluate&lt;/tt&gt; to emit LLVM IR from it and JIT execute it with the
actual runtime arguments of the call: &lt;tt class="docutils literal"&gt;1, 2&lt;/tt&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This might be a little mind-bending at first, because there are two different
executions that happen:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The first is calling the wrapped &lt;tt class="docutils literal"&gt;add&lt;/tt&gt; function itself, letting the Python
interpreter run it as usual, but with special arguments that build up the IR
instead of doing any computations. This is the &lt;em&gt;tracing step&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;The second is lowering this IR our tracing step built into LLVM IR and then
JIT executing it with the actual runtime argument values &lt;tt class="docutils literal"&gt;1, 2&lt;/tt&gt;; this is
the &lt;em&gt;execution step&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tracing approach has some interesting characteristics. Since we don't
have to analyze the source of the wrapped functions but only trace through
the execution, we can &amp;quot;magically&amp;quot; support a much richer set of programs, e.g.:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nd"&gt;@tracejit&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;use_locals&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
    &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;
    &lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;z&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;use_locals&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This &lt;em&gt;just works&lt;/em&gt; with our basic &lt;tt class="docutils literal"&gt;tracejit&lt;/tt&gt;. Since Python variables are
placeholders (references) for values, our tracing step is oblivious to them - it
follows the flow of values. Another example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nd"&gt;@tracejit&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;use_loop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;use_loop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This also just works! The created &lt;tt class="docutils literal"&gt;Expr&lt;/tt&gt; will be a long chain of &lt;tt class="docutils literal"&gt;BinExpr&lt;/tt&gt;
additions of &lt;tt class="docutils literal"&gt;i&lt;/tt&gt;'s runtime values through the loop, added to the &lt;tt class="docutils literal"&gt;BinExpr&lt;/tt&gt;
for &lt;tt class="docutils literal"&gt;b * c&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;This last example also leads us to a limitation of the tracing approach; the
loop cannot be &lt;em&gt;data-dependent&lt;/em&gt; - it cannot depend on the function's arguments,
because the tracing step has no concept of runtime values and wouldn't know
how many iterations to run through; or at least, it doesn't know this unless
we want to perform the tracing run for every runtime execution &lt;a class="footnote-reference" href="#footnote-4" id="footnote-reference-4"&gt;[4]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The tracing approach is useful in several domains, most notably
&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Automatic_differentiation"&gt;automatic differentiation&lt;/a&gt; (AD).
For a slightly deeper taste, check out my &lt;a class="reference external" href="https://github.com/eliben/radgrad"&gt;radgrad&lt;/a&gt; project.&lt;/p&gt;
&lt;div class="section" id="tracing-jit-case-study-jax"&gt;
&lt;h3&gt;Tracing JIT case study: JAX&lt;/h3&gt;
&lt;p&gt;The &lt;a class="reference external" href="https://jax.readthedocs.io/en/latest/"&gt;JAX ML framework&lt;/a&gt; uses a tracing
approach very similar to the one described here. The first code sample in this
post shows the JAX notation. JAX cleverly wraps Numpy with its own version which
is traced (similar to our &lt;tt class="docutils literal"&gt;_Box&lt;/tt&gt;, but JAX calls these boxes &amp;quot;tracers&amp;quot;),
letting you write regular-feeling Numpy code that can be JIT optimized and
executed on accelerators like GPUs and TPUs via &lt;a class="reference external" href="https://github.com/openxla"&gt;XLA&lt;/a&gt;. JAX's tracer builds up an underlying IR (called
&lt;a class="reference external" href="https://jax.readthedocs.io/en/latest/jaxpr.html"&gt;jaxpr&lt;/a&gt;) which can then be
emitted to XLA ops and passed to XLA for further lowering and execution.&lt;/p&gt;
&lt;p&gt;For a fairly deep overview of how JAX works, I recommend reading the
&lt;a class="reference external" href="https://jax.readthedocs.io/en/latest/autodidax.html"&gt;autodidax doc&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As mentioned earlier, JAX has &lt;a class="reference external" href="https://jax.readthedocs.io/en/latest/jit-compilation.html"&gt;some limitations&lt;/a&gt;
with things like data-dependent control flow in native Python. This won't work,
because there's control flow
that depends on a runtime value (&lt;tt class="docutils literal"&gt;count&lt;/tt&gt;):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;jax&lt;/span&gt;

&lt;span class="nd"&gt;@jax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jit&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sum_datadep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;total&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;total&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;total&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sum_datadep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When &lt;tt class="docutils literal"&gt;sum_datadep&lt;/tt&gt; is executed, JAX will throw an exception, saying something
like:&lt;/p&gt;
&lt;blockquote&gt;
This concrete value was not available in Python because it depends on the
value of the argument count.&lt;/blockquote&gt;
&lt;p&gt;As a remedy, JAX has its
own built-in intrinsics from the &lt;a class="reference external" href="https://jax.readthedocs.io/en/latest/jax.lax.html"&gt;jax.lax package&lt;/a&gt;.
Here's the example rewritten in a way that actually works:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;jax&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;jax&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;lax&lt;/span&gt;

&lt;span class="nd"&gt;@jax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jit&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sum_datadep_fori&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;body&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;total&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;total&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;lax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fori_loop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;body&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;fori_loop&lt;/tt&gt; (and many other built-ins in the &lt;tt class="docutils literal"&gt;lax&lt;/tt&gt; package) is something JAX
can trace through, generating a corresponding XLA operation (XLA has support for
&lt;a class="reference external" href="https://openxla.org/xla/operation_semantics"&gt;While loops&lt;/a&gt;, to which this
&lt;tt class="docutils literal"&gt;lax.fori_loop&lt;/tt&gt; can be lowered).&lt;/p&gt;
&lt;p&gt;The tracing approach has clear benefits for JAX as well; because it only cares
about the flow of values, it can handle arbitrarily complicated Python code,
as long as the flow of values can be traced. Just like the local variables and
data-independent loops shown earlier, but also things like closures. This makes
meta-programming and templating easy &lt;a class="footnote-reference" href="#footnote-5" id="footnote-reference-5"&gt;[5]&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="code"&gt;
&lt;h2&gt;Code&lt;/h2&gt;
&lt;p&gt;The full code for this post is available &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/tree/main/2025/decjit"&gt;on GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-1" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Once again, this is a very simplified example. A more realistic
translator would have to support &lt;a class="reference external" href="https://docs.python.org/3/library/dis.html#python-bytecode-instructions"&gt;many, many more&lt;/a&gt;
Python bytecode instructions.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-2" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-2"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;In fact, &lt;tt class="docutils literal"&gt;llvmlite&lt;/tt&gt; itself is a Numba sub-project and is maintained
by the Numba team, for which I'm grateful!&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-3" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-3"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;For a fun exercise, try adding constant folding to the wrapped &lt;tt class="docutils literal"&gt;_op&lt;/tt&gt;:
when both its arguments are constants (not boxes), instead placing
each in a &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;_Box(ConstantExpr(...))&lt;/span&gt;&lt;/tt&gt;, it could perform the mathematical
operation on them and return a single constant box. This is a common
optimization in compilers!&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-4" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-4"&gt;[4]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;p class="first"&gt;In all the JIT approaches showed in this post, the expectation is that
compilation happens once, but the compiled function can be executed
many times (perhaps in a loop). This means that the compilation step
cannot depend on the runtime values of the function's arguments, because
it has no access to them. You could say that it &lt;em&gt;does&lt;/em&gt;, but that's just
for the very first time the function is run (in the tracing approach);
it has no way of knowing their values the next times the function will
run.&lt;/p&gt;
&lt;p class="last"&gt;JAX has &lt;a class="reference external" href="https://jax.readthedocs.io/en/latest/jit-compilation.html#marking-arguments-as-static"&gt;some provisions&lt;/a&gt;
for cases where a function is invoked with a small set of runtime
values and we want to separately JIT each of them.&lt;/p&gt;
&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-5" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-5"&gt;[5]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;A reader pointed out that &lt;a class="reference external" href="https://blog.tensorflow.org/2018/07/autograph-converts-python-into-tensorflow-graphs.html"&gt;TensorFlow's AutoGraph&lt;/a&gt;
feature combines the AST and tracing approaches. TF's &lt;em&gt;eager mode&lt;/em&gt;
performs tracing, but it also uses AST analyses to rewrite Python loops
and conditions into builtins like &lt;tt class="docutils literal"&gt;tf.cond&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;tf.while_loop&lt;/tt&gt;.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</content><category term="misc"></category><category term="Python"></category><category term="Compilation"></category><category term="Machine Learning"></category></entry><entry><title>Reverse mode Automatic Differentiation</title><link href="https://eli.thegreenplace.net/2025/reverse-mode-automatic-differentiation/" rel="alternate"></link><published>2025-01-13T19:02:00-08:00</published><updated>2025-01-17T21:51:01-08:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2025-01-13:/2025/reverse-mode-automatic-differentiation/</id><summary type="html">&lt;p&gt;Automatic Differentiation (AD) is an important algorithm for calculating the
derivatives of arbitrary functions that can be expressed by a computer program.
One of my favorite CS papers is
&lt;a class="reference external" href="https://arxiv.org/abs/1502.05767"&gt;&amp;quot;Automatic differentiation in machine learning: a survey&amp;quot;&lt;/a&gt; by
Baydin, Perlmutter, Radul and Siskind (ADIMLAS from here on).
While this post attempts â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Automatic Differentiation (AD) is an important algorithm for calculating the
derivatives of arbitrary functions that can be expressed by a computer program.
One of my favorite CS papers is
&lt;a class="reference external" href="https://arxiv.org/abs/1502.05767"&gt;&amp;quot;Automatic differentiation in machine learning: a survey&amp;quot;&lt;/a&gt; by
Baydin, Perlmutter, Radul and Siskind (ADIMLAS from here on).
While this post attempts to be useful on its own, it serves best as a followup
to the ADIMLAS paper - so I strongly encourage you to read that first.&lt;/p&gt;
&lt;p&gt;The main idea of AD is to treat a computation as a nested sequence of function
compositions, and then calculate the derivative of the outputs w.r.t. the inputs
using repeated applications of the chain rule. There are two methods of AD:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Forward mode: where derivatives are computed starting at the inputs&lt;/li&gt;
&lt;li&gt;Reverse mode: where derivatives are computed starting at the outputs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Reverse mode AD is a generalization of the &lt;em&gt;backpropagation&lt;/em&gt; technique used
in training neural networks. While backpropagation starts from a single scalar
output, reverse mode AD works for any number of function outputs. In this post
I'm going to be describing how reverse mode AD works in detail.&lt;/p&gt;
&lt;p&gt;While reading the ADIMLAS paper is strongly recommended but not required,
there &lt;em&gt;is&lt;/em&gt; one mandatory pre-requisite for this post: a good understanding of
the chain rule of calculus, including its multivariate formulation. Please
read &lt;a class="reference external" href="https://eli.thegreenplace.net/2016/the-chain-rule-of-calculus"&gt;my earlier post on the subject&lt;/a&gt;
first if you're not familiar with it.&lt;/p&gt;
&lt;div class="section" id="linear-chain-graphs"&gt;
&lt;h2&gt;Linear chain graphs&lt;/h2&gt;
&lt;p&gt;Let's start with a simple example where the computation is a linear chain of
primitive operations: the Sigmoid function.&lt;/p&gt;
&lt;img alt="\[S(x)=\frac{1}{1+e^{-x}}\]" class="align-center" src="https://eli.thegreenplace.net/images/math/9a39d0495ce32da5840b76adaf508a0349394c49.png" style="height: 38px;" /&gt;
&lt;p&gt;This is a basic Python implementation:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sigmoid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To apply the chain rule, we'll break down the calculation of &lt;object class="valign-m5" data="https://eli.thegreenplace.net/images/math/fa94a6b584da9e970e40fbcbe4d615031ac59bc2.svg" style="height: 19px;" type="image/svg+xml"&gt;S(x)&lt;/object&gt; to
a sequence of function compositions, as follows:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/33494603270cd9090af303e2e99cf367173f588b.svg" style="height: 119px;" type="image/svg+xml"&gt;\[\begin{align*}
  f(x)&amp;amp;=-x\\
  g(f)&amp;amp;=e^f\\
  w(g)&amp;amp;=1+g\\
  v(w)&amp;amp;=\frac{1}{w}
\end{align*}\]&lt;/object&gt;
&lt;p&gt;Take a moment to convince yourself that &lt;object class="valign-m5" data="https://eli.thegreenplace.net/images/math/fa94a6b584da9e970e40fbcbe4d615031ac59bc2.svg" style="height: 19px;" type="image/svg+xml"&gt;S(x)&lt;/object&gt; is equivalent to
the composition &lt;object class="valign-m5" data="https://eli.thegreenplace.net/images/math/2496463ea05f38acb598c84a70bfcc4692591511.svg" style="height: 19px;" type="image/svg+xml"&gt;v\circ(w\circ(g\circ f))(x)&lt;/object&gt;.&lt;/p&gt;
&lt;p&gt;The same decomposition of &lt;tt class="docutils literal"&gt;sigmoid&lt;/tt&gt; into primitives in Python would look as
follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sigmoid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;
    &lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;
    &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Yet another representation is this computational graph:&lt;/p&gt;
&lt;img alt="Computational graph showing sigmoid" class="align-center" src="https://eli.thegreenplace.net/images/2025/sigmoid-graph.png" /&gt;
&lt;p&gt;Each box (graph node) represents a primitive operation, and the name assigned
to it (the green rectangle on the right of each box). An arrows (graph edge)
represent the flow of values between operations.&lt;/p&gt;
&lt;p&gt;Our goal is to find the derivative of &lt;em&gt;S&lt;/em&gt; w.r.t. &lt;em&gt;x&lt;/em&gt; at some point &lt;img alt="x_0" class="valign-m3" src="https://eli.thegreenplace.net/images/math/efbda784ad565c1c5201fdc948a570d0426bc6e6.png" style="height: 11px;" /&gt;,
denoted as &lt;object class="valign-m5" data="https://eli.thegreenplace.net/images/math/e4ba6fb484fe0c504010c93b6144b99a885a0b97.svg" style="height: 19px;" type="image/svg+xml"&gt;S&amp;#x27;(x_0)&lt;/object&gt;. The process starts by running the computational
graph forward with our value of &lt;img alt="x_0" class="valign-m3" src="https://eli.thegreenplace.net/images/math/efbda784ad565c1c5201fdc948a570d0426bc6e6.png" style="height: 11px;" /&gt;. As an example, we'll use
&lt;object class="valign-m3" data="https://eli.thegreenplace.net/images/math/064a529ef0eed72cc7839b45e015ec432a83c9b2.svg" style="height: 16px;" type="image/svg+xml"&gt;x_0=0.5&lt;/object&gt;:&lt;/p&gt;
&lt;img alt="Computational graph with forward calculation at 0.5" class="align-center" src="https://eli.thegreenplace.net/images/2025/sigmoid-graph-forward-calc.png" /&gt;
&lt;p&gt;Since all the functions in this graph have a single input and a single output,
it's sufficient to use the single-variable formulation of the chain rule.&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/28362ed858958e6d1e4754338cb3e6bc6aca6026.svg" style="height: 21px;" type="image/svg+xml"&gt;\[(g \circ f)&amp;#x27;(x_0)={g}&amp;#x27;(f(x_0)){f}&amp;#x27;(x_0)\]&lt;/object&gt;
&lt;p&gt;To avoid confusion, let's switch notation so we can explicitly see which
derivatives are involved. For &lt;img alt="f(x)" class="valign-m4" src="https://eli.thegreenplace.net/images/math/3e03f4706048fbc6c5a252a85d066adf107fcc1f.png" style="height: 18px;" /&gt; and &lt;object class="valign-m5" data="https://eli.thegreenplace.net/images/math/5ad8d30dbab83209f45a10850ffbcacf6662321e.svg" style="height: 19px;" type="image/svg+xml"&gt;g(f)&lt;/object&gt; as before, we can
write the derivatives like this:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/2a365d03b211d0f53930958bcf200b18409b32b6.svg" style="height: 40px;" type="image/svg+xml"&gt;\[f&amp;#x27;(x)=\frac{df}{dx}\quad g&amp;#x27;(f)=\frac{dg}{df}\]&lt;/object&gt;
&lt;p&gt;Each of these is a function we can evaluate at some point; for example, we
denote the evaluation of &lt;object class="valign-m5" data="https://eli.thegreenplace.net/images/math/9567f23affb8a7bd391269e4572b0200f9747cb8.svg" style="height: 19px;" type="image/svg+xml"&gt;f&amp;#x27;(x)&lt;/object&gt; at &lt;img alt="x_0" class="valign-m3" src="https://eli.thegreenplace.net/images/math/efbda784ad565c1c5201fdc948a570d0426bc6e6.png" style="height: 11px;" /&gt; as &lt;object class="valign-m6" data="https://eli.thegreenplace.net/images/math/5bf185ec15f166ab5130fbff525b5dc8a2d91546.svg" style="height: 23px;" type="image/svg+xml"&gt;\frac{df}{dx}(x_0)&lt;/object&gt;.
So we can rewrite the chain rule like this:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/9ec7442f9adf5913013decd3f4959574375fec58.svg" style="height: 42px;" type="image/svg+xml"&gt;\[\frac{d(g \circ f)}{dx}(x_0)=\frac{dg}{df}(f(x_0))\frac{df}{dx}(x_0)\]&lt;/object&gt;
&lt;p&gt;Reverse mode AD means applying the chain rule to our computation graph, starting
with the last operation and ending at the first.
Remember that our final goal is to calculate:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/e2774a76c051cd50d2dbf1ae13593fa7f1e773db.svg" style="height: 36px;" type="image/svg+xml"&gt;\[\frac{dS}{dx}(x_0)\]&lt;/object&gt;
&lt;p&gt;Where &lt;em&gt;S&lt;/em&gt; is a composition of multiple functions. The first composition we
unravel is the last node in the graph, where &lt;em&gt;v&lt;/em&gt; is calculated from &lt;em&gt;w&lt;/em&gt;. This is
the chain rule for it:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/234154080611fa2d641c60b299b89513aed5dad6.svg" style="height: 38px;" type="image/svg+xml"&gt;\[\frac{dS}{dw}=\frac{d(S \circ v)}{dw}(x_0)=\frac{dS}{dv}(v(x_0))\frac{dv}{dw}(x_0)\]&lt;/object&gt;
&lt;p&gt;The formula for &lt;em&gt;S&lt;/em&gt; is &lt;object class="valign-m5" data="https://eli.thegreenplace.net/images/math/f5dec59579550096a611d2ed38b64a0935219947.svg" style="height: 19px;" type="image/svg+xml"&gt;S(v)=v&lt;/object&gt;, so its derivative is 1. The formula for
&lt;em&gt;v&lt;/em&gt; is &lt;object class="valign-m6" data="https://eli.thegreenplace.net/images/math/15935505468369a4c3d1371b6092dd47fb843936.svg" style="height: 22px;" type="image/svg+xml"&gt;v(w)=\frac{1}{w}&lt;/object&gt;, so its derivative is &lt;object class="valign-m7" data="https://eli.thegreenplace.net/images/math/26a341f4d7d5266620d3ad953a2b3b6cf45d1b42.svg" style="height: 23px;" type="image/svg+xml"&gt;-\frac{1}{w^2}&lt;/object&gt;.
Substituting the value of &lt;em&gt;w&lt;/em&gt; computed in the forward pass, we get:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/f4fac2ae8c9004597295e076cb4bbabac5a364f1.svg" style="height: 45px;" type="image/svg+xml"&gt;\[\frac{dS}{dw}(x_0)=1\cdot\frac{-1}{w^2}\bigg\rvert_{w=1.61}=-0.39\]&lt;/object&gt;
&lt;p&gt;Continuing backwards from &lt;em&gt;v&lt;/em&gt; to &lt;em&gt;w&lt;/em&gt;:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/b16fa07dd10b039349e4addc1948ffe7c1207bed.svg" style="height: 40px;" type="image/svg+xml"&gt;\[\frac{dS}{dg}(x_0)=\frac{dS}{dw}(x_0)\frac{dw}{dg}(x_0)\]&lt;/object&gt;
&lt;p&gt;We've already calculated &lt;object class="valign-m6" data="https://eli.thegreenplace.net/images/math/7f843eaca6c53d1341ffd2285f643d0f233d18cb.svg" style="height: 22px;" type="image/svg+xml"&gt;\frac{dS}{dw}(x_0)&lt;/object&gt; in the previous step. Since
&lt;object class="valign-m4" data="https://eli.thegreenplace.net/images/math/f16c67e0ba9a5df1ffa4ebe6e9d13dcf9a9df0e1.svg" style="height: 16px;" type="image/svg+xml"&gt;w=1+g&lt;/object&gt;, we know that &lt;object class="valign-m5" data="https://eli.thegreenplace.net/images/math/93fc061d1af1e6125431be32a6d07be34ae82976.svg" style="height: 19px;" type="image/svg+xml"&gt;w&amp;#x27;(g)=1&lt;/object&gt;, so:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/bead5038f022559d95b89314911e713bc88d0a05.svg" style="height: 40px;" type="image/svg+xml"&gt;\[\frac{dS}{dg}(x_0)=-0.39\cdot1=-0.39\]&lt;/object&gt;
&lt;p&gt;Continuing similarly down the chain, until we get to the input &lt;em&gt;x&lt;/em&gt;:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/e9b20f826ab6a143e8dc08f0e1d4bffdef1739f1.svg" style="height: 94px;" type="image/svg+xml"&gt;\[\begin{align*}
  \frac{dS}{df}(x_0)&amp;amp;=\frac{dS}{dg}(x_0)\frac{dg}{df}(x_0)=-0.39\cdot e^f\bigg\rvert_{f=-0.5}=-0.24\\
  \frac{dS}{dx}(x_0)&amp;amp;=\frac{dS}{df}(x_0)\frac{df}{dx}(x_0)=-0.24\cdot -1=0.24
\end{align*}\]&lt;/object&gt;
&lt;p&gt;We're done; the value of the derivative of the sigmoid function at &lt;object class="valign-0" data="https://eli.thegreenplace.net/images/math/b252e76d8a58888c218a5a4c2d463bdd8f0c0b20.svg" style="height: 13px;" type="image/svg+xml"&gt;x=0.5&lt;/object&gt;
is 0.24; this can be easily verified with a calculator using the analytical
derivative of this function.&lt;/p&gt;
&lt;p&gt;As you can see, this procedure is rather mechanical and it's not surprising that
it can be automated. Before we get to automation, however, let's review the
more common scenario where the computational graph is a DAG rather than a linear
chain.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="general-dags"&gt;
&lt;h2&gt;General DAGs&lt;/h2&gt;
&lt;p&gt;The sigmoid sample we worked though above has a very simple, linear
computational graph. Each node has a single predecessor and a single successor;
moreover, the function itself has a single input and single output. Therefore,
the single-variable chain rule is sufficient here.&lt;/p&gt;
&lt;p&gt;In the more general case, we'll encounter functions that have multiple inputs,
may also have multiple outputs &lt;a class="footnote-reference" href="#footnote-1" id="footnote-reference-1"&gt;[1]&lt;/a&gt;, and the internal nodes are connected in
non-linear patterns. To compute their derivatives, we have to use the
multivariate chain rule.&lt;/p&gt;
&lt;p&gt;As a reminder, in the most general case we're dealing with a function that has
&lt;em&gt;n&lt;/em&gt; inputs, denoted &lt;object class="valign-m4" data="https://eli.thegreenplace.net/images/math/ea64bb914bc3a768b4557a09b6e79badac50efb6.svg" style="height: 12px;" type="image/svg+xml"&gt;a=a_1,a_2\cdots a_n&lt;/object&gt;, and &lt;em&gt;m&lt;/em&gt;
outputs, denoted &lt;object class="valign-m4" data="https://eli.thegreenplace.net/images/math/97ca4dff67272bbafc9631d485c7687d07dffe90.svg" style="height: 16px;" type="image/svg+xml"&gt;f_1,f_2\cdots f_m&lt;/object&gt;. In other words, the function is
mapping &lt;img alt="f:\mathbb{R}^{n} \to \mathbb{R}^{m}" class="valign-m4" src="https://eli.thegreenplace.net/images/math/13f219789047343729036279bb11630db317d98d.png" style="height: 16px;" /&gt;.&lt;/p&gt;
&lt;p&gt;The partial derivative of output &lt;em&gt;i&lt;/em&gt; w.r.t. input &lt;em&gt;j&lt;/em&gt; at some point &lt;em&gt;a&lt;/em&gt; is:&lt;/p&gt;
&lt;img alt="\[D_j f_i(a)=\frac{\partial f_i}{\partial a_j}(a)\]" class="align-center" src="https://eli.thegreenplace.net/images/math/30881b5a92e45259714ba01c7a12fbf8f6c56109.png" style="height: 42px;" /&gt;
&lt;p&gt;Assuming &lt;em&gt;f&lt;/em&gt; is differentiable at &lt;em&gt;a&lt;/em&gt;, then the complete derivative of &lt;em&gt;f&lt;/em&gt;
w.r.t. its inputs can be represented by the &lt;em&gt;Jacobian matrix&lt;/em&gt;:&lt;/p&gt;
&lt;img alt="\[Df(a)=\begin{bmatrix} D_1 f_1(a) &amp;amp;amp; \cdots &amp;amp;amp; D_n f_1(a) \\ \vdots &amp;amp;amp;  &amp;amp;amp; \vdots \\ D_1 f_m(a) &amp;amp;amp; \cdots &amp;amp;amp; D_n f_m(a) \\ \end{bmatrix}\]" class="align-center" src="https://eli.thegreenplace.net/images/math/ab09367d48e9ef4d8bc2314a60313dec700193af.png" style="height: 76px;" /&gt;
&lt;p&gt;The multivariate chain rule then states that if we compose &lt;object class="valign-m4" data="https://eli.thegreenplace.net/images/math/fc2de39fe9cb2349e17b06356b230494023e2663.svg" style="height: 16px;" type="image/svg+xml"&gt;f\circ g&lt;/object&gt;
(and assuming all the dimensions are correct), the derivative is:&lt;/p&gt;
&lt;img alt="\[D(f \circ g)(a)=Df(g(a)) \cdot Dg(a)\]" class="align-center" src="https://eli.thegreenplace.net/images/math/00bdefa904bd34df2dfb50cc385e6497c4e5096e.png" style="height: 18px;" /&gt;
&lt;p&gt;This is the matrix multiplication of &lt;img alt="Df(g(a))" class="valign-m4" src="https://eli.thegreenplace.net/images/math/e567730c48bb2f95c258b630b4d6e997043e09ab.png" style="height: 18px;" /&gt; and &lt;img alt="Dg(a)" class="valign-m4" src="https://eli.thegreenplace.net/images/math/2575fc98e794a733a7aa6237fe67246a41e6c8c5.png" style="height: 18px;" /&gt;.&lt;/p&gt;
&lt;div class="section" id="linear-nodes"&gt;
&lt;h3&gt;Linear nodes&lt;/h3&gt;
&lt;p&gt;As a warmup, let's start with a linear node that has a single input and a single
output:&lt;/p&gt;
&lt;img alt="A single node f(x) with one input and one output" class="align-center" src="https://eli.thegreenplace.net/images/2025/linear-node.png" /&gt;
&lt;p&gt;In all these examples, we assume the full graph output is &lt;em&gt;S&lt;/em&gt;, and its
derivative by the node's outputs is
&lt;object class="valign-m9" data="https://eli.thegreenplace.net/images/math/f57c6269b575f0c225f18e0bef2f974a5a048802.svg" style="height: 26px;" type="image/svg+xml"&gt;\frac{\partial S}{\partial f}&lt;/object&gt;.
We're then interested in finding &lt;object class="valign-m6" data="https://eli.thegreenplace.net/images/math/0367612a0ebda078dea5f14a1fe973802a982d52.svg" style="height: 23px;" type="image/svg+xml"&gt;\frac{\partial S}{\partial x}&lt;/object&gt;.
Since since &lt;object class="valign-m4" data="https://eli.thegreenplace.net/images/math/77d5e13c951f5a369089f05a0505728896773ed3.svg" style="height: 16px;" type="image/svg+xml"&gt;f:\mathbb{R}\to\mathbb{R}&lt;/object&gt;, the Jacobian is just a scalar:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/507412aef50458ce55fd10110906db71979a548b.svg" style="height: 37px;" type="image/svg+xml"&gt;\[Df=\frac{\partial f}{\partial x}\]&lt;/object&gt;
&lt;p&gt;And the chain rule is:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/9d9fc987a32c5c653bccfce4a89ee860b14286ff.svg" style="height: 41px;" type="image/svg+xml"&gt;\[D(S\circ f)=DS(f)\cdot Df=\frac{\partial S}{\partial f}\frac{\partial f}{\partial x}\]&lt;/object&gt;
&lt;p&gt;No surprises so far - this is just the single variable chain rule!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="fan-in"&gt;
&lt;h3&gt;Fan-in&lt;/h3&gt;
&lt;p&gt;Let's move on to the next scenario, where &lt;em&gt;f&lt;/em&gt; has two inputs:&lt;/p&gt;
&lt;img alt="A single node f(x1,x2) with two inputs and one output" class="align-center" src="https://eli.thegreenplace.net/images/2025/fan-in-node.png" /&gt;
&lt;p&gt;Once again, we already have the derivative &lt;object class="valign-m9" data="https://eli.thegreenplace.net/images/math/f57c6269b575f0c225f18e0bef2f974a5a048802.svg" style="height: 26px;" type="image/svg+xml"&gt;\frac{\partial S}{\partial f}&lt;/object&gt;
available, and we're interested in finding the derivative of &lt;em&gt;S&lt;/em&gt; w.r.t. the
inputs.&lt;/p&gt;
&lt;p&gt;In this case, &lt;object class="valign-m4" data="https://eli.thegreenplace.net/images/math/20b92036dc896227ef062a8bbe58ba8c022805ab.svg" style="height: 19px;" type="image/svg+xml"&gt;f:\mathbb{R}^2\to\mathbb{R}&lt;/object&gt;, so the Jacobian is a 1x2
matrix:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/0d81f11639f8d8506ca7bdc461d5e5d3a9cc2e5b.svg" style="height: 42px;" type="image/svg+xml"&gt;\[Df=\left [
  \frac{\partial f}{\partial x_1} \quad \frac{\partial f}{\partial x_2}
\right ]\]&lt;/object&gt;
&lt;p&gt;And the chain rule here means multiplying a 1x1 matrix by a 1x2 matrix:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/057bba77db0d7abde54de3542704c4f5e0c32ff9.svg" style="height: 42px;" type="image/svg+xml"&gt;\[D(S\circ f)=DS(f)\cdot Df=
  \left [ \frac{\partial S}{\partial f} \right ]
  \left [ \frac{\partial f}{\partial x_1} \quad \frac{\partial f}{\partial x_2} \right ]
= \left [ \frac{\partial S}{\partial f} \frac{\partial f}{\partial x_1} \quad \frac{\partial S}{\partial f} \frac{\partial f}{\partial x_2} \right ]\]&lt;/object&gt;
&lt;p&gt;Therefore, we see that the output derivative propagates to each input
separately:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/781df9a4c6233932820bc19c4a6b155b86522aa5.svg" style="height: 87px;" type="image/svg+xml"&gt;\[\begin{align*}
  \frac{\partial S}{\partial x_1}&amp;amp;=\frac{\partial S}{\partial f} \frac{\partial f}{\partial x_1}\\
  \frac{\partial S}{\partial x_2}&amp;amp;=\frac{\partial S}{\partial f} \frac{\partial f}{\partial x_2}
\end{align*}\]&lt;/object&gt;
&lt;/div&gt;
&lt;div class="section" id="fan-out"&gt;
&lt;h3&gt;Fan-out&lt;/h3&gt;
&lt;p&gt;In the most general case, &lt;em&gt;f&lt;/em&gt; may have multiple inputs but its output may also
be used by more than one other node. As a concrete example, here's a node with
three inputs and an output that's used in two places:&lt;/p&gt;
&lt;img alt="A single node f(x1,x2,x3) with three inputs and two outputs" class="align-center" src="https://eli.thegreenplace.net/images/2025/fan-out-node.png" /&gt;
&lt;p&gt;While we denote each output edge from &lt;em&gt;f&lt;/em&gt; with a different name, &lt;em&gt;f&lt;/em&gt;
has a single output! This point is a bit subtle and important to dwell on:
yes, &lt;em&gt;f&lt;/em&gt; has a single output, so in the forward calculation both &lt;object class="valign-m4" data="https://eli.thegreenplace.net/images/math/0b35cc5e94a0d7682217d901f757b70990808891.svg" style="height: 16px;" type="image/svg+xml"&gt;f_1&lt;/object&gt;
and &lt;object class="valign-m4" data="https://eli.thegreenplace.net/images/math/9f68396d20ac17fe4705c1bf347774699bc27a3e.svg" style="height: 16px;" type="image/svg+xml"&gt;f_2&lt;/object&gt; will have the same value. However, we have to treat them
differently for the derivative calculation, because it's very possible that
&lt;object class="valign-m9" data="https://eli.thegreenplace.net/images/math/18c0d7d012453644b8448317709f2e54ebf0599c.svg" style="height: 26px;" type="image/svg+xml"&gt;\frac{\partial S}{\partial f_1}&lt;/object&gt; and &lt;object class="valign-m9" data="https://eli.thegreenplace.net/images/math/ceaa592c34f5079817c6abcfa6fabf5b2a3ed061.svg" style="height: 26px;" type="image/svg+xml"&gt;\frac{\partial S}{\partial f_2}&lt;/object&gt;
are different!&lt;/p&gt;
&lt;p&gt;In other words, we're reusing the machinery of multi-output functions here.
If &lt;em&gt;f&lt;/em&gt; had multiple outputs (e.g. a vector function), everything would work
exactly the same.&lt;/p&gt;
&lt;p&gt;In this case, since we treat &lt;em&gt;f&lt;/em&gt; as &lt;object class="valign-m4" data="https://eli.thegreenplace.net/images/math/c0ac304ca884452f91df6662e7f6919db48d69f9.svg" style="height: 19px;" type="image/svg+xml"&gt;f:\mathbb{R}^3\to\mathbb{R}^2&lt;/object&gt;,
its Jacobian is a 2x3 matrix:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/1a29aa7661d6293f39df5cf65181e04848ed6b82.svg" style="height: 75px;" type="image/svg+xml"&gt;\[Df=
\begin{bmatrix}
  \frac{\partial f_1}{\partial x_1} &amp;amp; \frac{\partial f_1}{\partial x_2} &amp;amp; \frac{\partial f_1}{\partial x_3} \\ \\
  \frac{\partial f_2}{\partial x_1} &amp;amp; \frac{\partial f_2}{\partial x_2} &amp;amp; \frac{\partial f_2}{\partial x_3} \\
\end{bmatrix}\]&lt;/object&gt;
&lt;p&gt;The Jacobian &lt;object class="valign-m5" data="https://eli.thegreenplace.net/images/math/a6de1a158410623c078f4274fe7c35e95fa36d98.svg" style="height: 19px;" type="image/svg+xml"&gt;DS(f)&lt;/object&gt; is a 1x2 matrix:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/7aae6e867bb005f41aed0591aee6d837dff93795.svg" style="height: 42px;" type="image/svg+xml"&gt;\[DS(f)=\left [ \frac{\partial S}{\partial f_1} \quad \frac{\partial S}{\partial f_2} \right ]\]&lt;/object&gt;
&lt;p&gt;Applying the chain rule:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/885af1372b513038aa1d6f52fc9e2d69e4e8f9a1.svg" style="height: 123px;" type="image/svg+xml"&gt;\[\begin{align*}
D(S\circ f)=DS(f)\cdot Df&amp;amp;=
\left [ \frac{\partial S}{\partial f_1} \quad \frac{\partial S}{\partial f_2} \right ]
  \begin{bmatrix}
  \frac{\partial f_1}{\partial x_1} &amp;amp; \frac{\partial f_1}{\partial x_2} &amp;amp; \frac{\partial f_1}{\partial x_3} \\ \\
  \frac{\partial f_2}{\partial x_1} &amp;amp; \frac{\partial f_2}{\partial x_2} &amp;amp; \frac{\partial f_2}{\partial x_3} \\
\end{bmatrix}\\
&amp;amp;=
\left [
\frac{\partial S}{\partial f_1}\frac{\partial f_1}{\partial x_1}+\frac{\partial S}{\partial f_2}\frac{\partial f_2}{\partial x_1}\qquad
\frac{\partial S}{\partial f_1}\frac{\partial f_1}{\partial x_2}+\frac{\partial S}{\partial f_2}\frac{\partial f_2}{\partial x_2}\qquad
\frac{\partial S}{\partial f_1}\frac{\partial f_1}{\partial x_3}+\frac{\partial S}{\partial f_2}\frac{\partial f_2}{\partial x_3}
\right ]
\end{align*}\]&lt;/object&gt;
&lt;p&gt;Therefore, we have:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/5148bfc79c2c82a178c9a0818931405d8067befd.svg" style="height: 134px;" type="image/svg+xml"&gt;\[\begin{align*}
  \frac{\partial S}{\partial x_1}&amp;amp;=\frac{\partial S}{\partial f_1}\frac{\partial f_1}{\partial x_1}+\frac{\partial S}{\partial f_2}\frac{\partial f_2}{\partial x_1}\\
  \frac{\partial S}{\partial x_2}&amp;amp;=\frac{\partial S}{\partial f_1}\frac{\partial f_1}{\partial x_2}+\frac{\partial S}{\partial f_2}\frac{\partial f_2}{\partial x_2}\\
  \frac{\partial S}{\partial x_3}&amp;amp;=\frac{\partial S}{\partial f_1}\frac{\partial f_1}{\partial x_3}+\frac{\partial S}{\partial f_2}\frac{\partial f_2}{\partial x_3}
\end{align*}\]&lt;/object&gt;
&lt;p&gt;The key point here - which we haven't encountered before - is that the derivatives
through &lt;em&gt;f&lt;/em&gt; add up for each of its outputs (or for each copy of its output).
Qualitatively, it means that the sensitivity of &lt;em&gt;f&lt;/em&gt;'s input to the output is
the sum of its sensitivities across each output separately. This makes logical
sense, and mathematically it's just the consequence of the dot product inherent
in matrix multiplication.&lt;/p&gt;
&lt;p&gt;Now that we understand how reverse mode AD works for the more general case
of DAG nodes, let's work through a complete example.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="general-dags-full-example"&gt;
&lt;h2&gt;General DAGs - full example&lt;/h2&gt;
&lt;p&gt;Consider this function (a sample used in the ADIMLAS paper):&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/1568c8ae7ffdb24afc990d937585b7a779e185b2.svg" style="height: 19px;" type="image/svg+xml"&gt;\[f(x_1, x_2)=ln(x_1)+x_1 x_2-sin(x_2)\]&lt;/object&gt;
&lt;p&gt;It has two inputs and a single output; once we decompose it to primitive
operations, we can represent it with the following computational graph &lt;a class="footnote-reference" href="#footnote-2" id="footnote-reference-2"&gt;[2]&lt;/a&gt;:&lt;/p&gt;
&lt;img alt="Computational graph of f as function of x_1 and x_2" class="align-center" src="https://eli.thegreenplace.net/images/2025/fpaper-graph.png" /&gt;
&lt;p&gt;As before, we begin by running the computation forward for the values of
&lt;object class="valign-m4" data="https://eli.thegreenplace.net/images/math/c5ea3aabcca7242c957a64cb671c96944ec70bcc.svg" style="height: 12px;" type="image/svg+xml"&gt;x_1,x_2&lt;/object&gt; at which we're interested to find the derivative. Let's take
&lt;object class="valign-m3" data="https://eli.thegreenplace.net/images/math/a1e99f7b67c1a129f77df5026f3701a5cfbdcc3f.svg" style="height: 15px;" type="image/svg+xml"&gt;x_1=2&lt;/object&gt; and &lt;object class="valign-m3" data="https://eli.thegreenplace.net/images/math/c2025f310759a37b724da44e26ea744680a2743e.svg" style="height: 16px;" type="image/svg+xml"&gt;x_2=5&lt;/object&gt;:&lt;/p&gt;
&lt;img alt="Computational graph with forward calculation at 2, 5" class="align-center" src="https://eli.thegreenplace.net/images/2025/fpaper-graph-forward-calc.png" /&gt;
&lt;p&gt;Recall that our goal is to calculate &lt;object class="valign-m8" data="https://eli.thegreenplace.net/images/math/92a7ef7129edaf480d777987e2b69306fff75f87.svg" style="height: 26px;" type="image/svg+xml"&gt;\frac{\partial f}{\partial x_1}&lt;/object&gt;
and &lt;object class="valign-m8" data="https://eli.thegreenplace.net/images/math/0af90c749150f76175dd2af7dc930774ab7579c0.svg" style="height: 26px;" type="image/svg+xml"&gt;\frac{\partial f}{\partial x_2}&lt;/object&gt;. Initially we know that
&lt;object class="valign-m8" data="https://eli.thegreenplace.net/images/math/dc5d153e1b607ee33620d8c97cc46edf61fa7696.svg" style="height: 26px;" type="image/svg+xml"&gt;\frac{\partial f}{\partial v_5}=1&lt;/object&gt; &lt;a class="footnote-reference" href="#footnote-3" id="footnote-reference-3"&gt;[3]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Starting with the &lt;object class="valign-m3" data="https://eli.thegreenplace.net/images/math/ca513d085e9f35047a4c85c1759e63b9f3d23e5b.svg" style="height: 11px;" type="image/svg+xml"&gt;v_5&lt;/object&gt; node, let's use the fan-in formulas developed
earlier:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/b45f5a7e39c1f64899b95d2ea3ef7562401b3eeb.svg" style="height: 85px;" type="image/svg+xml"&gt;\[\begin{align*}
  \frac{\partial f}{\partial v_4}&amp;amp;=\frac{\partial f}{\partial v_5} \frac{\partial v_5}{\partial v_4}=1\cdot 1=1\\
  \frac{\partial f}{\partial v_3}&amp;amp;=\frac{\partial f}{\partial v_5} \frac{\partial v_5}{\partial v_3}=1\cdot -1=-1
\end{align*}\]&lt;/object&gt;
&lt;p&gt;Next, let's tackle &lt;object class="valign-m3" data="https://eli.thegreenplace.net/images/math/9a69ccb973264d203d460f9a7e0df867faf7e918.svg" style="height: 11px;" type="image/svg+xml"&gt;v_4&lt;/object&gt;. It also has a fan-in configuration, so we'll
use similar formulas, plugging in the value of &lt;object class="valign-m8" data="https://eli.thegreenplace.net/images/math/39e8a55c9a3ae7936e835846a6ed4c631922e039.svg" style="height: 26px;" type="image/svg+xml"&gt;\frac{\partial f}{\partial v_4}&lt;/object&gt; we've just
calculated:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/e735c4d3d5ef555607e8acde0f84310291277101.svg" style="height: 85px;" type="image/svg+xml"&gt;\[\begin{align*}
  \frac{\partial f}{\partial v_1}&amp;amp;=\frac{\partial f}{\partial v_4} \frac{\partial v_4}{\partial v_1}=1\cdot 1=1\\
  \frac{\partial f}{\partial v_2}&amp;amp;=\frac{\partial f}{\partial v_4} \frac{\partial v_4}{\partial v_2}=1\cdot 1=1
\end{align*}\]&lt;/object&gt;
&lt;p&gt;On to &lt;object class="valign-m4" data="https://eli.thegreenplace.net/images/math/9b12bbf79036cb3e904f971fd86838db1dade1aa.svg" style="height: 12px;" type="image/svg+xml"&gt;v_1&lt;/object&gt;. It's a simple linear node, so:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/55bb2c892485048d8ccb9796017d2002cd205231.svg" style="height: 44px;" type="image/svg+xml"&gt;\[\frac{\partial f}{\partial x_1}^{(1)}=\frac{\partial f}{\partial v_1} \frac{\partial v_1}{\partial x_1}=1\cdot \frac{1}{x_1}=0.5\]&lt;/object&gt;
&lt;p&gt;Note the (1) superscript though! Since &lt;object class="valign-m3" data="https://eli.thegreenplace.net/images/math/593f4cff5d4210d46e140db57bafc4f692493f76.svg" style="height: 11px;" type="image/svg+xml"&gt;x_1&lt;/object&gt; is a fan-out node, it will have
more than one contribution to its derivative; we've just computed the one from
&lt;object class="valign-m4" data="https://eli.thegreenplace.net/images/math/9b12bbf79036cb3e904f971fd86838db1dade1aa.svg" style="height: 12px;" type="image/svg+xml"&gt;v_1&lt;/object&gt;. Next, let's compute the one from &lt;object class="valign-m3" data="https://eli.thegreenplace.net/images/math/2e84f52c0f54659a1f533b25591adb924f2a4131.svg" style="height: 11px;" type="image/svg+xml"&gt;v_2&lt;/object&gt;. That's another
fan-in node:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/abb4615332fa4d17f90efc39ef6574223a66c901.svg" style="height: 94px;" type="image/svg+xml"&gt;\[\begin{align*}
  \frac{\partial f}{\partial x_1}^{(2)}&amp;amp;=\frac{\partial f}{\partial v_2} \frac{\partial v_2}{\partial x_1}=1\cdot x_2=5\\
  \frac{\partial f}{\partial x_2}^{(1)}&amp;amp;=\frac{\partial f}{\partial v_2} \frac{\partial v_2}{\partial x_2}=1\cdot x_1=2
\end{align*}\]&lt;/object&gt;
&lt;p&gt;We've calculated the other contribution to the &lt;object class="valign-m3" data="https://eli.thegreenplace.net/images/math/593f4cff5d4210d46e140db57bafc4f692493f76.svg" style="height: 11px;" type="image/svg+xml"&gt;x_1&lt;/object&gt; derivative, and the
first out of two contributions for the &lt;object class="valign-m3" data="https://eli.thegreenplace.net/images/math/a8728ff397f08f1999170f64ff5838333f755380.svg" style="height: 11px;" type="image/svg+xml"&gt;x_2&lt;/object&gt; derivative. Next, let's
handle &lt;object class="valign-m3" data="https://eli.thegreenplace.net/images/math/73db09ec63501c91f822ea29cefadf3bb9837084.svg" style="height: 11px;" type="image/svg+xml"&gt;v_3&lt;/object&gt;:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/6a9dce7fcdeee31cdf6dead194b8d3898b04db61.svg" style="height: 44px;" type="image/svg+xml"&gt;\[\frac{\partial f}{\partial x_2}^{(2)}=\frac{\partial f}{\partial v_3} \frac{\partial v_3}{\partial x_2}=-1\cdot cos(x_2)=-0.28\]&lt;/object&gt;
&lt;p&gt;Finally, we're ready to add up the derivative contributions for the input arguments.
&lt;object class="valign-m3" data="https://eli.thegreenplace.net/images/math/593f4cff5d4210d46e140db57bafc4f692493f76.svg" style="height: 11px;" type="image/svg+xml"&gt;x_1&lt;/object&gt; is a &amp;quot;fan-out&amp;quot; node, with two outputs. Recall from the section above
that we just sum their contributions:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/2905b796b72079d5677b85735f0e8715a5bfd0da.svg" style="height: 44px;" type="image/svg+xml"&gt;\[\frac{\partial f}{\partial x_1}=\frac{\partial f}{\partial x_1}^{(1)}+\frac{\partial f}{\partial x_1}^{(2)}=0.5+5=5.5\]&lt;/object&gt;
&lt;p&gt;And:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/98bfd4fb2ad61c35ffc3d5e45ff26c0886829a6e.svg" style="height: 44px;" type="image/svg+xml"&gt;\[\frac{\partial f}{\partial x_2}=\frac{\partial f}{\partial x_2}^{(1)}+\frac{\partial f}{\partial x_2}^{(2)}=2-0.28=1.72\]&lt;/object&gt;
&lt;p&gt;And we're done! Once again, it's easy to verify - using a calculator and the
analytical derivatives of &lt;object class="valign-m5" data="https://eli.thegreenplace.net/images/math/c644ca35529294cbdae3f76b2dab55120f5cbdbf.svg" style="height: 19px;" type="image/svg+xml"&gt;f(x_1,x_2)&lt;/object&gt; - that these are the right
derivatives at the given points.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="backpropagation-in-ml-reverse-mode-ad-and-vjps"&gt;
&lt;h2&gt;Backpropagation in ML, reverse mode AD and VJPs&lt;/h2&gt;
&lt;p&gt;A quick note on reverse mode AD vs forward mode (please read the ADIMLAS paper
for much more details):&lt;/p&gt;
&lt;p&gt;Reverse mode AD is the approach commonly used for machine learning and neural
networks, because these tend to have a scalar &lt;em&gt;loss&lt;/em&gt; (or &lt;em&gt;error&lt;/em&gt;) output that we
want to minimize. In reverse mode, we have to run AD once per output, while in
forward mode we'd have to run it once per &lt;em&gt;input&lt;/em&gt;. Therefore, when the input
size is much larger than the output size (as is the case in NNs), reverse mode
is preferable.&lt;/p&gt;
&lt;p&gt;There's another advantage, and it relates to the term &lt;em&gt;vector-jacobian product&lt;/em&gt;
(VJP) that you will definitely run into once you start digging deeper in this
domain.&lt;/p&gt;
&lt;p&gt;The VJP is basically a fancy way of saying &amp;quot;using the chain rule in reverse mode
AD&amp;quot;. Recall that in the most general case, the multivariate chain rule is:&lt;/p&gt;
&lt;img alt="\[D(f \circ g)(a)=Df(g(a)) \cdot Dg(a)\]" class="align-center" src="https://eli.thegreenplace.net/images/math/00bdefa904bd34df2dfb50cc385e6497c4e5096e.png" style="height: 18px;" /&gt;
&lt;p&gt;However, in the case of reverse mode AD, we typically have a single output
from the full graph, so &lt;img alt="Df(g(a))" class="valign-m4" src="https://eli.thegreenplace.net/images/math/e567730c48bb2f95c258b630b4d6e997043e09ab.png" style="height: 18px;" /&gt; is a row vector. The chain rule
then means multiplying this row vector by a matrix representing the node's
jacobian. This is the &lt;em&gt;vector-jacobian product&lt;/em&gt;, and its output is another
row vector. Scroll back to the &lt;em&gt;Fan-out&lt;/em&gt; sample to see an example of this.&lt;/p&gt;
&lt;p&gt;This may not seem very profound so far, but it carries an important meaning in
terms of computational efficiency. For each node in the graph, we don't have
to store its complete jacobian; all we need is a function that takes a row
vector and produces the VJP. This is important because jacobians can be very
large and very sparse &lt;a class="footnote-reference" href="#footnote-4" id="footnote-reference-4"&gt;[4]&lt;/a&gt;. In practice, this means that when AD libraries
define the derivative of a computation node, they don't ask you to register
a complete jacobian for each operation, but rather a VJP.&lt;/p&gt;
&lt;p&gt;This also provides an additional way to think about the relative efficiency of
reverse mode AD for ML
applications; since a graph typically has many inputs (all the weights), and a
single output (scalar loss), accumulating from the end going backwards means the
intermediate products are VJPs that are row vectors; accumulating from the front
would mean multiplying full jacobians together, and the intermediate results
would be matrices &lt;a class="footnote-reference" href="#footnote-5" id="footnote-reference-5"&gt;[5]&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="a-simple-python-implementation-of-reverse-mode-ad"&gt;
&lt;h2&gt;A simple Python implementation of reverse mode AD&lt;/h2&gt;
&lt;p&gt;Enough equations, let's see some code! The whole point of AD is that it's
&lt;em&gt;automatic&lt;/em&gt;, meaning that it's simple to implement in a program. What follows
is the simplest implementation I could think of; it requires one to build
expressions out of a special type, which can then calculate gradients
automatically.&lt;/p&gt;
&lt;p&gt;Let's start with some usage samples; here's the Sigmoid calculation presented
earlier:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Var&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;sigmoid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;xx = &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="si"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;.2&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;, sigmoid = &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;sigmoid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="si"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;.2&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;sigmoid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;grad&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;dsigmoid/dxx = &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gv&lt;/span&gt;&lt;span class="si"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;.2&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We begin by building the Sigmoid expression using &lt;tt class="docutils literal"&gt;Var&lt;/tt&gt; values (more on this
later). We can then run the &lt;tt class="docutils literal"&gt;grad&lt;/tt&gt; method on a &lt;tt class="docutils literal"&gt;Var&lt;/tt&gt;, with an output
gradient of 1.0 and see that the gradient for &lt;tt class="docutils literal"&gt;xx&lt;/tt&gt; is 0.24, as calculated
before.&lt;/p&gt;
&lt;p&gt;Here's the expression we used for the DAG section:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Var&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;2.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;x2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Var&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;5.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;x1&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x2&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;sin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;x1 = &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;x1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="si"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;.2&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;, x2 = &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;x2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="si"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;.2&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;, f = &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="si"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;.2&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;grad&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;df/dx1 = &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;x1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gv&lt;/span&gt;&lt;span class="si"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;.2&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;, df/dx2 = &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;x2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gv&lt;/span&gt;&lt;span class="si"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;.2&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once again, we build up the expression, then call &lt;tt class="docutils literal"&gt;grad&lt;/tt&gt; on the final value.
It will populate the &lt;tt class="docutils literal"&gt;gv&lt;/tt&gt; attributes of input &lt;tt class="docutils literal"&gt;Var&lt;/tt&gt;s with the derivatives
calculated w.r.t. these inputs.&lt;/p&gt;
&lt;p&gt;Let's see how &lt;tt class="docutils literal"&gt;Var&lt;/tt&gt; works. The high-level overview is:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;A &lt;tt class="docutils literal"&gt;Var&lt;/tt&gt; represents a node in the computational graph we've been discussing
in this post.&lt;/li&gt;
&lt;li&gt;Using operator overloading and custom math functions (like the &lt;tt class="docutils literal"&gt;exp&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;sin&lt;/tt&gt;
and &lt;tt class="docutils literal"&gt;log&lt;/tt&gt; seen in the samples above), when an expression is constructed
out of &lt;tt class="docutils literal"&gt;Var&lt;/tt&gt; values, we also build the computational graph in the
background. Each &lt;tt class="docutils literal"&gt;Var&lt;/tt&gt; has links to its &lt;em&gt;predecessors&lt;/em&gt; in the graph (the
other &lt;tt class="docutils literal"&gt;Var&lt;/tt&gt;s that feed into it).&lt;/li&gt;
&lt;li&gt;When the &lt;tt class="docutils literal"&gt;grad&lt;/tt&gt; method is called, it runs reverse mode AD through the
computational graph, using the chain rule.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here's the &lt;tt class="docutils literal"&gt;Var&lt;/tt&gt; class:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Var&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predecessors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;v&lt;/tt&gt; is the value (forward calculation) of this &lt;tt class="docutils literal"&gt;Var&lt;/tt&gt;. &lt;tt class="docutils literal"&gt;predecessors&lt;/tt&gt; is
the list of predecessors, each of this type:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nd"&gt;@dataclass&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Predecessor&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;multiplier&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;
    &lt;span class="n"&gt;var&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Var&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Consider the &lt;tt class="docutils literal"&gt;v5&lt;/tt&gt; node in DAG sample, for example. It represents the
calculation &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;v4-v3&lt;/span&gt;&lt;/tt&gt;. The &lt;tt class="docutils literal"&gt;Var&lt;/tt&gt; representing &lt;tt class="docutils literal"&gt;v5&lt;/tt&gt; will have a list of
two predecessors, one for &lt;tt class="docutils literal"&gt;v4&lt;/tt&gt; and one for &lt;tt class="docutils literal"&gt;v3&lt;/tt&gt;. Each of these will
have a &amp;quot;multiplier&amp;quot; associated with it:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;For &lt;tt class="docutils literal"&gt;v3&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;Predecessor.var&lt;/tt&gt; points to the &lt;tt class="docutils literal"&gt;Var&lt;/tt&gt; representing &lt;tt class="docutils literal"&gt;v3&lt;/tt&gt;
and &lt;tt class="docutils literal"&gt;Predecessor.multiplier&lt;/tt&gt; is -1, since this is the derivative
of &lt;tt class="docutils literal"&gt;v5&lt;/tt&gt; w.r.t. &lt;tt class="docutils literal"&gt;v3&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;Similarly, for &lt;tt class="docutils literal"&gt;v4&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;Predecessor.var&lt;/tt&gt; points to the &lt;tt class="docutils literal"&gt;Var&lt;/tt&gt; representing
&lt;tt class="docutils literal"&gt;v4&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;Predecessor.multiplier&lt;/tt&gt; is 1.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let's see some overloaded operators of &lt;tt class="docutils literal"&gt;Var&lt;/tt&gt; &lt;a class="footnote-reference" href="#footnote-6" id="footnote-reference-6"&gt;[6]&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__add__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;other&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ensure_var&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Var&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predecessors&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Predecessor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predecessors&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Predecessor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt;

&lt;span class="c1"&gt;# ...&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__mul__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;other&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ensure_var&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Var&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predecessors&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Predecessor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predecessors&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Predecessor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And some of the custom math functions:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;log(x) - natural logarithm of x&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ensure_var&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Var&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predecessors&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Predecessor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;sin(x)&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ensure_var&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Var&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predecessors&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Predecessor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note how the multipliers for each node are exactly the derivatives of its
output w.r.t. corresponding input. Notice also that in some cases we use the
forward calculated value of a &lt;tt class="docutils literal"&gt;Var&lt;/tt&gt;'s inputs to calculate this derivative
(e.g. in the case of &lt;tt class="docutils literal"&gt;sin(x)&lt;/tt&gt;, the derivative is &lt;tt class="docutils literal"&gt;cos(x)&lt;/tt&gt;, so we need the
actual value of &lt;tt class="docutils literal"&gt;x&lt;/tt&gt;).&lt;/p&gt;
&lt;p&gt;Finally, this is the &lt;tt class="docutils literal"&gt;grad&lt;/tt&gt; method:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;grad&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gv&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gv&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;gv&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predecessors&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;var&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;grad&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;multiplier&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;gv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Some notes about this method:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;It has to be invoked on a &lt;tt class="docutils literal"&gt;Var&lt;/tt&gt; node that represents the entire computation.&lt;/li&gt;
&lt;li&gt;Since this function walks the graph backwards (from the outputs to the inputs),
this is the direction our graph edges are pointing (we keep track of the
predecessors of each node, not the successors).&lt;/li&gt;
&lt;li&gt;Since we typically want the derivative of some output &amp;quot;loss&amp;quot; w.r.t. each
&lt;tt class="docutils literal"&gt;Var&lt;/tt&gt;, the computation will usually start with &lt;tt class="docutils literal"&gt;grad(1.0)&lt;/tt&gt;, because the
output of the entire computation &lt;em&gt;is&lt;/em&gt; the loss.&lt;/li&gt;
&lt;li&gt;For each node, &lt;tt class="docutils literal"&gt;grad&lt;/tt&gt; adds the incoming gradient to its own, and propagates
the incoming gradient to each of its predecessors, using the relevant
multiplier.&lt;/li&gt;
&lt;li&gt;The addition &lt;tt class="docutils literal"&gt;self.gv += gv&lt;/tt&gt; is key to managing nodes with fan-out. Recall
our discussion from the DAG section - according to the multivariate chain rule,
fan-out nodes' derivatives add up for each of their outputs.&lt;/li&gt;
&lt;li&gt;This implementation of &lt;tt class="docutils literal"&gt;grad&lt;/tt&gt; is very simplistic and inefficient because it
will process the same &lt;tt class="docutils literal"&gt;Var&lt;/tt&gt; multiple times in complex graphs. A more
efficient implementation would sort the graph topologically first and then
would only have to visit each &lt;tt class="docutils literal"&gt;Var&lt;/tt&gt; once.&lt;/li&gt;
&lt;li&gt;Since the gradient of each &lt;tt class="docutils literal"&gt;Var&lt;/tt&gt; adds up, one shouldn't be reusing &lt;tt class="docutils literal"&gt;Var&lt;/tt&gt;s
between different computations. Once &lt;tt class="docutils literal"&gt;grad&lt;/tt&gt; was run, the &lt;tt class="docutils literal"&gt;Var&lt;/tt&gt; should
not be used for other &lt;tt class="docutils literal"&gt;grad&lt;/tt&gt; calculations.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The full code for this sample is &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/blob/main/2025/rad/rad.py"&gt;available here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The goal of this post is to serve as a supplement for the ADIMLAS paper; once
again, if the topic of AD is interesting to you, I strongly encourage you to
read the paper! I hope this post added something on top - please let me know
if you have any questions.&lt;/p&gt;
&lt;p&gt;Industrial strength implementations of AD, like &lt;a class="reference external" href="https://github.com/HIPS/autograd/"&gt;autograd&lt;/a&gt;
and &lt;a class="reference external" href="https://github.com/jax-ml/jax"&gt;JAX&lt;/a&gt;, have much better ergonomics and
performance than the toy implementation shown above. That said, the underlying
principles are similar - reverse mode AD on computational graphs. To explore
how such a system works, see my
&lt;a class="reference external" href="https://github.com/eliben/radgrad"&gt;radgrad&lt;/a&gt; project.&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-1" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;In this post we're only looking at single-output graphs, however, since
these are typically sufficient in machine learning (the output is some
scalar &amp;quot;loss&amp;quot; or &amp;quot;error&amp;quot; that we're trying to minimize). That said,
for functions with multiple outputs the process is very similar - we just
have to run the reverse mode AD process for each output variable
separately.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-2" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-2"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Note that the notation here is a bit different from the one used for
the sigmoid function. This notation is adopted from the ADIMLAS paper,
which uses &lt;object class="valign-m3" data="https://eli.thegreenplace.net/images/math/f0cd317158e9b3b19134b2c5db4e0861fcd95222.svg" style="height: 11px;" type="image/svg+xml"&gt;v_i&lt;/object&gt; for all temporary values within the graph.
I'm keeping the notations different to emphasize they have absolutely
no bearing on the math and the AD algorithm. They're just a naming
convention.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-3" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-3"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;For consistency, I'll be using the partial derivative notation
throughout this example, even for nodes that have a single input and
output.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-4" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-4"&gt;[4]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;For an example of gigantic, sparse jacobians see my older post
on &lt;a class="reference external" href="https://eli.thegreenplace.net/2018/backpropagation-through-a-fully-connected-layer/"&gt;backpropagation through a fully connected layer&lt;/a&gt;.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-5" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-5"&gt;[5]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;There are a lot of additional nuances here to explain; I strongly
recommend this &lt;a class="reference external" href="https://videolectures.net/videos/deeplearning2017_johnson_automatic_differentiation"&gt;excellent lecture&lt;/a&gt;
by &lt;a class="reference external" href="https://github.com/mattjj"&gt;Matthew Johnson&lt;/a&gt; (of JAX and autograd
fame) for a deeper overview.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-6" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-6"&gt;[6]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;These use the utility function &lt;tt class="docutils literal"&gt;ensure_var&lt;/tt&gt;; all it does is wrap the
its argument in a &lt;tt class="docutils literal"&gt;Var&lt;/tt&gt; if it's not already a &lt;tt class="docutils literal"&gt;Var&lt;/tt&gt;. This is needed
to wrap constants in the expression, to ensure that the computational
graph includes everything.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</content><category term="misc"></category><category term="Math"></category><category term="Machine Learning"></category><category term="Python"></category></entry><entry><title>GoMLX: ML in Go without Python</title><link href="https://eli.thegreenplace.net/2024/gomlx-ml-in-go-without-python/" rel="alternate"></link><published>2024-11-22T07:00:00-08:00</published><updated>2024-11-22T15:00:29-08:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2024-11-22:/2024/gomlx-ml-in-go-without-python/</id><summary type="html">&lt;p&gt;In the &lt;a class="reference external" href="https://eli.thegreenplace.net/2024/ml-in-go-with-a-python-sidecar/"&gt;previous post&lt;/a&gt;
I talked about running ML inference in Go through a Python sidecar process. In
this post, let's see how we can accomplish the same tasks without using Python
at all.&lt;/p&gt;
&lt;div class="section" id="how-ml-models-are-implemented"&gt;
&lt;h2&gt;How ML models are implemented&lt;/h2&gt;
&lt;p&gt;Let's start with a brief overview of how ML models are â€¦&lt;/p&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;In the &lt;a class="reference external" href="https://eli.thegreenplace.net/2024/ml-in-go-with-a-python-sidecar/"&gt;previous post&lt;/a&gt;
I talked about running ML inference in Go through a Python sidecar process. In
this post, let's see how we can accomplish the same tasks without using Python
at all.&lt;/p&gt;
&lt;div class="section" id="how-ml-models-are-implemented"&gt;
&lt;h2&gt;How ML models are implemented&lt;/h2&gt;
&lt;p&gt;Let's start with a brief overview of how ML models are implemented
under the hood &lt;a class="footnote-reference" href="#footnote-1" id="footnote-reference-1"&gt;[1]&lt;/a&gt;. The model is typically written in Python, using one of the
ML frameworks like TensorFlow, JAX or PyTorch. The framework takes care
of at least 2 high-level concerns for developers:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Expressive way to describe the model architecture, including
auto-differentiation for training.&lt;/li&gt;
&lt;li&gt;Efficient implementation of computational primitives on common HW: CPUs,
GPUs and TPUs.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In-between these two concerns there exists a standardized model definition
format (or several) that helps multiple tools interoperate. While it's by no
means the only solution &lt;a class="footnote-reference" href="#footnote-2" id="footnote-reference-2"&gt;[2]&lt;/a&gt;, let's look at the &lt;a class="reference external" href="https://openxla.org/"&gt;OpenXLA stack&lt;/a&gt; as a way to run models on diverse hardware:&lt;/p&gt;
&lt;img alt="OpenXLA architectural diagram, with a gopher" class="align-center" src="https://eli.thegreenplace.net/images/2024/openxla-diagram-with-gopher.png" /&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The top layer are the frameworks that provide high-level primitives to define
ML models, and translate them to
a common interchange format called &lt;a class="reference external" href="https://github.com/openxla/stablehlo"&gt;StableHLO&lt;/a&gt; (where &amp;quot;HLO&amp;quot; stands for High-Level
Operations). I've added the gopher on the very right - it will soon become
clear why.&lt;/li&gt;
&lt;li&gt;The bottom layer is the HW that executes these models efficiently.&lt;/li&gt;
&lt;li&gt;In the middle is the OpenXLA system, which includes two major components:
the XLA compiler translating HLO to HW machine code, and &lt;a class="reference external" href="https://opensource.googleblog.com/2023/05/pjrt-simplifying-ml-hardware-and-framework-integration.html"&gt;PJRT&lt;/a&gt; -
the &lt;em&gt;runtime&lt;/em&gt; component responsible for managing HW devices, moving data
(tensors) between the host CPU and these devices, executing tasks, sharding and
so on.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There's a huge amount of complexity hidden by the bottom layers of this diagram.
Efficient compilation and code generation for diverse HW - including using fixed
blocks and libraries (like cuDNN), runtime management etc. All of this is really
something one shouldn't try to re-implement unless there's a really, &lt;em&gt;really&lt;/em&gt;
good reason to do so. And the best part? There's no Python there - this is
C and C++; Python only exists on the upper layer - in the high-level ML
frameworks.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="gomlx"&gt;
&lt;h2&gt;GoMLX&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/gomlx"&gt;GoMLX&lt;/a&gt; is a relatively new Go package for ML
that deserves some attention. GoMLX slots in as one of the frameworks,
exactly where the Gopher is in the diagram above &lt;a class="footnote-reference" href="#footnote-3" id="footnote-reference-3"&gt;[3]&lt;/a&gt;. This is absolutely the
right approach to the problem. There's no point in re-implementing the
low-level primitives - whatever works for TF and JAX will work for Go as well!
Google, NVIDIA, Intel and several other companies invest huge resources into
these systems, and it's a good idea to benefit from these efforts.&lt;/p&gt;
&lt;p&gt;In this post I will showcase re-implementations of some of the samples from
the &lt;a class="reference external" href="https://eli.thegreenplace.net/2024/ml-in-go-with-a-python-sidecar/"&gt;previous post&lt;/a&gt;,
but with no Python in sight. But first, a few words about what GoMLX does.&lt;/p&gt;
&lt;p&gt;GoMLX should be familiar if you've used one of the popular Python ML frameworks.
You build a computational graph representing your model - the usual operations
are supported and sufficient to implement anything from linear regression to
cutting-edge transformers. Since GoMLX wraps XLA, it has access to all the same
building blocks TF and JAX use (and it adds its own higher-level primitives,
similarly to the Python frameworks).&lt;/p&gt;
&lt;p&gt;GoMLX supports &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Automatic_differentiation"&gt;automatic differentiation&lt;/a&gt; to
create the &lt;a class="reference external" href="https://eli.thegreenplace.net/2018/backpropagation-through-a-fully-connected-layer/"&gt;backward propagation&lt;/a&gt;
operations required to update weights in training. It also provides many helpers
for training and keeping track of progress, as well as &lt;a class="reference external" href="https://github.com/janpfeifer/gonb"&gt;Jupyter notebook support&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="an-image-model-for-the-cifar-10-dataset-with-gomlx"&gt;
&lt;h2&gt;An image model for the CIFAR-10 dataset with GoMLX&lt;/h2&gt;
&lt;p&gt;In the &lt;a class="reference external" href="https://eli.thegreenplace.net/2024/ml-in-go-with-a-python-sidecar/"&gt;previous post&lt;/a&gt;
we built a CNN (convolutional neural network) model using TF+Keras in Python,
and ran its inference in a sidecar process we could control from Go.&lt;/p&gt;
&lt;p&gt;Here, let's build a similar model in Go, without using Python at all; we'll
be training it on the same &lt;a class="reference external" href="https://www.cs.toronto.edu/~kriz/cifar.html"&gt;CIFAR-10 dataset&lt;/a&gt;
we've used before.&lt;/p&gt;
&lt;img alt="CIFAR-10 dataset sample" class="align-center" src="https://eli.thegreenplace.net/images/2024/cifar10.png" /&gt;
&lt;p&gt;The full code for this sample &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/tree/main/2024/go-mlx/cifar-cnn"&gt;is here&lt;/a&gt;;
it is heavily based on GoMLX's
&lt;a class="reference external" href="https://github.com/gomlx/gomlx/tree/main/examples/cifar"&gt;own example&lt;/a&gt;, with
some modifications for simplicity and clarity. Here's the code defining the
model graph:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;func&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;C10ConvModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;mlxctx&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;mlxcontext&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Context&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;spec&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;any&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;inputs&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Node&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Node&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;batchedImages&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;g&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;batchedImages&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Graph&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;dtype&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;batchedImages&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;DType&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;batchSize&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;batchedImages&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Shape&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="nx"&gt;Dimensions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;batchedImages&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;layerIdx&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;nextCtx&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;name&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;mlxcontext&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Context&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nx"&gt;newCtx&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;mlxctx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Inf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;%03d_%s&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;layerIdx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nx"&gt;layerIdx&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;newCtx&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// Convolution / activation layers&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;layers&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Convolution&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;nextCtx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;conv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;Filters&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;KernelSize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;PadSame&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="nx"&gt;Done&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;AssertDims&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;batchSize&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;activations&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;layers&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Convolution&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;nextCtx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;conv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;Filters&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;KernelSize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;PadSame&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="nx"&gt;Done&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;activations&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;MaxPool&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;Window&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;Done&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;layers&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;DropoutNormalize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;nextCtx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;dropout&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Scalar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;g&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.3&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;AssertDims&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;batchSize&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;layers&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Convolution&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;nextCtx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;conv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;Filters&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;KernelSize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;PadSame&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="nx"&gt;Done&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;AssertDims&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;batchSize&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;activations&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;layers&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Convolution&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;nextCtx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;conv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;Filters&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;KernelSize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;PadSame&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="nx"&gt;Done&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;AssertDims&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;batchSize&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;activations&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;MaxPool&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;Window&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;Done&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;layers&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;DropoutNormalize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;nextCtx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;dropout&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Scalar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;g&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;AssertDims&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;batchSize&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;layers&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Convolution&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;nextCtx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;conv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;Filters&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;KernelSize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;PadSame&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="nx"&gt;Done&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;AssertDims&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;batchSize&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;activations&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;layers&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Convolution&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;nextCtx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;conv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;Filters&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;KernelSize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;PadSame&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="nx"&gt;Done&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;AssertDims&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;batchSize&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;activations&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;MaxPool&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;Window&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;Done&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;layers&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;DropoutNormalize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;nextCtx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;dropout&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Scalar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;g&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;AssertDims&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;batchSize&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// Flatten logits, and apply dense layer&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;batchSize&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;layers&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;nextCtx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;dense&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;activations&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;layers&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;DropoutNormalize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;nextCtx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;dropout&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Scalar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;g&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;numClasses&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;layers&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;nextCtx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;dense&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;numClasses&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Node&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As you might expect, the Go code is longer and more explicit (nodes are threaded
explicitly between builder calls, instead of being magically accumulated). It's
not hard to envision a Keras-like high level library on top of this.&lt;/p&gt;
&lt;p&gt;Here's a snippet from &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/blob/main/2024/go-mlx/cifar-cnn/classify-cnn/classify-cnn.go"&gt;the classifier (inference)&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;func&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;flagCheckpoint&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;flag&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;String&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;checkpoint&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Directory to load checkpoint from&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;flag&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Parse&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;mlxctx&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;mlxcontext&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;New&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;backend&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;backends&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;New&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;checkpoints&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;mlxctx&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;Dir&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;flagCheckpoint&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;Done&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;!=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;nil&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;panic&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;mlxctx&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;mlxctx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Reuse&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;// helps sanity check the loaded context&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;exec&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;mlxcontext&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;NewExec&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;backend&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;mlxctx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;In&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;model&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;mlxctx&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;mlxcontext&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Context&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;image&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Node&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Node&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;// Convert our image to a tensor with batch dimension of size 1, and pass&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;// it to the C10ConvModel graph.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nx"&gt;image&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;ExpandAxes&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;image&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;// Create a batch dimension of size 1.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;cnnmodel&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;C10ConvModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;mlxctx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;nil&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Node&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nx"&gt;image&lt;/span&gt;&lt;span class="p"&gt;})[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;// Take the class with highest logit value, then remove the batch dimension.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nx"&gt;choice&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;ArgMax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;dtypes&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Int32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// classify takes a 32x32 image and returns a Cifar-10 classification according&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// to the models. Use C10Labels to convert the returned class to a string&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// name. The returned class is from 0 to 9.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;classify&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;img&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;image&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Image&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;int32&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nx"&gt;input&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;images&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;ToTensor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;dtypes&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Float32&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;Single&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;img&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nx"&gt;outputs&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;exec&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;input&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nx"&gt;classID&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;tensors&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;ToScalar&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="kt"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;](&lt;/span&gt;&lt;span class="nx"&gt;outputs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;classID&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// ...&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now &lt;tt class="docutils literal"&gt;classify&lt;/tt&gt; is a function that takes an &lt;a class="reference external" href="https://pkg.go.dev/image#Image"&gt;image.Image&lt;/a&gt; and runs it through the network, returning
the index of the most likely label out of the list of CIFAR-10 labels.&lt;/p&gt;
&lt;p&gt;The &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/blob/main/2024/go-mlx/cifar-cnn/README.md"&gt;README file&lt;/a&gt;
in the sample explains how to run it locally on a GPU; the
model trains and runs successfully, with similar results to the TF+Keras
model we trained in Python earlier.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="gemma2-with-gomlx"&gt;
&lt;h2&gt;Gemma2 with GoMLX&lt;/h2&gt;
&lt;p&gt;For a (much) more involved example, GoMLX has a full implementation of
&lt;a class="reference external" href="https://github.com/gomlx/gemma"&gt;Gemma2 inference&lt;/a&gt;. The model implementation
itself is in the &lt;a class="reference external" href="https://github.com/gomlx/gemma/tree/main/transformers"&gt;transformers package&lt;/a&gt;.
It should look fairly familiar if you've seen a transformer implementation in
another language.&lt;/p&gt;
&lt;p&gt;The official example in that repository shows how to run it with weights
downloaded from HuggingFace; since I've already downloaded the &lt;a class="reference external" href="https://www.kaggle.com/models/google/gemma-2"&gt;Gemma2 weights
from Kaggle&lt;/a&gt; for the &lt;a class="reference external" href="https://eli.thegreenplace.net/2024/ml-in-go-with-a-python-sidecar/"&gt;previous
post&lt;/a&gt;,
here's a simple adaptation:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;var&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;flagDataDir&lt;/span&gt;&lt;span class="w"&gt;   &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;flag&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;String&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;data&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;dir with converted weights&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;flagVocabFile&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;flag&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;String&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;vocab&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;tokenizer vocabulary file&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="kd"&gt;func&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;flag&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Parse&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;ctx&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;context&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;New&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// Load model weights from the checkpoint downloaded from Kaggle.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;kaggle&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;ReadConvertedWeights&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;ctx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;flagDataDir&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;!=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;nil&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Fatal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// Load tokenizer vocabulary.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;vocab&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;sentencepiece&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;NewFromPath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;flagVocabFile&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;!=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;nil&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Fatal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// Create a Gemma sampler and start sampling tokens.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;sampler&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;samplers&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;New&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;backends&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;New&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;ctx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;vocab&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;!=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;nil&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Fatalf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;%+v&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;start&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;time&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Now&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;sampler&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Sample&lt;/span&gt;&lt;span class="p"&gt;([]&lt;/span&gt;&lt;span class="kt"&gt;string&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Are bees and wasps similar?&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;!=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;nil&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Fatalf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;%+v&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;fmt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;\tElapsed time: %s\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;time&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Since&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;start&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;fmt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Generated text:\n%s\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;strings&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;\n\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The complete code together with installation and setup instructions
&lt;a class="reference external" href="https://github.com/eliben/code-for-blog/tree/main/2024/go-mlx/gemma"&gt;is here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;gomlx/gemma&lt;/tt&gt; demonstrates that GoMLX has sufficiently advanced capabilities
to run a real production-grade open LLM, without Python in the loop.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="summary"&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;The &lt;a class="reference external" href="https://eli.thegreenplace.net/2024/ml-in-go-with-a-python-sidecar/"&gt;previous post&lt;/a&gt;
discussed some options for incorporating ML inference into a Go project via
a minimal Python sidecar process. Here, we take it a step further and
implement ML inference in Go without using Python. We do so by leveraging
GoMLX, which itself relies on XLA and PJRT to do the heavy lifting.&lt;/p&gt;
&lt;p&gt;If we strip down a framework like TensorFlow to its layers, GoMLX reuses the
bottom layers (which is where most of the magic lies), and replaces the
model builder library with a Go variant.&lt;/p&gt;
&lt;p&gt;Since GoMLX is still a relatively new project, it may be a little risky for
production uses at this point. That said, I find this direction very promising
and will be following the project's development with interest.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="code"&gt;
&lt;h2&gt;Code&lt;/h2&gt;
&lt;p&gt;The full code for the samples in this post is &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/tree/main/2024/go-mlx"&gt;on GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-1" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;This assumes you know the basics of neural network graphs,
their training, etc. If not, check out &lt;a class="reference external" href="https://eli.thegreenplace.net/2018/understanding-how-to-implement-a-character-based-rnn-language-model/"&gt;this post&lt;/a&gt;
and some of my other posts in the &lt;a class="reference external" href="https://eli.thegreenplace.net/tag/machine-learning"&gt;Machine Learning category&lt;/a&gt;.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-2" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-2"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;It's likely the most common production solution, and pretty much the only
way to access Google's TPUs.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-3" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-3"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;It does so by including Go bindings for both XLA and PJRT; these are
wrapped in higher-level APIs for users.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</content><category term="misc"></category><category term="Go"></category><category term="Machine Learning"></category><category term="Python"></category></entry><entry><title>ML in Go with a Python sidecar</title><link href="https://eli.thegreenplace.net/2024/ml-in-go-with-a-python-sidecar/" rel="alternate"></link><published>2024-11-11T06:13:00-08:00</published><updated>2024-11-11T14:29:57-08:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2024-11-11:/2024/ml-in-go-with-a-python-sidecar/</id><summary type="html">&lt;p&gt;Machine learning models are rapidly becoming more capable; how can we make
use of these powerful new tools in our Go applications?&lt;/p&gt;
&lt;p&gt;For top-of-the-line commercial LLMs like ChatGPT, Gemini or Claude, the models
are exposed as language agnostic REST APIs. We can hand-craft
HTTP requests or use client libraries (SDKs â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Machine learning models are rapidly becoming more capable; how can we make
use of these powerful new tools in our Go applications?&lt;/p&gt;
&lt;p&gt;For top-of-the-line commercial LLMs like ChatGPT, Gemini or Claude, the models
are exposed as language agnostic REST APIs. We can hand-craft
HTTP requests or use client libraries (SDKs) provided by the LLM vendors.
If we need more customized solutions, however, some challenges arise. Completely
bespoke models are typically trained in Python using tools like TensorFlow,
JAX or PyTorch that don't have real non-Python alternatives.&lt;/p&gt;
&lt;p&gt;In this post, I will present some approaches for Go developers to use ML models
in their applications - with increasing level of customization. The summary up
front is that it's pretty easy, and we only have to deal with Python very
minimally, if at all - depending on the circumstances.&lt;/p&gt;
&lt;img alt="Go gopher with Python logo inside" class="align-center" src="https://eli.thegreenplace.net/images/2024/gopherpythonlogo.png" style="width: 219px;" /&gt;
&lt;div class="section" id="internet-llm-services"&gt;
&lt;h2&gt;Internet LLM services&lt;/h2&gt;
&lt;p&gt;This is the easiest category: multimodal services from Google, OpenAI
and others are available as REST APIs with convenient client libraries for
most leading languages (including Go), as well as third-party packages that
provide abstractions on top (e.g. &lt;a class="reference external" href="https://github.com/tmc/langchaingo"&gt;langchaingo&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Check out the official Go blog titled &lt;a class="reference external" href="https://go.dev/blog/llmpowered"&gt;Building LLM-powered applications in
Go&lt;/a&gt; that was published earlier this year.
I've written about it before on this blog as well:
&lt;a class="reference external" href="https://eli.thegreenplace.net/2024/gemini-cli-access-gemini-models-from-the-command-line/"&gt;#1&lt;/a&gt;,
&lt;a class="reference external" href="https://eli.thegreenplace.net/2023/retrieval-augmented-generation-in-go/"&gt;#2&lt;/a&gt;,
&lt;a class="reference external" href="https://eli.thegreenplace.net/2023/using-gemini-models-from-go/"&gt;#3&lt;/a&gt; etc.&lt;/p&gt;
&lt;p&gt;Go is typically as well supported as other programming languages in this domain;
in fact, it's uniquely powerful for such applications because of its
network-native nature; quoting from the Go blog post:&lt;/p&gt;
&lt;blockquote&gt;
Working with LLM services often means sending REST or RPC requests to a
network service, waiting for the response, sending new requests to other
services based on that and so on. Go excels at all of these, providing great
tools for managing concurrency and the complexity of juggling network
services.&lt;/blockquote&gt;
&lt;p&gt;Since this has been covered extensively, let's move on to the more challenging
scenarios.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="locally-running-llms"&gt;
&lt;h2&gt;Locally-running LLMs&lt;/h2&gt;
&lt;p&gt;There's a plethora of high-quality open models &lt;a class="footnote-reference" href="#footnote-1" id="footnote-reference-1"&gt;[1]&lt;/a&gt; one can choose from to
run locally: Gemma, Llama, Mistral and many more. While these models aren't
quite as capable as the strongest commercial LLM services, they are often
surprisingly good and have clear benefits w.r.t. cost and privacy.&lt;/p&gt;
&lt;p&gt;The industry has begun standardizing on some common formats for shipping and
sharing these models - e.g. GGUF from &lt;a class="reference external" href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt;,
&lt;a class="reference external" href="https://huggingface.co/docs/safetensors/en/index"&gt;safetensors from Hugging Face&lt;/a&gt;
or the older &lt;a class="reference external" href="https://github.com/onnx/"&gt;ONNX&lt;/a&gt;.
Additionally, there are a number of excellent OSS tools that let us run such
models locally and expose a REST API for an experience that's very similar to
the OpenAI or Gemini APIs, including dedicated client libraries.&lt;/p&gt;
&lt;p&gt;The best known such tool is probably &lt;a class="reference external" href="https://ollama.com/"&gt;Ollama&lt;/a&gt;; I've
written extensively about it in the past:
&lt;a class="reference external" href="https://eli.thegreenplace.net/2024/the-life-of-an-ollama-prompt/"&gt;#1&lt;/a&gt;,
&lt;a class="reference external" href="https://eli.thegreenplace.net/2023/using-ollama-with-langchaingo/"&gt;#2&lt;/a&gt;,
&lt;a class="reference external" href="https://eli.thegreenplace.net/2024/gemma-ollama-and-langchaingo/"&gt;#3&lt;/a&gt;.&lt;/p&gt;
&lt;img alt="Internals of ollama, showing service connecting to clients and loading GGUF" class="align-center" src="https://eli.thegreenplace.net/images/2024/ollama-internals.png" /&gt;
&lt;p&gt;Ollama lets us customize an LLM through a &lt;a class="reference external" href="https://github.com/ollama/ollama/blob/main/docs/modelfile.md"&gt;Modelfile&lt;/a&gt;,
which includes things like setting model parameters, system prompts etc. If we
fine-tuned a model &lt;a class="footnote-reference" href="#footnote-2" id="footnote-reference-2"&gt;[2]&lt;/a&gt;, it can also be loaded into Ollama by specifying our
own GGUF file.&lt;/p&gt;
&lt;p&gt;If you're running in a cloud environment, some vendors already have
off-the-shelf solutions like &lt;a class="reference external" href="https://cloud.google.com/run/docs/tutorials/gpu-gemma2-with-ollama"&gt;GCP's Cloud Run integration&lt;/a&gt; that
may be useful.&lt;/p&gt;
&lt;p&gt;Ollama isn't the only player in this game, either; recently a new tool
emerged with a slightly different approach. &lt;a class="reference external" href="https://github.com/Mozilla-Ocho/llamafile"&gt;Llamafile&lt;/a&gt;
distributes the entire model as a single binary, which is portable across
several OSes and CPU architectures. Like Ollama, it provides REST APIs for the
model.&lt;/p&gt;
&lt;p&gt;If such a customized LLM is a suitable solution for your project, consider just
running Ollama or Llamafile and using their REST APIs to communicate with the
model. If you need higher degrees of customization, read on.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="a-note-about-the-sidecar-pattern"&gt;
&lt;h2&gt;A note about the sidecar pattern&lt;/h2&gt;
&lt;p&gt;Before we proceed, I want to briefly discuss the &lt;a class="reference external" href="https://kubernetes.io/docs/concepts/workloads/pods/sidecar-containers/"&gt;sidecar pattern&lt;/a&gt;
of application deployment. That k8s link talks about &lt;em&gt;containers&lt;/em&gt;, but the
pattern isn't limited to these. It applies to any software architecture in which
functionality is isolated across processes.&lt;/p&gt;
&lt;p&gt;Suppose we have an application that requires some library functionality; using
Go as an example, we could find &lt;a class="reference external" href="https://pkg.go.dev/"&gt;an appropriate package&lt;/a&gt;, import it and be on our way. Suppose there's no
suitable Go package, however. If libraries exist with a C interface, we could
alternatively use &lt;a class="reference external" href="https://go.dev/blog/cgo"&gt;cgo&lt;/a&gt; to import it.&lt;/p&gt;
&lt;p&gt;But say there's no C API either, for example if the functionality is only
provided by a language without a convenient exported interface. Maybe it's
in Lisp, or Perl, or... Python.&lt;/p&gt;
&lt;p&gt;A very general solution could be to wrap the code we need in some kind of server
interface and run it as a separate process; this kind of process is called a
&lt;em&gt;sidecar&lt;/em&gt; - it's launched specifically to provide additional functionality for
another process. Whichever inter-process communication (IPC) mechanism we use,
the benefits of this approach are many - isolation, security, language
independence, etc. In today's world of containers and orchestration this
approach is becoming increasingly more common; this is why many of the links
about sidecars lead to k8s and other containerized solutions.&lt;/p&gt;
&lt;img alt="Depiction of a motorcycle with a Gopher, with Python in a sidecar" class="align-center" src="https://eli.thegreenplace.net/images/2024/sidecar-go-py.png" style="width: 256px;" /&gt;
&lt;p&gt;The Ollama approach outlined in the previous section is one example of using
the sidecar pattern. Ollama provides us with LLM functionality but it runs as
a server in its own process.&lt;/p&gt;
&lt;p&gt;The solutions presented in the rest of this post are more explicit and fully
worked-out examples of using the sidecar pattern.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="locally-running-llm-with-python-and-jax"&gt;
&lt;h2&gt;Locally-running LLM with Python and JAX&lt;/h2&gt;
&lt;p&gt;Suppose none of the existing open LLMs will do for our project, even
fine-tuned. At this point we can consider training our own LLM - this
is hugely expensive, but perhaps there's no choice. Training usually involves
one of the large ML frameworks like TensorFlow, JAX or PyTorch. In this section
I'm not going to talk about how to train models; instead, I'll show how to run
local inference of an already trained model - in Python with JAX, and use that
as a sidecar server for a Go application.&lt;/p&gt;
&lt;p&gt;The sample (&lt;a class="reference external" href="https://github.com/eliben/code-for-blog/tree/main/2024/go-py-ml/jax-gemma-server"&gt;full code is here&lt;/a&gt;)
is based on the
&lt;a class="reference external" href="https://github.com/google-deepmind/gemma/"&gt;official Gemma repository&lt;/a&gt;,
using its &lt;em&gt;sampler&lt;/em&gt; library &lt;a class="footnote-reference" href="#footnote-3" id="footnote-reference-3"&gt;[3]&lt;/a&gt;. It comes with a README that explains how
to set everything up. This is the relevant code instantiating a Gemma
sampler:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Once initialized, this will hold a sampler_lib.Sampler instance that&lt;/span&gt;
&lt;span class="c1"&gt;# can be used to generate text.&lt;/span&gt;
&lt;span class="n"&gt;gemma_sampler&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;initialize_gemma&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Initialize Gemma sampler, loading the model into the GPU.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;model_checkpoint&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getenv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;MODEL_CHECKPOINT&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;model_tokenizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getenv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;MODEL_TOKENIZER&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;parameters&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;params_lib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load_and_format_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model_checkpoint&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Parameters loaded&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;vocab&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;spm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SentencePieceProcessor&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model_tokenizer&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;transformer_config&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;transformer_lib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TransformerConfig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;parameters&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;cache_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;transformer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;transformer_lib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Transformer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;transformer_config&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;global&lt;/span&gt; &lt;span class="n"&gt;gemma_sampler&lt;/span&gt;
    &lt;span class="n"&gt;gemma_sampler&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sampler_lib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Sampler&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;transformer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;transformer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;parameters&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;transformer&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Sampler ready&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The model weights and tokenizer vocabulary are files downloaded
&lt;a class="reference external" href="https://www.kaggle.com/models/google/gemma"&gt;from Kaggle&lt;/a&gt;, per the
instructions in the Gemma repository README.&lt;/p&gt;
&lt;p&gt;So we have LLM inference up and running in Python; how do we use it from
Go?&lt;/p&gt;
&lt;p&gt;Using a sidecar, of course. Let's whip up a quick web server around this model
and expose a trivial REST interface on a local port that Go (or any other
tool) can talk to. As an example, I've set up a Flask-based web server around
this inference code. The web server is invoked with &lt;a class="reference external" href="https://gunicorn.org/"&gt;gunicorn&lt;/a&gt; - see the
&lt;a class="reference external" href="https://github.com/eliben/code-for-blog/blob/main/2024/go-py-ml/jax-gemma-server/run-gemma-server.sh"&gt;shell script&lt;/a&gt; for details.&lt;/p&gt;
&lt;p&gt;Excluding the imports, here's the entire application code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;create_app&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="c1"&gt;# Create an app and perform one-time initialization of Gemma.&lt;/span&gt;
    &lt;span class="n"&gt;app&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Flask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="vm"&gt;__name__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;app&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;app_context&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="n"&gt;initialize_gemma&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;app&lt;/span&gt;

&lt;span class="n"&gt;app&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_app&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;# Route for simple echoing / smoke test.&lt;/span&gt;
&lt;span class="nd"&gt;@app&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;route&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/echo&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;methods&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;POST&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;echo&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;prompt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;prompt&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;echo_prompt&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;prompt&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;


&lt;span class="c1"&gt;# The real route for generating text.&lt;/span&gt;
&lt;span class="nd"&gt;@app&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;route&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/prompt&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;methods&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;POST&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;prompt&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;prompt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;prompt&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="c1"&gt;# For total_generation_steps, 128 is a default taken from the Gemma&lt;/span&gt;
    &lt;span class="c1"&gt;# sample. It&amp;#39;s a tradeoff between speed and quality (higher values mean&lt;/span&gt;
    &lt;span class="c1"&gt;# better quality but slower generation).&lt;/span&gt;
    &lt;span class="c1"&gt;# The user can override this value by passing a &amp;quot;sampling_steps&amp;quot; key in&lt;/span&gt;
    &lt;span class="c1"&gt;# the request JSON.&lt;/span&gt;
    &lt;span class="n"&gt;sampling_steps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;sampling_steps&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;sampled_str&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gemma_sampler&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;input_strings&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;prompt&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="n"&gt;total_generation_steps&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sampling_steps&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;response&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;sampled_str&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The server exposes two routes:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;prompt&lt;/tt&gt;: a client sends in a textual prompt, the server runs Gemma
inference and returns the generated text in a JSON response&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;echo&lt;/tt&gt;: used for testing and benchmarking&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here's how it all looks tied together:&lt;/p&gt;
&lt;img alt="Flask server wrapping Gemma sampling and exposing REST" class="align-center" src="https://eli.thegreenplace.net/images/2024/jax-gemma-server.png" style="width: 500px;" /&gt;
&lt;p&gt;The important takeaway is that this is just an example. Literally any part of
this setup can be changed: one could use a different ML library (maybe PyTorch
instead of JAX); one could use a different model (not Gemma, not even an LLM)
and one can use a different setup to build a web server around it. There are
many options, and each developer will choose what fits their project best.&lt;/p&gt;
&lt;p&gt;It's also worth noting that we've written less than 100 lines of Python code
in total - much of it piecing together snippets from tutorials. This tiny amount
of Python code is sufficient to wrap an HTTP server with a simple REST interface
around an LLM running locally through JAX on the GPU. From here on, we're safely
back in our application's actual business logic and Go.&lt;/p&gt;
&lt;p&gt;Now, a word about performance. One of the concerns developers may have with
sidecar-based solutions is the performance overhead of IPC
between Python and Go. I've added a simple &lt;tt class="docutils literal"&gt;echo&lt;/tt&gt; endpoint to measure this
effect; take a look at the &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/tree/main/2024/go-py-ml/jax-gemma-server/measure-request-latency"&gt;Go client that exercises it&lt;/a&gt;;
on my machine the
latency of sending a JSON request from Go to the Python server and getting back
the echo response is about 0.35 ms on average. Compared to the time it takes
Gemma to process a prompt and return a response (typically measured in seconds,
or maybe hundreds of milliseconds on very powerful GPUs), this is entirely
negligible.&lt;/p&gt;
&lt;p&gt;That said, not every custom model you may need to run is a full-fledged LLM.
What if your model is small and fast, and the overhead of 0.35 ms becomes
significant? Worry not, it can be optimized. This is the topic of the next
section.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="locally-running-fast-image-model-with-python-and-tensorflow"&gt;
&lt;h2&gt;Locally-running fast image model with Python and TensorFlow&lt;/h2&gt;
&lt;p&gt;The final sample of this post mixes things up a bit:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;We'll be using a simple image model (instead of an LLM)&lt;/li&gt;
&lt;li&gt;We're going to train it ourselves using TensorFlow+Keras (instead of JAX)&lt;/li&gt;
&lt;li&gt;We'll use a different IPC method between the Python sidecar
server and clients (instead of HTTP+REST)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The model is still implemented in Python, and it's still driven as a sidecar
server process by a Go client &lt;a class="footnote-reference" href="#footnote-4" id="footnote-reference-4"&gt;[4]&lt;/a&gt;. The idea here is to show the versatility of
the sidecar approach, and to demonstrate a lower-latency way to communicate
between the processes.&lt;/p&gt;
&lt;p&gt;The full code of the sample &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/tree/main/2024/go-py-ml/tf-cifar-server"&gt;is here&lt;/a&gt;.
It trains a simple CNN
(convolutional neural network) to classify images from the
&lt;a class="reference external" href="https://www.cs.toronto.edu/~kriz/cifar.html"&gt;CIFAR-10 dataset&lt;/a&gt;:&lt;/p&gt;
&lt;img alt="CIFAR-10 dataset sample" class="align-center" src="https://eli.thegreenplace.net/images/2024/cifar10.png" /&gt;
&lt;p&gt;The neural net setup with TensorFlow and Keras was taken from an official
tutorial. Here's the entire network definition:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Sequential&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Conv2D&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;relu&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;input_shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MaxPooling2D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Conv2D&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;relu&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MaxPooling2D&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Conv2D&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;relu&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Flatten&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;relu&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;CIFAR-10 images are 32x32 pixels, each pixel being 3 values for red, green
and blue. In the original dataset, these values are bytes in the inclusive
range 0-255 representing color intensity. This should explain the
&lt;tt class="docutils literal"&gt;(32, 32, 3)&lt;/tt&gt; shape appearing in the code. The full code for training the
model is in the &lt;tt class="docutils literal"&gt;train.py&lt;/tt&gt; file in the sample; it runs for a bit and saves the
serialized model along with the trained weights into a local file.&lt;/p&gt;
&lt;p&gt;The next component is an &amp;quot;image server&amp;quot;: it loads the trained model+weights
file from disk and runs inference on images passed into it, returning the
label the model thinks is most likely for each.&lt;/p&gt;
&lt;p&gt;The server doesn't use HTTP and REST, however. It creates a
&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Unix_domain_socket"&gt;Unix domain socket&lt;/a&gt;
and uses a simple length-prefix encoding protocol to communicate:&lt;/p&gt;
&lt;img alt="Length-prefix packet format" class="align-center" src="https://eli.thegreenplace.net/images/2024/length-prefix-packet.png" style="width: 663px;" /&gt;
&lt;p&gt;Each packet starts with a 4-byte field that specifies the length of the rest
of the contents. A type is a single byte, and the body can be anything &lt;a class="footnote-reference" href="#footnote-5" id="footnote-reference-5"&gt;[5]&lt;/a&gt;.
In the sample image server two commands are currently supported:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;0 means &amp;quot;echo&amp;quot; - the server will respond with the same packet back to
the client. The contents of the packet body are immaterial.&lt;/li&gt;
&lt;li&gt;1 means &amp;quot;classify&amp;quot; - the packet body is interpreted as a 32x32 RGB image,
encoded as the red channel for each pixel in the first 1024 bytes (32x32,
&lt;a class="reference external" href="https://eli.thegreenplace.net/2015/memory-layout-of-multi-dimensional-arrays"&gt;row major&lt;/a&gt;),
then green in the next 1024 bytes and finally blue in the last 1024
bytes. Here the server will run the image through the model, and reply with
the label the model thinks describes the image.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The sample also includes &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/tree/main/2024/go-py-ml/tf-cifar-server/client"&gt;a simple Go client&lt;/a&gt;
that can take a PNG file
from disk, encode it in the required format and send it over the domain socket
to the server, recording the response.&lt;/p&gt;
&lt;p&gt;The client can also be used to benchmark the latency of a roundtrip message
exchange. It's easier to just show the code instead of explaining what it does:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;func&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;runBenchmark&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;c&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;net&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Conn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;numIters&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// Create a []byte with 3072 bytes.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;body&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;make&lt;/span&gt;&lt;span class="p"&gt;([]&lt;/span&gt;&lt;span class="kt"&gt;byte&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3072&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;i&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;range&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;body&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nx"&gt;body&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;byte&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;i&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;t1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;time&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Now&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;range&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;numIters&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nx"&gt;sendPacket&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;c&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;messageTypeEcho&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;body&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nx"&gt;cmd&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;resp&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;readPacket&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;cmd&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;!=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;||&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;resp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;!=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;body&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Fatal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;bad response&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;elapsed&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;time&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Since&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;t1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;fmt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Num packets: %d, Elapsed time: %s\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;numIters&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;elapsed&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;fmt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Average time per request: %d ns\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;elapsed&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Nanoseconds&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;int64&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;numIters&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In my testing, the average latency of a roundtrip
is about 10 Î¼s (that's &lt;em&gt;micro&lt;/em&gt;-seconds). Considering the size of the message
and it being Python on the other end, this is roughly in-line with my
&lt;a class="reference external" href="https://eli.thegreenplace.net/2019/unix-domain-sockets-in-go/"&gt;earlier benchmarking of Unix domain socket latency in Go&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;How long does a single image inference take with this model? In my measurements,
about 3 ms. Recall that the communication latency for the HTTP+REST approach was
0.35 ms; while this is only 12% of the image inference time, it's close enough
to be potentially worrying. On a beefy server-class GPU the time can be much
shorter &lt;a class="footnote-reference" href="#footnote-6" id="footnote-reference-6"&gt;[6]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;With the custom protocol over domain sockets, the latency - being 10 Î¼s -
seems quite negligible no matter what you end up running
on your GPU.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="code"&gt;
&lt;h2&gt;Code&lt;/h2&gt;
&lt;p&gt;The full code for the samples in this post is &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/tree/main/2024/go-py-ml"&gt;on GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-1" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;To be pedantic, these models are not entirely open: their inference
architecture is open-source and their weights are available, but the
details of their training remain proprietary.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-2" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-2"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;The details of fine-tuning models are beyond the scope of this post,
but there are plenty resources about this online.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-3" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-3"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&amp;quot;Sampling&amp;quot; in LLMs means roughly &amp;quot;inference&amp;quot;. A trained model is
fed an input prompt and then &amp;quot;sampled&amp;quot; to produce its output.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-4" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-4"&gt;[4]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;In my samples, the Python server and Go client simply run in different
terminals and talk to each other. How service management is structured
is very project-specific. We could envision an approach wherein the
Go application launches the Python server to run in the background and
communicates with it. Increasingly likely these days, however, would
be a container-based setup, where each program is its own container
and an orchestration solution launches and manages these containers.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-5" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-5"&gt;[5]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;You may be wondering why I'm implementing a custom protocol here instead
of using something established. In real life, I'd definitely recommend
using something like gRPC. However, for the sake of this sample I wanted
something that would be (1) simple without additional libraries and
(2) very fast. FWIW, I don't think the latency numbers would be very
much different for gRPC. Check out my
&lt;a class="reference external" href="https://eli.thegreenplace.net/2019/unix-domain-sockets-in-go/"&gt;earlier post about RPC over Unix domain sockets in Go&lt;/a&gt;.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-6" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-6"&gt;[6]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;On the other hand, the model I'm running here is &lt;em&gt;really&lt;/em&gt; small.
It's fair to say realistic models you'll use in your application
will be much larger and hence slower.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</content><category term="misc"></category><category term="Go"></category><category term="Machine Learning"></category><category term="Python"></category></entry><entry><title>My favorite prime number generator</title><link href="https://eli.thegreenplace.net/2023/my-favorite-prime-number-generator/" rel="alternate"></link><published>2023-08-22T20:01:00-07:00</published><updated>2024-05-04T19:46:23-07:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2023-08-22:/2023/my-favorite-prime-number-generator/</id><summary type="html">&lt;p&gt;Many years ago I've re-posted a &lt;a class="reference external" href="https://stackoverflow.com/a/568618/"&gt;Stack Overflow answer&lt;/a&gt; with Python code for a terse prime sieve
function that generates a potentially infinite sequence of prime
numbers (&amp;quot;potentially&amp;quot; because it &lt;em&gt;will&lt;/em&gt; run out of memory eventually). Since
then, I've used this code &lt;em&gt;many&lt;/em&gt; times - mostly because it's short and clear â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Many years ago I've re-posted a &lt;a class="reference external" href="https://stackoverflow.com/a/568618/"&gt;Stack Overflow answer&lt;/a&gt; with Python code for a terse prime sieve
function that generates a potentially infinite sequence of prime
numbers (&amp;quot;potentially&amp;quot; because it &lt;em&gt;will&lt;/em&gt; run out of memory eventually). Since
then, I've used this code &lt;em&gt;many&lt;/em&gt; times - mostly because it's short and clear. In
this post I will explain how this code works, where it comes from (I didn't come
up with it), and some potential optimizations. If you want a teaser, here it is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;gen_primes&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Generate an infinite sequence of prime numbers.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;D&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
    &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
                &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setdefault&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;del&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="section" id="the-sieve-of-eratosthenes"&gt;
&lt;h2&gt;The sieve of Eratosthenes&lt;/h2&gt;
&lt;p&gt;To understand what this code does, we should first start with the basic Sieve
of Eratosthenes; if you're familiar with it, feel free to skip this section.&lt;/p&gt;
&lt;p&gt;The &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes"&gt;Sieve of Eratosthenes&lt;/a&gt; is a well-known
algorithm from ancient Greek times for finding all the primes below a certain
number reasonably efficiently using a tabular representation. This animation
from Wikipedia explains it pretty well:&lt;/p&gt;
&lt;img alt="Animated GIF of the Sieve of Eratosthenes in action" class="align-center" src="https://eli.thegreenplace.net/images/2023/eratosthenes-animation-wikipedia.gif" /&gt;
&lt;p&gt;Starting with the first prime (2) it marks all its multiples until the requested
limit. It then takes the next unmarked number, assumes it's a prime (because it
is not a multiple of a smaller prime), and marks &lt;em&gt;its&lt;/em&gt; multiples, and so on
until all the multiples below the limit are marked. The remaining
unmarked numbers are primes.&lt;/p&gt;
&lt;p&gt;Here's a well-commented, basic Python implementation:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;gen_primes_upto&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Generates a sequence of primes &amp;lt; n.&lt;/span&gt;

&lt;span class="sd"&gt;    Uses the full sieve of Eratosthenes with O(n) memory.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt;

    &lt;span class="c1"&gt;# Initialize table; True means &amp;quot;prime&amp;quot;, initially assuming all numbers&lt;/span&gt;
    &lt;span class="c1"&gt;# are prime.&lt;/span&gt;
    &lt;span class="n"&gt;table&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;
    &lt;span class="n"&gt;sqrtn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ceil&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

    &lt;span class="c1"&gt;# Starting with 2, for each True (prime) number I in the table, mark all&lt;/span&gt;
    &lt;span class="c1"&gt;# its multiples as composite (starting with I*I, since earlier multiples&lt;/span&gt;
    &lt;span class="c1"&gt;# should have already been marked as multiples of smaller primes).&lt;/span&gt;
    &lt;span class="c1"&gt;# At the end of this process, the remaining True items in the table are&lt;/span&gt;
    &lt;span class="c1"&gt;# primes, and the False items are composites.&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sqrtn&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                &lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;False&lt;/span&gt;

    &lt;span class="c1"&gt;# Yield all the primes in the table.&lt;/span&gt;
    &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
            &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When we want a list of all the primes below some known limit,
&lt;tt class="docutils literal"&gt;gen_primes_upto&lt;/tt&gt; is great, and performs fairly well. There are two issues
with it, though:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;We have to know what the limit is ahead of time; this isn't always possible
or convenient.&lt;/li&gt;
&lt;li&gt;Its memory usage is high - O(n); this can be significantly optimized,
however; see the bonus section at the end of the post for details.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="the-infinite-prime-generator"&gt;
&lt;h2&gt;The infinite prime generator&lt;/h2&gt;
&lt;p&gt;Back to the infinite prime generator that's in the focus of this post. Here is
its code again, now with some comments:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;gen_primes&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Generate an infinite sequence of prime numbers.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="c1"&gt;# Maps composites to primes witnessing their compositeness.&lt;/span&gt;
    &lt;span class="n"&gt;D&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;

    &lt;span class="c1"&gt;# The running integer that&amp;#39;s checked for primeness&lt;/span&gt;
    &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;

    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="c1"&gt;# q is a new prime.&lt;/span&gt;
            &lt;span class="c1"&gt;# Yield it and mark its first multiple that isn&amp;#39;t&lt;/span&gt;
            &lt;span class="c1"&gt;# already marked in previous iterations&lt;/span&gt;
            &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="c1"&gt;# q is composite. D[q] holds some of the primes that&lt;/span&gt;
            &lt;span class="c1"&gt;# divide it. Since we&amp;#39;ve reached q, we no longer&lt;/span&gt;
            &lt;span class="c1"&gt;# need it in the map, but we&amp;#39;ll mark the next&lt;/span&gt;
            &lt;span class="c1"&gt;# multiples of its witnesses to prepare for larger&lt;/span&gt;
            &lt;span class="c1"&gt;# numbers&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
                &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setdefault&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;del&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

        &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The key to the algorithm is the map &lt;tt class="docutils literal"&gt;D&lt;/tt&gt;. It holds all the primes encountered
so far, but not as keys! Rather, they are stored as values, with the keys being
the next composite number they divide. This lets the program avoid having to
divide each number it encounters by all the primes known so far - it can simply
look in the map. A number that's not in the map is a new prime, and the way
the map updates is not unlike the sieve of Eratosthenes - when a composite is
removed, we add the &lt;em&gt;next&lt;/em&gt; composite multiple of the same prime(s). This is
guaranteed to cover all the composite numbers, while prime numbers should never
be keys in &lt;tt class="docutils literal"&gt;D&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;I highly recommend instrumenting this function with some printouts and running
through a sample invocation - it makes it easy to understand how the algorithm
makes progress.&lt;/p&gt;
&lt;p&gt;Compared to the full sieve &lt;tt class="docutils literal"&gt;gen_primes_upto&lt;/tt&gt;, this function doesn't require
us to know the limit ahead of time - it will keep producing prime numbers ad
infinitum (but will run out of memory eventually). As for memory usage, the
&lt;tt class="docutils literal"&gt;D&lt;/tt&gt; map has all the primes in it &lt;em&gt;somewhere&lt;/em&gt;, but each one appears only once.
So its size is &lt;object class="valign-m5" data="https://eli.thegreenplace.net/images/math/d047b6d9c65037f42dcfda7db0732cf2163b8ee7.svg" style="height: 19px;" type="image/svg+xml"&gt;O(\pi(n))&lt;/object&gt;, where &lt;object class="valign-m5" data="https://eli.thegreenplace.net/images/math/ac6df731942da5bd58234248a7aa9bd85b9100bd.svg" style="height: 19px;" type="image/svg+xml"&gt;\pi(n)&lt;/object&gt; is the
&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Prime-counting_function"&gt;Prime-counting function&lt;/a&gt;,
the number of primes smaller or equal to &lt;em&gt;n&lt;/em&gt;. This can be
approximated by &lt;object class="valign-m10" data="https://eli.thegreenplace.net/images/math/8ed6967b3dea41c3ce34ed6e0bd449b2adf5699a.svg" style="height: 24px;" type="image/svg+xml"&gt;O(\frac{n}{ln(n)})&lt;/object&gt; &lt;a class="footnote-reference" href="#footnote-1" id="footnote-reference-1"&gt;[1]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I don't remember where I first saw this approach mentioned, but all the
breadcrumbs lead to &lt;a class="reference external" href="https://code.activestate.com/recipes/117119-sieve-of-eratosthenes/"&gt;this ActiveState Recipe by David Eppstein&lt;/a&gt; from
way back in 2002.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="optimizing-the-generator"&gt;
&lt;h2&gt;Optimizing the generator&lt;/h2&gt;
&lt;p&gt;I really like &lt;tt class="docutils literal"&gt;gen_primes&lt;/tt&gt;; it's short, easy to understand and gives me as
many primes as I need without forcing me to know what limit to use, and its
memory usage is much more reasonable than the full-blown sieve of Eratosthenes.
It is, however, also quite slow, over 5x slower than &lt;tt class="docutils literal"&gt;gen_primes_upto&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;The aforementioned ActiveState Recipe thread has several optimization ideas;
here's a version that incorporates ideas from Alex Martelli, Tim Hochberg and
Wolfgang Beneicke:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;gen_primes_opt&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
    &lt;span class="n"&gt;D&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;itertools&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;
            &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;  &lt;span class="c1"&gt;# get odd multiples&lt;/span&gt;
            &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;
            &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The optimizations are:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Instead of holding a list as the value of &lt;tt class="docutils literal"&gt;D&lt;/tt&gt;, just have a single number.
In cases where we need more than one witness to a composite, find the next
multiple of the witness and assign that instead (this is the &lt;tt class="docutils literal"&gt;while x in D&lt;/tt&gt;
inner loop in the &lt;tt class="docutils literal"&gt;else&lt;/tt&gt; clause). This is a bit like using linear probing
in a hash table instead of having a list per bucket.&lt;/li&gt;
&lt;li&gt;Skip even numbers by starting with 2 and then proceeding from 3 in steps
of 2.&lt;/li&gt;
&lt;li&gt;The loop assigning the next multiple of witnesses may land on even numbers
(when &lt;tt class="docutils literal"&gt;p&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;q&lt;/tt&gt; are both odd). So instead jump to &lt;tt class="docutils literal"&gt;q + p + p&lt;/tt&gt;
directly, which is guaranteed to be odd.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;With these in place, the function is more than 3x faster than before, and is
now only within 40% or so of &lt;tt class="docutils literal"&gt;gen_primes_upto&lt;/tt&gt;, while remaining short and
reasonably clear.&lt;/p&gt;
&lt;p&gt;There are even fancier algorithms that use interesting mathematical tricks to do
less work. Here's &lt;a class="reference external" href="https://stackoverflow.com/a/19391111/"&gt;an approach by Will Ness and Tim Peters&lt;/a&gt; (yes, &lt;em&gt;that&lt;/em&gt; Tim Peters) that's
reportedly faster. It uses the &lt;em&gt;wheels&lt;/em&gt; idea from &lt;a class="reference external" href="https://research.cs.wisc.edu/techreports/1990/TR909.pdf"&gt;this paper by Sorenson&lt;/a&gt;. Some additional
details on this approach are available &lt;a class="reference external" href="https://stackoverflow.com/a/30563958"&gt;here&lt;/a&gt;. This algorithm is both faster and
consumes less memory; on the other hand, it's no longer short and simple.&lt;/p&gt;
&lt;p&gt;To be honest, it always feels a bit odd to me to painfully optimize Python code,
when switching languages provides vastly bigger benefits. For example, I threw
together the same algorithms &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/tree/main/2023/prime-sieve/go-with-range-over-func"&gt;using Go&lt;/a&gt;
and its &lt;a class="reference external" href="https://github.com/golang/go/issues/61405"&gt;experimental iterator support&lt;/a&gt;; it's 3x faster than the
Python version, with very little effort (even though the new Go iterators and
&lt;tt class="docutils literal"&gt;yield&lt;/tt&gt; functions are still in the proposal stage and aren't optimized). I
can't try to rewrite it in C++ or Rust for now, due to the lack of generator
support; the &lt;tt class="docutils literal"&gt;yield&lt;/tt&gt; statement is what makes this code so nice and elegant,
and alternative idioms are much less convenient.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="bonus-segmented-sieve-of-eratosthenes"&gt;
&lt;h2&gt;Bonus: segmented sieve of Eratosthenes&lt;/h2&gt;
&lt;p&gt;The Wikipedia article on the sieve of Eratosthenes mentions a &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes#Segmented_sieve"&gt;segmented
approach&lt;/a&gt;, which
is also described in the &lt;a class="reference external" href="https://research.cs.wisc.edu/techreports/1990/TR909.pdf"&gt;Sorenson paper&lt;/a&gt; in section 5.&lt;/p&gt;
&lt;p&gt;The main insight is that we only need the primes up to &lt;object class="valign-m4" data="https://eli.thegreenplace.net/images/math/712f9a224d6c7824add37b6cd766c21f73a40d59.svg" style="height: 18px;" type="image/svg+xml"&gt;\sqrt{n}&lt;/object&gt; to
be able to sieve a table all the way to N. This results in a sieve that uses
only &lt;object class="valign-m5" data="https://eli.thegreenplace.net/images/math/5a41da22acdba46e7c8eeeaddbc58625f49cbfe5.svg" style="height: 19px;" type="image/svg+xml"&gt;O(\sqrt{n})&lt;/object&gt; memory. Here's a commented Python implementation:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;gen_primes_upto_segmented&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Generates a sequence of primes &amp;lt; n.&lt;/span&gt;

&lt;span class="sd"&gt;    Uses the segmented sieve or Eratosthenes algorithm with O(âˆšn) memory.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="c1"&gt;# Simplify boundary cases by hard-coding some small primes.&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt;

    &lt;span class="c1"&gt;# We break the range [0..n) into segments of size âˆšn&lt;/span&gt;
    &lt;span class="n"&gt;segsize&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ceil&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

    &lt;span class="c1"&gt;# Find the primes in the first segment by calling the basic sieve on that&lt;/span&gt;
    &lt;span class="c1"&gt;# segment (its memory usage will be O(âˆšn)). We&amp;#39;ll use these primes to&lt;/span&gt;
    &lt;span class="c1"&gt;# sieve all subsequent segments.&lt;/span&gt;
    &lt;span class="n"&gt;baseprimes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gen_primes_upto&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;segsize&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;bp&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;baseprimes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;bp&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;segstart&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;segsize&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;segsize&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;# Create a new table of size âˆšn for each segment; the old table&lt;/span&gt;
        &lt;span class="c1"&gt;# is thrown away, so the total memory use here is âˆšn&lt;/span&gt;
        &lt;span class="c1"&gt;# seg[i] represents the number segstart+i&lt;/span&gt;
        &lt;span class="n"&gt;seg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;segsize&lt;/span&gt;

        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;bp&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;baseprimes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="c1"&gt;# The first multiple of bp in this segment can be calculated using&lt;/span&gt;
            &lt;span class="c1"&gt;# modulo.&lt;/span&gt;
            &lt;span class="n"&gt;first_multiple&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
                &lt;span class="n"&gt;segstart&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;segstart&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;bp&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="n"&gt;segstart&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;bp&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;segstart&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;bp&lt;/span&gt;
            &lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="c1"&gt;# Mark all multiples of bp in the segment as composite.&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_multiple&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;segstart&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;segsize&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bp&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                &lt;span class="n"&gt;seg&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seg&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;False&lt;/span&gt;

        &lt;span class="c1"&gt;# Sieving is done; yield all composites in the segment (iterating only&lt;/span&gt;
        &lt;span class="c1"&gt;# over the odd ones).&lt;/span&gt;
        &lt;span class="n"&gt;start&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;segstart&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seg&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;seg&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;segstart&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="k"&gt;break&lt;/span&gt;
                &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;segstart&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="code"&gt;
&lt;h2&gt;Code&lt;/h2&gt;
&lt;p&gt;The full code for this post - along with tests and benchmarks - is available
&lt;a class="reference external" href="https://github.com/eliben/code-for-blog/tree/main/2023/prime-sieve"&gt;on GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-1" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;While this is a strong improvement over &lt;tt class="docutils literal"&gt;O(n)&lt;/tt&gt; (e.g. for a billion
primes, memory usage here is only 5% of the full sieve version), it
still depends on the size of the input. In the unlikely event that you
need to generate truly gigantic primes starting from 2, even the
square-root-space solutions become infeasible. In this case, the whole
approach should be changed; instead, one would just generate random huge
numbers and use probabilistic primality testing to check for their
primeness. This is what real libraries like Go's &lt;a class="reference external" href="https://pkg.go.dev/crypto/rand#Prime"&gt;crypto/rand.Prime&lt;/a&gt;
do.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</content><category term="misc"></category><category term="Math"></category><category term="Python"></category><category term="Go"></category></entry><entry><title>GitHub Actions: first impressions</title><link href="https://eli.thegreenplace.net/2020/github-actions-first-impressions/" rel="alternate"></link><published>2020-09-25T20:13:00-07:00</published><updated>2022-10-04T14:08:24-07:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2020-09-25:/2020/github-actions-first-impressions/</id><summary type="html">&lt;p&gt;I've been using &lt;a class="reference external" href="https://travis-ci.com/"&gt;Travis CI&lt;/a&gt; fairly extensively since
2013, when I moved my personal OSS projects &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/06/09/switching-my-open-source-projects-from-bitbucket-to-github"&gt;from Bitbucket to GitHub&lt;/a&gt;.
It's a great service and a much-appreciated boon to the open-source community.&lt;/p&gt;
&lt;p&gt;However, since Travis &lt;a class="reference external" href="https://blog.travis-ci.com/2018-05-02-open-source-projects-on-travis-ci-com-with-github-apps"&gt;announced that their .org variant is shutting down soon&lt;/a&gt;,
I wanted to check out some â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've been using &lt;a class="reference external" href="https://travis-ci.com/"&gt;Travis CI&lt;/a&gt; fairly extensively since
2013, when I moved my personal OSS projects &lt;a class="reference external" href="https://eli.thegreenplace.net/2013/06/09/switching-my-open-source-projects-from-bitbucket-to-github"&gt;from Bitbucket to GitHub&lt;/a&gt;.
It's a great service and a much-appreciated boon to the open-source community.&lt;/p&gt;
&lt;p&gt;However, since Travis &lt;a class="reference external" href="https://blog.travis-ci.com/2018-05-02-open-source-projects-on-travis-ci-com-with-github-apps"&gt;announced that their .org variant is shutting down soon&lt;/a&gt;,
I wanted to check out some of the alternatives, and GitHub actions (GHA) seemed
very interesting.&lt;/p&gt;
&lt;p&gt;So this week I've migrated &lt;a class="reference external" href="https://github.com/eliben/pycparser"&gt;pycparser&lt;/a&gt;
and a few of my other OSS projects over to GHA. This turned out to be very easy!
Here's a brief recap.&lt;/p&gt;
&lt;img alt="GitHub actions icon" class="align-center" src="https://eli.thegreenplace.net/images/2020/gha-icon.png" /&gt;
&lt;div class="section" id="workflow-configuration"&gt;
&lt;h2&gt;Workflow configuration&lt;/h2&gt;
&lt;p&gt;To activate GHA for pycparser, all I had to do is create the following YAML
file as &lt;tt class="docutils literal"&gt;.github/workflows/ci.yml&lt;/tt&gt; in the repository:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;name: pycparser-tests
on:
  push:
    branches:
      - master
  pull_request:
    branches:
      - master

jobs:
  build:

    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        python-version: [2.7, 3.6, 3.7, 3.8]
        os: [ubuntu-latest, macos-latest, windows-latest]

    steps:

    - uses: actions/checkout@v2
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v2
      with:
        python-version: ${{ matrix.python-version }}
    - name: Test
      run: |
        python tests/all_tests.py
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Some notes:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;This workflow fires on two kinds of events: pushes to the master branch and
PRs to the master branch. Each PR will have an automatic CI run for each
change (every new commit pushed).&lt;/li&gt;
&lt;li&gt;It runs in multiple configurations: the cross-product of Python versions and
OSes, as specified.&lt;/li&gt;
&lt;li&gt;The &lt;tt class="docutils literal"&gt;run:&lt;/tt&gt; entry is the command the runs the tests.&lt;/li&gt;
&lt;li&gt;While &lt;tt class="docutils literal"&gt;pycparser&lt;/tt&gt; doesn't have any dependencies, it's easy to have those too
by adding &lt;tt class="docutils literal"&gt;pip install $whatever&lt;/tt&gt; lines to &lt;tt class="docutils literal"&gt;run:&lt;/tt&gt; before the actual test
execution line.&lt;/li&gt;
&lt;/ul&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/2020/gha-badge.svg" type="image/svg+xml"&gt;GitHub tests passed badge&lt;/object&gt;
&lt;/div&gt;
&lt;div class="section" id="first-impressions"&gt;
&lt;h2&gt;First impressions&lt;/h2&gt;
&lt;p&gt;My first impressions of GHA compared to Travis:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Actions run &lt;em&gt;much faster&lt;/em&gt;; the CI jobs schedule pretty much immediately. On
Travis you might have to wait for multiple minutes.&lt;/li&gt;
&lt;li&gt;Out-of-the-box Windows and Mac OS option! I couldn't get these with the free
Travis variant and had to augment my CI solution for pycparser by running on
Windows through &lt;a class="reference external" href="https://www.appveyor.com/"&gt;AppVeyor&lt;/a&gt;. Now I only need
to maintain a single CI workflow.&lt;/li&gt;
&lt;li&gt;Travis seems to have better documentation and configurability at this point;
while the GHA documentation is comprehensive, it's a bit scattered and harder
to follow. This is something I hope will improve over time.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I like what I'm seeing from GHA so far; the ability to set up a CI workflow
very easily without bouncing between multiple Web UIs is a blessing, and GHA
appears to be a capable, performant platform with a convenient selection of
OSes.&lt;/p&gt;
&lt;p&gt;I'm still using Travis for some projects and will continue comparing the two
over the coming months.&lt;/p&gt;
&lt;/div&gt;
</content><category term="misc"></category><category term="Software &amp; Tools"></category><category term="Version control"></category><category term="Python"></category></entry><entry><title>You don't need virtualenv in Go</title><link href="https://eli.thegreenplace.net/2020/you-dont-need-virtualenv-in-go/" rel="alternate"></link><published>2020-06-13T05:41:00-07:00</published><updated>2024-07-04T13:41:09-07:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2020-06-13:/2020/you-dont-need-virtualenv-in-go/</id><summary type="html">&lt;p&gt;Programmers that come to Go from Python often wonder &amp;quot;do I need something like
&lt;a class="reference external" href="https://virtualenv.pypa.io/en/latest/"&gt;virtualenv&lt;/a&gt; here?&amp;quot;&lt;/p&gt;
&lt;p&gt;The short answer is &lt;strong&gt;NO&lt;/strong&gt;; this post will provide some additional details.&lt;/p&gt;
&lt;p&gt;While &lt;tt class="docutils literal"&gt;virtualenv&lt;/tt&gt; in Python is useful in many situations, I think it'd be
fair to divide them into two broad scenarios: for â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Programmers that come to Go from Python often wonder &amp;quot;do I need something like
&lt;a class="reference external" href="https://virtualenv.pypa.io/en/latest/"&gt;virtualenv&lt;/a&gt; here?&amp;quot;&lt;/p&gt;
&lt;p&gt;The short answer is &lt;strong&gt;NO&lt;/strong&gt;; this post will provide some additional details.&lt;/p&gt;
&lt;p&gt;While &lt;tt class="docutils literal"&gt;virtualenv&lt;/tt&gt; in Python is useful in many situations, I think it'd be
fair to divide them into two broad scenarios: for execution and for development.
Let's see what Go offers for each of these scenarios.&lt;/p&gt;
&lt;div class="section" id="execution"&gt;
&lt;h2&gt;Execution&lt;/h2&gt;
&lt;p&gt;There are multiple, mutually-incompatible versions of Python out in the wild.
There are even multiple versions of the packaging tools (like &lt;tt class="docutils literal"&gt;pip&lt;/tt&gt;). On top
of this, different programs need different packages, often themselves with
mutually-incompatible versions.&lt;/p&gt;
&lt;p&gt;Python code typically expects to be &lt;em&gt;installed&lt;/em&gt;, and expects to find packages
it depends on installed in a central location. This can be an issue for systems
where we don't have the permission to install packages/code to a central
location.&lt;/p&gt;
&lt;p&gt;All of this makes distributing Python applications quite tricky. It's common
to use bundling tools like &lt;a class="reference external" href="https://www.pyinstaller.org/"&gt;PyInstaller&lt;/a&gt;, but
&lt;tt class="docutils literal"&gt;virtualenv&lt;/tt&gt; is also a popular option &lt;a class="footnote-reference" href="#footnote-1" id="footnote-reference-1"&gt;[1]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Go is a statically compiled language, so this is a non-problem! Binaries are
easy to build and distribute; the binary is a native executable for a given
platform (just like a native executable built from C or C++ source), and has
no dependencies on compiler or package versions. While you can &lt;em&gt;install&lt;/em&gt; Go
programs into a central location, you by no means have to do this. In fact, you
typically don't have to install Go programs at all. Just invoke the binary.&lt;/p&gt;
&lt;p&gt;It's also worth mentioning that Go has great cross-compilation support, making
it easy to create binaries &lt;a class="reference external" href="https://github.com/golang/go/wiki/WindowsCrossCompiling"&gt;for multiple OSes from a single development machine&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="development"&gt;
&lt;h2&gt;Development&lt;/h2&gt;
&lt;p&gt;Consider the following situation: you're developing a package, which depends on
N other packages at specific versions; e.g. you need package &lt;tt class="docutils literal"&gt;foo&lt;/tt&gt; at version
1.2 or above. Your system may have an older version of &lt;tt class="docutils literal"&gt;foo&lt;/tt&gt; installed - 0.9;
you try to upgrade it to 1.2 and some other program breaks. Now, this all sounds
very manageable for package &lt;tt class="docutils literal"&gt;foo&lt;/tt&gt; - how hard can it be to upgrade the uses of
this simple package?&lt;/p&gt;
&lt;p&gt;Reality is more difficult. &lt;tt class="docutils literal"&gt;foo&lt;/tt&gt; could be Django; your code depends on
a new version, while some other critical systems depend on an old version. Good
luck fixing this conundrum. In Python, &lt;tt class="docutils literal"&gt;viruatenv&lt;/tt&gt; is a critical tool to make
such situations manageable; newer tools like &lt;a class="reference external" href="https://pypi.org/project/pipenv/"&gt;pipenv&lt;/a&gt; wrap &lt;tt class="docutils literal"&gt;virtualenv&lt;/tt&gt; with more usability
patterns.&lt;/p&gt;
&lt;p&gt;How about Go?&lt;/p&gt;
&lt;p&gt;If you're using Go modules, this situation is very easy to handle. In a way,
a Go module serves as its own &lt;tt class="docutils literal"&gt;virtualenv&lt;/tt&gt;. Your &lt;tt class="docutils literal"&gt;go.mod&lt;/tt&gt; file specifies the
exact versions of dependency packages needed for your development, and these
versions don't mix up with packages you need to develop some other project
(which has its own &lt;tt class="docutils literal"&gt;go.mod&lt;/tt&gt;).&lt;/p&gt;
&lt;p&gt;Moreover, Go module directives like &lt;tt class="docutils literal"&gt;replace&lt;/tt&gt; make it easy to short-circuit
dependencies to try local patches. While debugging your project you find that
package &lt;tt class="docutils literal"&gt;foo&lt;/tt&gt; has a bug that may be affecting you? Want to try a quick fix and
see if you're right? No problem, just clone &lt;tt class="docutils literal"&gt;foo&lt;/tt&gt; locally, apply a fix, and
use a &lt;tt class="docutils literal"&gt;replace&lt;/tt&gt; to use this locally patched &lt;tt class="docutils literal"&gt;foo&lt;/tt&gt;. See
&lt;a class="reference external" href="https://eli.thegreenplace.net/2024/locally-patching-dependencies-in-go/"&gt;this post&lt;/a&gt;
for a few ways to automate this process.&lt;/p&gt;
&lt;p&gt;What about different Go versions? Suppose you have to investigate a user report
complaining that your code doesn't work with an older Go version. Or maybe
you're curious to see how the upcoming beta release of a Go version will affect
you. Go makes it easy to &lt;a class="reference external" href="https://golang.org/doc/install#extra_versions"&gt;install different versions locally&lt;/a&gt;. These different versions have
their own standard libraries that won't interfere with each other.&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-1" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Fun fact: &lt;a class="reference external" href="https://eli.thegreenplace.net/2014/blogging-setup-with-pelican/"&gt;this blog uses&lt;/a&gt;
the Pelican static site generator. To regenerate the site I run Pelican
in a &lt;tt class="docutils literal"&gt;virtualenv&lt;/tt&gt; because I need a specific version of Pelican with some
personal patches.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</content><category term="misc"></category><category term="Go"></category><category term="Python"></category></entry><entry><title>Faster XML stream processing in Go</title><link href="https://eli.thegreenplace.net/2019/faster-xml-stream-processing-in-go/" rel="alternate"></link><published>2019-07-22T05:37:00-07:00</published><updated>2024-05-04T19:46:23-07:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2019-07-22:/2019/faster-xml-stream-processing-in-go/</id><summary type="html">&lt;p&gt;XML processing was all the rage 15 years ago; while it's less
prominent these days, it's still an important task in some application domains.
In this post I'm going to compare the speed of stream-processing huge XML files
in Go, Python and C and finish up with a new, minimal â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;XML processing was all the rage 15 years ago; while it's less
prominent these days, it's still an important task in some application domains.
In this post I'm going to compare the speed of stream-processing huge XML files
in Go, Python and C and finish up with a new, minimal module that uses C to
accelerate this task for Go. All the code shown throughout this post is
available &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/tree/main/2019/xml-stream"&gt;in this GitHub repository&lt;/a&gt; the new
Go module &lt;a class="reference external" href="https://github.com/eliben/gosax"&gt;is here&lt;/a&gt;.&lt;/p&gt;
&lt;div class="section" id="what-does-xml-stream-processing-mean"&gt;
&lt;h2&gt;What does XML stream processing mean?&lt;/h2&gt;
&lt;p&gt;First, let's define the problem at hand in more detail. Roughly speaking, there
are two ways we can process data from a file:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Read the whole file into memory at once, and then proces the data in
memory.&lt;/li&gt;
&lt;li&gt;Read the file in chunks, process each chuck, without having the whole data
in memory at any given time.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In many ways, (1) is more convenient because we can easily go back to any part
of the file. However, in some situations (2) is essential; specifically, when
the file is very large. This is where &lt;em&gt;stream&lt;/em&gt; processing comes in. If our input
file is 500 GiB, we're unlikely to be able to read it into memory and have to
process it in parts. Even for smaller files that would theoretically fit into
RAM, it's not always a good idea to read them wholly; this dramatically
increases the active heap size and can cause performance issues in
garbage-collected languages.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-task"&gt;
&lt;h2&gt;The task&lt;/h2&gt;
&lt;p&gt;For this benchmark, I'm using &lt;a class="reference external" href="https://github.com/eliben/xmlgen"&gt;xmlgen&lt;/a&gt; to
create a 230 MiB XML file &lt;a class="footnote-reference" href="#footnote-1" id="footnote-reference-1"&gt;[1]&lt;/a&gt;. A tiny fragment of the file may look like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;lt;?xml version=&amp;quot;1.0&amp;quot; standalone=&amp;quot;yes&amp;quot;?&amp;gt;
&amp;lt;site&amp;gt;
  &amp;lt;regions&amp;gt;
    &amp;lt;asia&amp;gt;
      &amp;lt;item id=&amp;quot;item0&amp;quot;&amp;gt;
        &amp;lt;location&amp;gt;United States&amp;lt;/location&amp;gt;
        &amp;lt;quantity&amp;gt;1&amp;lt;/quantity&amp;gt;
        &amp;lt;name&amp;gt;duteous nine eighteen &amp;lt;/name&amp;gt;
        &amp;lt;payment&amp;gt;Creditcard&amp;lt;/payment&amp;gt;
        ...
      &amp;lt;/item&amp;gt;
    &amp;lt;/asia&amp;gt;
  &amp;lt;/regions&amp;gt;
&amp;lt;/site&amp;gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The task is to find how many times &amp;quot;Africa&amp;quot; appears in the data of the
&lt;tt class="docutils literal"&gt;&amp;lt;location&amp;gt;&lt;/tt&gt; tag throughout the document.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="baseline-using-the-go-standard-library"&gt;
&lt;h2&gt;Baseline - using the Go standard library&lt;/h2&gt;
&lt;p&gt;Let's start with a baseline implementation - using the standard library's
&lt;tt class="docutils literal"&gt;encoding/xml&lt;/tt&gt; package. While the package's &lt;tt class="docutils literal"&gt;Unmarshal&lt;/tt&gt; mode will parse the
whole file in one go, it can also be used to process XML token by token and
selectively parse interesting elements. Here is the code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;package&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;main&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;encoding/xml&amp;quot;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;fmt&amp;quot;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;io&amp;quot;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;log&amp;quot;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;os&amp;quot;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;strings&amp;quot;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="kd"&gt;type&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;location&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;struct&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;Data&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;string&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;`xml:&amp;quot;,chardata&amp;quot;`&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="kd"&gt;func&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;os&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;os&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;!=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;nil&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Fatal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;defer&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;f&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;d&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;xml&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;NewDecoder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;count&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nx"&gt;tok&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;d&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Token&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;tok&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;nil&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;||&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;io&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;EOF&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="c1"&gt;// EOF means we&amp;#39;re done.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;!=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;nil&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Fatalf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Error decoding token: %s&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;switch&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;ty&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;tok&lt;/span&gt;&lt;span class="p"&gt;.(&lt;/span&gt;&lt;span class="kd"&gt;type&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;xml&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;StartElement&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;ty&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Name&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Local&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;location&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="c1"&gt;// If this is a start element named &amp;quot;location&amp;quot;, parse this element&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="c1"&gt;// fully.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="kd"&gt;var&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;loc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;location&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;d&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;DecodeElement&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="nx"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="nx"&gt;ty&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;!=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;nil&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;          &lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Fatalf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Error decoding item: %s&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;strings&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Contains&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Africa&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;          &lt;/span&gt;&lt;span class="nx"&gt;count&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;default&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;fmt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;count =&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;count&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I made sure to double check that the memory usage of this program stays bounded
and low while processing a large file - the maximum RSS was under 7 MiB while
processing our 230 MiB input file. I'm verifying this for all the programs
presented in this post using &lt;tt class="docutils literal"&gt;/usr/bin/time &lt;span class="pre"&gt;-v&lt;/span&gt;&lt;/tt&gt; on Linux.&lt;/p&gt;
&lt;p&gt;This program takes 6.24 seconds to process the whole file and print out the
result.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="python-implementation"&gt;
&lt;h2&gt;Python implementation&lt;/h2&gt;
&lt;p&gt;The first Python implementation uses the &lt;tt class="docutils literal"&gt;xml.etree.ElementTree&lt;/tt&gt; module from
the standard library:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;xml.etree.ElementTree&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;ET&lt;/span&gt;

&lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;elem&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;ET&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iterparse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;events&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;end&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,)):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;event&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;end&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;elem&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tag&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;location&amp;#39;&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;elem&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Africa&amp;#39;&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;elem&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="n"&gt;elem&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clear&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;count =&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The key here is the &lt;tt class="docutils literal"&gt;elem.clear()&lt;/tt&gt; call. It ensures that each element gets
discarded afer parsing it fully, so the memory usage won't grow linearly with
the size of the file (unless the file is pathological). This program takes 3.7
seconds to process the whole file - much faster than our Go program. Why is
that?&lt;/p&gt;
&lt;p&gt;While the Go program uses 100% Go code for the task (&lt;tt class="docutils literal"&gt;encoding/xml&lt;/tt&gt; is
implemented entirely in Go), the Python program is using a C extension (most of
&lt;tt class="docutils literal"&gt;ElementTree&lt;/tt&gt; is written in C) wrapping a fast XML parser in C - &lt;a class="reference external" href="https://github.com/libexpat/libexpat"&gt;libexpat&lt;/a&gt;. The bulk of the work here is done in
C, which is faster than Go.
The performance of &lt;tt class="docutils literal"&gt;encoding/xml&lt;/tt&gt; is further discussed in
&lt;a class="reference external" href="https://github.com/golang/go/issues/21823"&gt;this issue&lt;/a&gt;, though it's an
old one and the performance has been somewhat optimized since then.&lt;/p&gt;
&lt;p&gt;An alternative XML parsing library for Python is &lt;a class="reference external" href="https://github.com/lxml/lxml"&gt;lxml&lt;/a&gt;,
which uses &lt;a class="reference external" href="https://www.xmlsoft.org/"&gt;libxml&lt;/a&gt; underneath. Here's a Python
version using lxml:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;lxml&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;etree&lt;/span&gt;

&lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;elem&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;etree&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iterparse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;events&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;end&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,)):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;event&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;end&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;elem&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tag&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;location&amp;#39;&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;elem&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Africa&amp;#39;&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;elem&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="n"&gt;elem&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clear&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;count =&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This looks very similar to the previous version, and that's on purpose. lxml
has an &lt;tt class="docutils literal"&gt;etree&lt;/tt&gt;-compatible API to make transition from the standard library
smoother. This version also takes around 3.7 seconds for our 230 MiB file.&lt;/p&gt;
&lt;p&gt;The reason I'm including lxml here is that it will run faster than
&lt;tt class="docutils literal"&gt;xml.etree.ElementTree&lt;/tt&gt; when slurping the whole file, for our particular file
size. I want to highlight that this is outside of the scope for my experiment,
because I only care about streaming processing. The only way (that I'm aware
of!) to successfully process a 500 GiB file with lxml would be by using
&lt;tt class="docutils literal"&gt;iterparse&lt;/tt&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="how-fast-can-it-run"&gt;
&lt;h2&gt;How fast can it run?&lt;/h2&gt;
&lt;p&gt;Based on the measurements presented here, Go is about 68% slower than Python for
parsing a large XML file in a streaming fashion. While Go usually compiles to
a much faster code than pure Python, the Python implementations have the backing
of efficient C libraries with which it's difficult to compete. I was curious
to know how fast it could be, in theory &lt;a class="footnote-reference" href="#footnote-2" id="footnote-reference-2"&gt;[2]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To answer this question, I implemented the same program using pure C with
libxml, which has a &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Simple_API_for_XML"&gt;SAX API&lt;/a&gt;. I won't paste it wholly
here because it's longer, but you can find the &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/tree/main/2019/xml-stream/c-libxmlsax-count"&gt;full source code on GitHub&lt;/a&gt;.
It takes just 0.56 seconds to process our 230 MiB input file, which is very
impressive given the other results, but also not very surprising. This is C,
after all.&lt;/p&gt;
&lt;p&gt;You may wonder - if lxml uses libxml underneath, why is it so much slower than
the pure C version? The answer is Python call overhead. The lxml version calls
back into Python &lt;em&gt;for every parsed element&lt;/em&gt;, which incurs a significant
cost &lt;a class="footnote-reference" href="#footnote-3" id="footnote-reference-3"&gt;[3]&lt;/a&gt;. Another reason is that my C implementation doesn't actually parse an
element - it's just a simple event-based state machine, so there's less extra
work being done.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="using-libxml-from-go"&gt;
&lt;h2&gt;Using libxml from Go&lt;/h2&gt;
&lt;p&gt;To recap where we are so far:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Python libraries based on underlying C implementations are faster than
pure Go.&lt;/li&gt;
&lt;li&gt;Pure C is much faster still.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We have two options: we can either try to optimize Go's &lt;tt class="docutils literal"&gt;encoding/xml&lt;/tt&gt;
package, or we can try to wrap a fast C library with Go. While the former is a
worthy goal, it involves a large effort and should be a topic for a separate
post. Here, I'll go for the latter.&lt;/p&gt;
&lt;p&gt;Seaching around the web, I found a few wrappers around libxml. Two that seemed
moderately popular and maintained are &lt;a class="reference external" href="https://github.com/lestrrat-go/libxml2"&gt;https://github.com/lestrrat-go/libxml2&lt;/a&gt;
and &lt;a class="reference external" href="https://github.com/moovweb/gokogiri"&gt;https://github.com/moovweb/gokogiri&lt;/a&gt;. Unfortunately, neither of these (or
the other bindings I found) are exposing the SAX API of libxml; instead, they
focus on the DOM API, where the whole document is parsed by the underlying
library and a tree is returned. As mentioned above, we need the SAX interface
to process huge files.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="gosax"&gt;
&lt;h2&gt;gosax&lt;/h2&gt;
&lt;p&gt;It's time to roll our own :-) I wrote the &lt;a class="reference external" href="https://github.com/eliben/gosax"&gt;gosax&lt;/a&gt; module, which uses Cgo to call into libxml
and exposes a SAX interface &lt;a class="footnote-reference" href="#footnote-4" id="footnote-reference-4"&gt;[4]&lt;/a&gt;. Implementing it was an interesting exercise
in Cgo, because it requires some non-trivial concepts like
&lt;a class="reference external" href="https://eli.thegreenplace.net/2019/passing-callbacks-and-pointers-to-cgo/"&gt;registering Go callbacks with C&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here's a version of our program using gosax:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;package&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;main&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;fmt&amp;quot;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;os&amp;quot;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;strings&amp;quot;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;github.com/eliben/gosax&amp;quot;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="kd"&gt;func&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;counter&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;inLocation&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;scb&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;gosax&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;SaxCallbacks&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nx"&gt;StartElement&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;name&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;string&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;attrs&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt;&lt;span class="kt"&gt;string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;name&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;location&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nx"&gt;inLocation&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nx"&gt;inLocation&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nx"&gt;EndElement&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;name&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nx"&gt;inLocation&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nx"&gt;Characters&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;contents&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;inLocation&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;strings&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Contains&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;contents&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Africa&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nx"&gt;counter&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;gosax&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;ParseFile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;os&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;scb&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;!=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;nil&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;panic&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;fmt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;counter =&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;counter&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As you can see, it implements a state machine that remembers being inside
a &lt;tt class="docutils literal"&gt;location&lt;/tt&gt; element, where the character data is checked. This program
takes 4.03 seconds to process our input file. Not bad! But we can do a bit
better, and &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/blob/main/2019/xml-stream/gosax-count/gosax-count.go"&gt;with a couple of optimizations&lt;/a&gt;
I managed to bring it down to 3.68 seconds - about the same speed as the Python
implementations!&lt;/p&gt;
&lt;p&gt;IMHO the roughly similar run times here are a coincidence, because the Python
programs are different from my approach in that they expose a higher-level API
than pure SAX. Recall that &lt;tt class="docutils literal"&gt;iterparse&lt;/tt&gt; returns a parsed element, and we
can access its &lt;tt class="docutils literal"&gt;text&lt;/tt&gt; attribute, etc. In gosax, we have to do this much more
manually. Since the the &lt;a class="reference external" href="https://about.sourcegraph.com/go/gophercon-2018-adventures-in-cgo-performance"&gt;cost of calls between Cgo and Go is rather high&lt;/a&gt;,
there is an optimization opportunity here for gosax. We could do more work in
C - parsing a full element, and returning it wholly to Go. This would move work
from the Go side to the C side, as well as reduce the number of cross-language
calls. But this is a task for another day.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Well, this was fun :-) There are 5 different implementations of the same simple
task described here, in 3 different programming languages. Here is a summary
of the speed measurements we got:&lt;/p&gt;
&lt;img alt="Performance comparison chart" class="align-center" src="https://eli.thegreenplace.net/images/2019/xml-sax-comparison.png" /&gt;
&lt;p&gt;Python's performance story has always been - &amp;quot;it's probably fast enough, and in
the rare cases where it isn't, use a C extension&amp;quot;. In Go the narrative is
somewhat different: in most cases, the Go compiler produces fairly fast code.
Pure Go code is significantly faster than Python and often faster than Java.
Even so, every once in a while it may be useful to dip into C or C++ for
performance, and in these cases Cgo is a good approach.&lt;/p&gt;
&lt;p&gt;It's obvious that &lt;tt class="docutils literal"&gt;encoding/xml&lt;/tt&gt; &lt;a class="reference external" href="https://github.com/golang/go/issues/21823"&gt;needs some work w.r.t. performance&lt;/a&gt;, but until that happens - there
are good alternatives! Leveraging the speed of libxml has been possible for the
DOM API, and now is possible for the SAX API as well. In the long run, I believe
that serious performance work on &lt;tt class="docutils literal"&gt;encoding/xml&lt;/tt&gt; can make it go faster than
the libxml wrappers because it would elimitate the high cost of C-to-Go calls.&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-1" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;This size will easily fit in RAM, but it's good enough to provide a
meaningful benchmarking duration.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-2" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-2"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;When working on optimizations, it's often useful to know &amp;quot;the speed
of light&amp;quot; of some computation. Say we want to optimize some function in
our program. It's worth asking - how much faster will the program be if
this function takes 0 time? If the overall change is tiny, the function
is not worth optimizing, most likely. This is just a practical
application of Amdahl's law.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-3" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-3"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;We can test this hypothesis by timing how long it takes the non-streaming
API in lxml to parse the same file. Since it parses the whole XML file
in C before returning the parsed structure to Python, we expect the
Python call overhead to be much smaller. Indeed, for files that fit into
memory this is faster. But once again, in this post we return our
attention to streaming APIs - assuming this is our only choice for
gigantic files.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-4" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-4"&gt;[4]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;gosax is very minimal, only providing the most common SAX callbacks.
The decision to create a new module was just for convenience and speed;
the more correct thing would have likely been to contribute to one of
the existing libxml wrappers. I don't see gosax as production-quality
at this stage - I just hacked it together to be able to experiment for
this post.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</content><category term="misc"></category><category term="Go"></category><category term="C &amp; C++"></category><category term="Python"></category></entry><entry><title>Type erasure and reification</title><link href="https://eli.thegreenplace.net/2018/type-erasure-and-reification/" rel="alternate"></link><published>2018-12-05T05:10:00-08:00</published><updated>2023-02-04T13:41:52-08:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2018-12-05:/2018/type-erasure-and-reification/</id><summary type="html">&lt;p&gt;In this post I'd like to discuss the concepts of &lt;em&gt;type erasure&lt;/em&gt; and
&lt;em&gt;reification&lt;/em&gt; in programming languages. I don't intend to dive very deeply into
the specific rules of any particular language; rather, the post is going to
present several simple examples in multiple languages, hoping to provide enough
intuition â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this post I'd like to discuss the concepts of &lt;em&gt;type erasure&lt;/em&gt; and
&lt;em&gt;reification&lt;/em&gt; in programming languages. I don't intend to dive very deeply into
the specific rules of any particular language; rather, the post is going to
present several simple examples in multiple languages, hoping to provide enough
intuition and background for a more serious study, if necessary. As you'll
see, the actual concepts are very simple and familiar. Deeper details of
specific languages pertain more to the idiosyncrasies of those languages'
semantics and implementations.&lt;/p&gt;
&lt;p&gt;Important note: in C++ there is a programming pattern called &lt;em&gt;type erasure&lt;/em&gt;,
which is quite distinct from what I'm trying to describe here &lt;a class="footnote-reference" href="#footnote-1" id="footnote-reference-1"&gt;[1]&lt;/a&gt;. I'll be
using C++ examples here, but that's to demonstrate how the original concepts
apply in C++. The programming pattern will be covered in a separate post.&lt;/p&gt;
&lt;div class="section" id="types-at-compile-time-no-types-at-run-time"&gt;
&lt;h2&gt;Types at compile time, no types at run-time&lt;/h2&gt;
&lt;p&gt;The title of this section is a &amp;quot;one short sentence&amp;quot; explanation of what type
erasure means. With few exceptions, it only applies to languages with some
degree of compile time (a.k.a. &lt;em&gt;static&lt;/em&gt;) type checking. The basic principle
should be immediately familiar to folks who have some idea of what machine code
generated from low-level languages like C looks like. While C has static typing,
this only matters in the compiler - the generated code is completely oblivious
to types.&lt;/p&gt;
&lt;p&gt;For example, consider the following C snippet:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;typedef&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;Frob_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;arr&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Frob&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;extract&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Frob&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;frob&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;frob&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;frob&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;arr&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When compiling the function &lt;tt class="docutils literal"&gt;extract&lt;/tt&gt;, the compiler will perform type
checking. It won't let us access fields that were not declared in the struct,
for example. Neither will it let us pass a pointer to a different struct (or to
a &lt;tt class="docutils literal"&gt;float&lt;/tt&gt;) into &lt;tt class="docutils literal"&gt;extract&lt;/tt&gt;. But once it's done helping us, the compiler
generates code which is completely type-free:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;0:   8b 47 04                mov    0x4(%rdi),%eax
3:   0f af 47 24             imul   0x24(%rdi),%eax
7:   c3                      retq
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The compiler is familiar with the &lt;a class="reference external" href="https://eli.thegreenplace.net/2011/09/06/stack-frame-layout-on-x86-64/"&gt;stack frame layout&lt;/a&gt; and
other specifics of the ABI, and generates code that assumes a correct type of
structure was passed in. If the actual type is not what this function expects,
there will be trouble (either accessing unmapped memory, or accessing wrong
data).&lt;/p&gt;
&lt;p&gt;A slightly adjusted example will clarify this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;extract_cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Frob&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;frob&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;frob&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;frob&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;arr&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The compiler will generate exactly identical code from this function, which in
itself a good indication of when the types matter and when they don't. What's
more interesting is that &lt;tt class="docutils literal"&gt;extract_cast&lt;/tt&gt; makes it extremely easy for
programmers to shoot themselves in the foot:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;SomeOtherStruct&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ss&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;extract_cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;ss&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;// oops&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In general, &lt;em&gt;type erasure&lt;/em&gt; is a concept that descibes these semantics of a
language. Types matter to the compiler, which uses them to generate code and
help the programmer avoid errors. Once everything is type-checked, however, the
types are simply &lt;em&gt;erased&lt;/em&gt; and the code the compiler generates is oblivious to
them. The next section will put this in context by comparing to the opposite
approach.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="reification-retaining-types-at-run-time"&gt;
&lt;h2&gt;Reification - retaining types at run-time&lt;/h2&gt;
&lt;p&gt;While erasure means the compiler discards all type information for the actual
generated code, &lt;em&gt;reification&lt;/em&gt; is the other way to go - types are retained at
run-time and used for perform various checks. A classical example from Java will
help demonstrate this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Main&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;static&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;strings&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;a&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;b&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;Object&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;strings&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This code creates an array of &lt;tt class="docutils literal"&gt;String&lt;/tt&gt;, and converts it to a generic array of
&lt;tt class="docutils literal"&gt;Object&lt;/tt&gt;. This is valid because arrays in Java
&lt;a class="reference external" href="https://eli.thegreenplace.net/2018/covariance-and-contravariance-in-subtyping/"&gt;are covariant&lt;/a&gt;,
so the compiler doesn't complain. However, in the next line we try to assign
an integer into the array. This happens to fail with an exception &lt;em&gt;at run-time&lt;/em&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Exception in thread &amp;quot;main&amp;quot; java.lang.ArrayStoreException: java.lang.Integer
    at Main.main(Main.java:5)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;A type check was inserted into the generated code, and it fired when an
incorrect assignment was attempted. In other words, the type of &lt;tt class="docutils literal"&gt;objects&lt;/tt&gt; is
&lt;em&gt;reified&lt;/em&gt;. Reification is defined roughly as &amp;quot;taking something abstract and
making it real/concrete&amp;quot;, which when applied to types means &amp;quot;compile-time types
are converted to actual run-time entities&amp;quot;.&lt;/p&gt;
&lt;p&gt;C++ has some type reification support as well, e.g. with &lt;tt class="docutils literal"&gt;dynamic_cast&lt;/tt&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;Base&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;virtual&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;basefunc&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;basefunc&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;};&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="k"&gt;struct&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;Derived&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;public&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Base&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;derivedfunc&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;derived&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;};&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;call_derived&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Base&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Derived&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;dynamic_cast&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Derived&lt;/span&gt;&lt;span class="o"&gt;*&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;!=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;nullptr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;derivedfunc&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;cast failed&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We can call &lt;tt class="docutils literal"&gt;call_derived&lt;/tt&gt; thus:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Derived&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;call_derived&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Base&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;call_derived&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The first call will successfully invoke &lt;tt class="docutils literal"&gt;derivedfunc&lt;/tt&gt;; the second will not,
because the &lt;tt class="docutils literal"&gt;dynamic_cast&lt;/tt&gt; will return &lt;tt class="docutils literal"&gt;nullptr&lt;/tt&gt; at run-time. This is
because we're using C++'s &lt;em&gt;run-time type information&lt;/em&gt; (RTTI) capabilities here,
where an actual representation of the type is stored in the generated code (most
likely attached to the vtable which every polymorphic object points to). C++
also has the &lt;tt class="docutils literal"&gt;typeid&lt;/tt&gt; feature, but I'm showing &lt;tt class="docutils literal"&gt;dynamic_cast&lt;/tt&gt; since it's the
one most commonly used.&lt;/p&gt;
&lt;p&gt;Note particularly the differences between this sample and the C sample in the
beginning of the post. Conceptually, it's similar - we use a pointer to a
general type (in C that's &lt;tt class="docutils literal"&gt;void*&lt;/tt&gt;, in the C++ example we use a base type) to
interact with concrete types. Whereas in C there is no built-in run-time type
feature, in C++ we can use RTTI in some cases. With RTTI enabled,
&lt;tt class="docutils literal"&gt;dynamic_cast&lt;/tt&gt; can be used to interact with the run-time (reified)
representation of types in a limited but useful way.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="type-erasure-and-java-generics"&gt;
&lt;h2&gt;Type erasure and Java generics&lt;/h2&gt;
&lt;p&gt;One place where folks not necessarily familiar with programming language type
theory encounter erasure is Java generics, which were bolted onto the language
after a large amount of code has already been written. The designers of Java
faced the binary compatibility challenge, wherein they wanted code compiled with
newer Java compilers to run on older VMs.&lt;/p&gt;
&lt;p&gt;The solution was to use type erasure to implement generics entirely in the
compiler. Here's a quote from the &lt;a class="reference external" href="https://docs.oracle.com/javase/tutorial/java/generics/erasure.html"&gt;official Java generics tutorial&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Generics were introduced to the Java language to provide tighter type checks
at compile time and to support generic programming. To implement generics, the
Java compiler applies type erasure to:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Replace all type parameters in generic types with their bounds or Object if
the type parameters are unbounded. The produced bytecode, therefore,
contains only ordinary classes, interfaces, and methods.&lt;/li&gt;
&lt;li&gt;Insert type casts if necessary to preserve type safety.&lt;/li&gt;
&lt;li&gt;Generate bridge methods to preserve polymorphism in extended generic types.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;Here's a very simple example to demonstrate what's going on, taken from
&lt;a class="reference external" href="https://stackoverflow.com/a/339708/8206"&gt;a Stack Overflow answer&lt;/a&gt;. This code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;java.util.List&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;java.util.ArrayList&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Main&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;static&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;list&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;new&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ArrayList&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;list&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Hi&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;list&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Uses a generic &lt;tt class="docutils literal"&gt;List&lt;/tt&gt;. However, what the compiler creates prior to emitting
bytecode is equivalent to:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;java.util.List&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;java.util.ArrayList&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Main&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;static&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;list&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;new&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ArrayList&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;list&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Hi&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;list&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here &lt;tt class="docutils literal"&gt;List&lt;/tt&gt; is a container of &lt;tt class="docutils literal"&gt;Object&lt;/tt&gt;, so we can assign any element to it
(similarly to the reification example shown in the previous section). The
compiler then inserts a cast when accessing that element as a string. In this
case the compiler will adamantly preserve type safety and won't let us do
&lt;tt class="docutils literal"&gt;list.add(5)&lt;/tt&gt; in the original snippet, because it sees that &lt;tt class="docutils literal"&gt;list&lt;/tt&gt; is a
&lt;tt class="docutils literal"&gt;List&amp;lt;String&amp;gt;&lt;/tt&gt;. Therefore, the cast to &lt;tt class="docutils literal"&gt;(String)&lt;/tt&gt; should be safe.&lt;/p&gt;
&lt;p&gt;Using type erasure to implement generics with backwards compatibility is a neat
idea, but it has its issues. Some folks complain that not having the types
available at runtime is a limitation (e.g. not being able to use &lt;tt class="docutils literal"&gt;instanceof&lt;/tt&gt;
and other reflection capabilities). Other languages, like C# and Dart 2, have
&lt;em&gt;reified generics&lt;/em&gt; which do preserve the type information at run-time.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="reification-in-dynamically-typed-languages"&gt;
&lt;h2&gt;Reification in dynamically typed languages&lt;/h2&gt;
&lt;p&gt;I hope it's obvious that the theory and techniques described above only apply
to statically-typed languages. In dynamically-typed languages, like Python,
there is almost no concept of types at compile-time, and types are a fully
reified concept. Even trivial errors like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Foo&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;bar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="k"&gt;pass&lt;/span&gt;

&lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Foo&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;joe&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;         &lt;span class="c1"&gt;# &amp;lt;--- calling non-existent method&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Fire at run-time, because there's no static type checking &lt;a class="footnote-reference" href="#footnote-2" id="footnote-reference-2"&gt;[2]&lt;/a&gt;. Types obviously
exist at run-time, with functions like &lt;tt class="docutils literal"&gt;type()&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;isinstance()&lt;/tt&gt; providing
complete reflection capabilities. The &lt;tt class="docutils literal"&gt;type()&lt;/tt&gt; function can even create new
types &lt;a class="reference external" href="https://eli.thegreenplace.net/2012/04/16/python-object-creation-sequence"&gt;entirely at run-time&lt;/a&gt;.&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-1" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;But it's most likely what you'll get to if you google for
&amp;quot;c++ type erasure&amp;quot;.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-2" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-2"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;To be clear - this is not a bug; it's a feature of Python. A new method
can be added to classes dynamically at runtime (here, some code could
have defined a &lt;tt class="docutils literal"&gt;joe&lt;/tt&gt; method for &lt;tt class="docutils literal"&gt;Foo&lt;/tt&gt; before the &lt;tt class="docutils literal"&gt;f.joe()&lt;/tt&gt;
invocation), and the compiler has absolutely no way of knowing this could
or couldn't happen. So it has to assume such invocations are valid and
rely on run-time checking to avoid serious errors like memory corruption.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</content><category term="misc"></category><category term="Programming"></category><category term="C &amp; C++"></category><category term="Python"></category></entry><entry><title>Type inference</title><link href="https://eli.thegreenplace.net/2018/type-inference/" rel="alternate"></link><published>2018-11-14T06:16:00-08:00</published><updated>2024-05-04T19:46:23-07:00</updated><author><name>Eli Bendersky</name></author><id>tag:eli.thegreenplace.net,2018-11-14:/2018/type-inference/</id><summary type="html">&lt;p&gt;Type inference is a major feature of several programming languages, most notably
languages from the ML family like Haskell. In this post I want to provide a
brief overview of type inference, along with a simple Python implementation for
a toy ML-like language.&lt;/p&gt;
&lt;div class="section" id="uni-directional-type-inference"&gt;
&lt;h2&gt;Uni-directional type inference&lt;/h2&gt;
&lt;p&gt;While static typing is â€¦&lt;/p&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;Type inference is a major feature of several programming languages, most notably
languages from the ML family like Haskell. In this post I want to provide a
brief overview of type inference, along with a simple Python implementation for
a toy ML-like language.&lt;/p&gt;
&lt;div class="section" id="uni-directional-type-inference"&gt;
&lt;h2&gt;Uni-directional type inference&lt;/h2&gt;
&lt;p&gt;While static typing is very useful, one of its potential downsides is verbosity.
The programmer has to annotate values with types throughout the code, which
results in more effort and clutter. What's really annoying, though, is that in
many cases these annotations feel superfluous. Consider this classical C++
example from pre-C++11 times:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;vector&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Blob&lt;/span&gt;&lt;span class="o"&gt;*&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;blobs&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;vector&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Blob&lt;/span&gt;&lt;span class="o"&gt;*&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;iterator&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;iter&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;blobs&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;begin&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Clearly when the compiler sees &lt;tt class="docutils literal"&gt;blobs.begin()&lt;/tt&gt;, it knows the type of
&lt;tt class="docutils literal"&gt;blobs&lt;/tt&gt;, so it also knows the type of the &lt;tt class="docutils literal"&gt;begin()&lt;/tt&gt; method invoked on it
because it is familiar with the declaration of &lt;tt class="docutils literal"&gt;begin&lt;/tt&gt;. Why should the
programmer be burdened with spelling out the type of the iterator? Indeed, one
of the most welcome changes in C++11 was lifting this burden by repurposing
&lt;tt class="docutils literal"&gt;auto&lt;/tt&gt; for basic type inference:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;vector&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Blob&lt;/span&gt;&lt;span class="o"&gt;*&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;blobs&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;auto&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;iter&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;blobs&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;begin&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Go has a similar capability with the &lt;tt class="docutils literal"&gt;:=&lt;/tt&gt; syntax. Given some function:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;func&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;parseThing&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;Node&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;error&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We can simply write:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nx"&gt;node&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;parseThing&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Without having to explicitly declare that &lt;tt class="docutils literal"&gt;node&lt;/tt&gt; has type &lt;tt class="docutils literal"&gt;Node&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;err&lt;/tt&gt;
has type &lt;tt class="docutils literal"&gt;error.&lt;/tt&gt;&lt;/p&gt;
&lt;p&gt;These features are certainly useful, and they involve some degree of type
inference from the compiler. Some functional programming proponents say this is
not &lt;em&gt;real&lt;/em&gt; type inference, but I think the difference is just a matter of
degree. There's certainly &lt;em&gt;some&lt;/em&gt; inference going on here, with the compiler
calculating and assigning the right types for expressions without the
programmer's help. Since this calculation flows in one direction (from the
declaration of the &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;vector::begin&lt;/span&gt;&lt;/tt&gt; method to the &lt;tt class="docutils literal"&gt;auto&lt;/tt&gt; assignment), I'll
call it &lt;em&gt;uni-directional&lt;/em&gt; type inference &lt;a class="footnote-reference" href="#footnote-1" id="footnote-reference-1"&gt;[1]&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="bi-directional-type-inference-hindley-milner"&gt;
&lt;h2&gt;Bi-directional type inference (Hindley-Milner)&lt;/h2&gt;
&lt;p&gt;If we define a new &lt;tt class="docutils literal"&gt;map&lt;/tt&gt; function in Haskell to map a function over a list,
we can do it as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nf"&gt;mymap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;[]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ow"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;[]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nf"&gt;mymap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="kt"&gt;:&lt;/span&gt;&lt;span class="n"&gt;rest&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ow"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mymap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;rest&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that we did not specify the types for either the arguments of
&lt;tt class="docutils literal"&gt;mymap&lt;/tt&gt;, or its return value. The Haskell compiler can infer them on its own,
using the definition provided:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;gt; :t Main.mymap
Main.mymap :: (t1 -&amp;gt; t) -&amp;gt; [t1] -&amp;gt; [t]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The compiler has determined that the first argument of &lt;tt class="docutils literal"&gt;mymap&lt;/tt&gt; is a generic
function, assigning its argument the type &lt;tt class="docutils literal"&gt;t1&lt;/tt&gt; and its return value the type
&lt;tt class="docutils literal"&gt;t&lt;/tt&gt;. The second argument of &lt;tt class="docutils literal"&gt;mymap&lt;/tt&gt; has the type &lt;tt class="docutils literal"&gt;[t1]&lt;/tt&gt;, which means &amp;quot;list
of &lt;tt class="docutils literal"&gt;t1&lt;/tt&gt;&amp;quot;; then the return value of &lt;tt class="docutils literal"&gt;mymap&lt;/tt&gt; has the type &amp;quot;list of &lt;tt class="docutils literal"&gt;t&lt;/tt&gt;&amp;quot;.
How was this accomplished?&lt;/p&gt;
&lt;p&gt;Let's start with the second argument. From the &lt;tt class="docutils literal"&gt;[] = []&lt;/tt&gt; variant, and also
from the &lt;tt class="docutils literal"&gt;(first:rest)&lt;/tt&gt; deconstruction, the compiler infers it has a list
type. But there's nothing else in the code constraining the element type, so the
compiler chooses a generic type specifier - &lt;tt class="docutils literal"&gt;t1&lt;/tt&gt;. &lt;tt class="docutils literal"&gt;f first&lt;/tt&gt; applies &lt;tt class="docutils literal"&gt;f&lt;/tt&gt; to
an element of this list, so &lt;tt class="docutils literal"&gt;f&lt;/tt&gt; has to take &lt;tt class="docutils literal"&gt;t1&lt;/tt&gt;; nothing constrains its
return value type, so it gets the generic &lt;tt class="docutils literal"&gt;t&lt;/tt&gt;. The result is &lt;tt class="docutils literal"&gt;f&lt;/tt&gt; has type
&lt;tt class="docutils literal"&gt;(t1 &lt;span class="pre"&gt;-&amp;gt;&lt;/span&gt; t)&lt;/tt&gt;, which in Haskell parlance means &amp;quot;a function from &lt;tt class="docutils literal"&gt;t1&lt;/tt&gt; to
&lt;tt class="docutils literal"&gt;t&lt;/tt&gt;&amp;quot;.&lt;/p&gt;
&lt;p&gt;Here is another example, written in a toy language I put together for the sake
of this post. The language is called &lt;strong&gt;microml&lt;/strong&gt;, and its implementation is
described at the end of the post:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;foo f g x = if f(x == 1) then g(x) else 20
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here &lt;tt class="docutils literal"&gt;foo&lt;/tt&gt; is declared as a function with three arguments. What is its type?
Let's try to run type inference manually. First, note that the body of the
function consists of an &lt;tt class="docutils literal"&gt;if&lt;/tt&gt; expresssion. As is common in programming
languages, this one has some strict typing rules in microml; namely, the type of
the condition is boolean (&lt;tt class="docutils literal"&gt;Bool&lt;/tt&gt;), and the types of the &lt;tt class="docutils literal"&gt;then&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;else&lt;/tt&gt;
clauses must match.&lt;/p&gt;
&lt;p&gt;So we know that &lt;tt class="docutils literal"&gt;f(x == 1)&lt;/tt&gt; has to return a &lt;tt class="docutils literal"&gt;Bool&lt;/tt&gt;. Moreover, since &lt;tt class="docutils literal"&gt;x&lt;/tt&gt; is
compared to an integer, &lt;tt class="docutils literal"&gt;x&lt;/tt&gt; is an &lt;tt class="docutils literal"&gt;Int&lt;/tt&gt;. What is the type of &lt;tt class="docutils literal"&gt;g&lt;/tt&gt;? Well, it
has an &lt;tt class="docutils literal"&gt;Int&lt;/tt&gt; argument, and it return value must match the type of the &lt;tt class="docutils literal"&gt;else&lt;/tt&gt;
clause, which is an &lt;tt class="docutils literal"&gt;Int&lt;/tt&gt; as well.&lt;/p&gt;
&lt;p&gt;To summarize:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The type of &lt;tt class="docutils literal"&gt;x&lt;/tt&gt; is &lt;tt class="docutils literal"&gt;Int&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;The type of &lt;tt class="docutils literal"&gt;f&lt;/tt&gt; is &lt;tt class="docutils literal"&gt;Bool &lt;span class="pre"&gt;-&amp;gt;&lt;/span&gt; Bool&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;The type of &lt;tt class="docutils literal"&gt;g&lt;/tt&gt; is &lt;tt class="docutils literal"&gt;Int &lt;span class="pre"&gt;-&amp;gt;&lt;/span&gt; Int&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So the overall type of &lt;tt class="docutils literal"&gt;foo&lt;/tt&gt; is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;((Bool -&amp;gt; Bool), (Int -&amp;gt; Int), Int) -&amp;gt; Int
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It takes three arguments, the types of which we have determined, and returns
an &lt;tt class="docutils literal"&gt;Int&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;Note how this type inference process is not just going in one direction, but
seems to be &amp;quot;jumping around&amp;quot; the body of the function figuring out known types
due to typing rules. This is why I call it bi-directional type inference,
but it's much better known as Hindley-Milner type inference, since it was
independently discovered by Roger Hindley in 1969 and Robin Milner in 1978.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="how-hindley-milner-type-inference-works"&gt;
&lt;h2&gt;How Hindley-Milner type inference works&lt;/h2&gt;
&lt;p&gt;We've seen a couple of examples of manually running type inference on some code
above. Now let's see how to translate it to an implementable algorithm. I'm
going to present the process in several separate stages, for simplicity. Some
other presentations of the algorithm combine several of these stages, but seeing
them separately is more educational, IMHO.&lt;/p&gt;
&lt;p&gt;The stages are:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Assign symbolic type names (like &lt;tt class="docutils literal"&gt;t1&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;t2&lt;/tt&gt;, ...) to all subexpressions.&lt;/li&gt;
&lt;li&gt;Using the language's typing rules, write a list of &lt;em&gt;type equations&lt;/em&gt; (or
&lt;em&gt;constraints&lt;/em&gt;) in terms of these type names.&lt;/li&gt;
&lt;li&gt;Solve the list of type equations using &lt;a class="reference external" href="https://eli.thegreenplace.net/2018/unification/"&gt;unification&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let's use this example again:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;foo f g x = if f(x == 1) then g(x) else 20
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Starting with &lt;strong&gt;stage 1&lt;/strong&gt;, we'll list all subexpressions in this
declaration (starting with the declaration itself) and assign unique type names
to them:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;foo                                       t0
f                                         t1
g                                         t2
x                                         t3
if f(x == 1) then g(x) else 20            t4
f(x == 1)                                 t5
x == 1                                    t6
x                                         t3
g(x)                                      t7
20                                        Int
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that every subexpression gets a type, and we de-duplicate them (e.g. &lt;tt class="docutils literal"&gt;x&lt;/tt&gt;
is encountered twice and gets the same type name assigned). Constant nodes get
known types.&lt;/p&gt;
&lt;p&gt;In &lt;strong&gt;stage 2&lt;/strong&gt;, we'll use the language's typing rules to write down equations
involving these type names. Usually books and papers use slightly scary formal
notation for typing rules; for example, for &lt;tt class="docutils literal"&gt;if&lt;/tt&gt;:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/67f9df5a4a93c7a445a1568ef49e5a5c3eab4fc5.svg" style="height: 41px;" type="image/svg+xml"&gt;\[\frac{\Gamma \vdash e_0 : Bool, \Gamma \vdash e_1 : T, \Gamma \vdash e_2 : T}{\Gamma \vdash if\: e_0\: then\: e_1\: else\: e_2 : T}\]&lt;/object&gt;
&lt;p&gt;All this means is the intuitive typing of &lt;tt class="docutils literal"&gt;if&lt;/tt&gt; we've described above: the
condition is expected to be boolean, and the types of the &lt;tt class="docutils literal"&gt;then&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;else&lt;/tt&gt;
clauses are expected to match, and their type becomes the type of the whole
expression.&lt;/p&gt;
&lt;p&gt;To unravel the notation, prepend &amp;quot;given that&amp;quot; to the expression above the line
and &amp;quot;we can derive&amp;quot; to the expression below the line;
&lt;object class="valign-m3" data="https://eli.thegreenplace.net/images/math/3e4033fef16d01026c5da2f9c029a352f2ad9537.svg" style="height: 16px;" type="image/svg+xml"&gt;\Gamma \vdash e_0 : Bool&lt;/object&gt; means that &lt;object class="valign-m3" data="https://eli.thegreenplace.net/images/math/7d22d6376548637fa828311e10662c6ab5e1b439.svg" style="height: 11px;" type="image/svg+xml"&gt;e_0&lt;/object&gt; is typed to Bool in
the set of typing assumptions called &lt;object class="valign-m1" data="https://eli.thegreenplace.net/images/math/4c596c27eb47af04b4c9c7534f796b1a3b7f28e4.svg" style="height: 13px;" type="image/svg+xml"&gt;\Gamma&lt;/object&gt;.&lt;/p&gt;
&lt;p&gt;Similarly, a typing rule for single-argument function application would be:&lt;/p&gt;
&lt;object class="align-center" data="https://eli.thegreenplace.net/images/math/a172aee1cd75a57dfd68b6ecf55868500c3bb9ae.svg" style="height: 41px;" type="image/svg+xml"&gt;\[\frac{\Gamma \vdash e_0 : T, \Gamma \vdash f : T \rightarrow U}{\Gamma \vdash f(e_0) : U}\]&lt;/object&gt;
&lt;p&gt;The real trick of type inference is running these typing rules &lt;em&gt;in reverse&lt;/em&gt;. The
rule tells us how to assign types to the whole expression given its constituent
types, but we can also use it as an equation that works both ways and lets us
infer constituent types from the whole expression's type.&lt;/p&gt;
&lt;p&gt;Let's see what equations we can come up with, looking at the code:&lt;/p&gt;
&lt;p&gt;From &lt;tt class="docutils literal"&gt;f(x == 1)&lt;/tt&gt; we infer &lt;tt class="docutils literal"&gt;t1 = (t6 &lt;span class="pre"&gt;-&amp;gt;&lt;/span&gt; t5)&lt;/tt&gt;, because &lt;tt class="docutils literal"&gt;t1&lt;/tt&gt; is the type of
&lt;tt class="docutils literal"&gt;f&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;t6&lt;/tt&gt; is the type of &lt;tt class="docutils literal"&gt;x == 1&lt;/tt&gt;, and &lt;tt class="docutils literal"&gt;t5&lt;/tt&gt; is the type of &lt;tt class="docutils literal"&gt;f(x ==
1)&lt;/tt&gt;. Note that we're using the typing rules for function application here.
Moreover, we can infer that &lt;tt class="docutils literal"&gt;t3&lt;/tt&gt; is &lt;tt class="docutils literal"&gt;Int&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;t6&lt;/tt&gt; is &lt;tt class="docutils literal"&gt;Bool&lt;/tt&gt; because
of the typing rule of the &lt;tt class="docutils literal"&gt;==&lt;/tt&gt; operator.&lt;/p&gt;
&lt;p&gt;Similarly, from &lt;tt class="docutils literal"&gt;g(x)&lt;/tt&gt; we infer &lt;tt class="docutils literal"&gt;t2 = (t3 &lt;span class="pre"&gt;-&amp;gt;&lt;/span&gt; t7)&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;From the &lt;tt class="docutils literal"&gt;if&lt;/tt&gt; expression, we infer that &lt;tt class="docutils literal"&gt;t6&lt;/tt&gt; is &lt;tt class="docutils literal"&gt;Bool&lt;/tt&gt; (since it's the
condition of the &lt;tt class="docutils literal"&gt;if&lt;/tt&gt;) and that &lt;tt class="docutils literal"&gt;t4 = Int&lt;/tt&gt;, because the &lt;tt class="docutils literal"&gt;then&lt;/tt&gt; and
&lt;tt class="docutils literal"&gt;else&lt;/tt&gt; clauses must match.&lt;/p&gt;
&lt;p&gt;Now we have a list of equations, and our task is to find the most general
solution, treating the equations as constraints. This is done by using the
unification algorithm which I described in detail in the &lt;a class="reference external" href="https://eli.thegreenplace.net/2018/unification/"&gt;previous post&lt;/a&gt;. The solution we're seeking
here is precisely the &lt;em&gt;most general unifier&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;For our expression, the algorithm will find the type of &lt;tt class="docutils literal"&gt;foo&lt;/tt&gt; to be:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;((Bool -&amp;gt; Bool), (Int -&amp;gt; Int), Int) -&amp;gt; Int)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As expected.&lt;/p&gt;
&lt;p&gt;If we make a slight modification to the expression to remove the comparison of
&lt;tt class="docutils literal"&gt;x&lt;/tt&gt; with 1:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;foo f g x = if f(x) then g(x) else 20
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then we can no longer constrain the type of &lt;tt class="docutils literal"&gt;x&lt;/tt&gt;, since all we know about it
is that it's passed into functions &lt;tt class="docutils literal"&gt;f&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;g&lt;/tt&gt;, and nothing else constrains
the arguments of these functions. The type inference process will thus calculate
this type for &lt;tt class="docutils literal"&gt;foo&lt;/tt&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;((a -&amp;gt; Bool), (a -&amp;gt; Int), a) -&amp;gt; Int
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It assigns &lt;tt class="docutils literal"&gt;x&lt;/tt&gt; the generic type name &lt;tt class="docutils literal"&gt;a&lt;/tt&gt;, and uses it for the arguments of
&lt;tt class="docutils literal"&gt;f&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;g&lt;/tt&gt; as well.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-implementation"&gt;
&lt;h2&gt;The implementation&lt;/h2&gt;
&lt;p&gt;An implementation of microml is &lt;a class="reference external" href="https://github.com/eliben/code-for-blog/tree/main/2018/type-inference"&gt;available here&lt;/a&gt;, as
a self-contained Python program that parses a microml declaration and infers its
type. The best starting point is &lt;tt class="docutils literal"&gt;main.py&lt;/tt&gt;, which spells out the stages of
type inference:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;foo f g x = if f(x == 1) then g(x) else 20&amp;#39;&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Code&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;----&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;code&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sep&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Parse the microml code snippet into an AST.&lt;/span&gt;
&lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Parser&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse_decl&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Parsed AST&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;----&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sep&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Stage 1: Assign symbolic typenames&lt;/span&gt;
&lt;span class="n"&gt;typing&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;assign_typenames&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Typename assignment&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;----&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="n"&gt;typing&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show_type_assignment&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sep&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Stage 2: Generate a list of type equations&lt;/span&gt;
&lt;span class="n"&gt;equations&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;typing&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;generate_equations&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;equations&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Equations&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;----&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sep&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;eq&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;equations&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="si"&gt;{:15}&lt;/span&gt;&lt;span class="s1"&gt; &lt;/span&gt;&lt;span class="si"&gt;{:20}&lt;/span&gt;&lt;span class="s1"&gt; | &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;eq&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;left&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;eq&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;right&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;eq&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;orig_node&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# Stage 3: Solve equations using unification&lt;/span&gt;
&lt;span class="n"&gt;unifier&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;typing&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unify_all_equations&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;equations&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Inferred type&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;----&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="n"&gt;typing&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_expression_type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;unifier&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rename_types&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
      &lt;span class="n"&gt;sep&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will print out:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Code
----
foo f g x = if f(x == 1) then g(x) else 20

Parsed AST
----
Decl(foo, Lambda([f, g, x], If(App(f, [(x == 1)]), App(g, [x]), 20)))

Typename assignment
----
Lambda([f, g, x], If(App(f, [(x == 1)]), App(g, [x]), 20))   t0
If(App(f, [(x == 1)]), App(g, [x]), 20)                      t4
App(f, [(x == 1)])                                           t5
f                                                            t1
(x == 1)                                                     t6
x                                                            t3
1                                                            Int
App(g, [x])                                                  t7
g                                                            t2
x                                                            t3
20                                                           Int

Equations
----
Int             Int                  | 1
t3              Int                  | (x == 1)
Int             Int                  | (x == 1)
t6              Bool                 | (x == 1)
t1              (t6 -&amp;gt; t5)           | App(f, [(x == 1)])
t2              (t3 -&amp;gt; t7)           | App(g, [x])
Int             Int                  | 20
t5              Bool                 | If(App(f, [(x == 1)]), App(g, [x]), 20)
t4              t7                   | If(App(f, [(x == 1)]), App(g, [x]), 20)
t4              Int                  | If(App(f, [(x == 1)]), App(g, [x]), 20)
t0              ((t1, t2, t3) -&amp;gt; t4) | Lambda([f, g, x], If(App(f, [(x == 1)]), App(g, [x]), 20))

Inferred type
----
(((Bool -&amp;gt; Bool), (Int -&amp;gt; Int), Int) -&amp;gt; Int)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;There are many more examples of type-inferred microml code snippets in the test
file &lt;tt class="docutils literal"&gt;test_typing.py&lt;/tt&gt;. Here's another example which is interesting:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;gt; foo f x = if x then lambda t -&amp;gt; f(t) else lambda j -&amp;gt; f(x)
((Bool -&amp;gt; a), Bool) -&amp;gt; (Bool -&amp;gt; a)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The actual inference is implemented in &lt;tt class="docutils literal"&gt;typing.py&lt;/tt&gt;, which is fairly well
commented and should be easy to understand after reading this post. The
trickiest part is probably the unification algorithm, but that one is just a
slight adaptation of the algorithm presented in the previous post.&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-1" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;p class="first"&gt;After this post was published, it was pointed out that another type
checking / inference technique is already called bi-directional (see
&lt;a class="reference external" href="https://arxiv.org/abs/1306.6032"&gt;this paper&lt;/a&gt; for example); while it's
related to Hindley-Milner (HM), it's a distinct method. Therefore, my
terminology here can create a confusion.&lt;/p&gt;
&lt;p class="last"&gt;I'll emphasize that my only use of the term &amp;quot;bi-directional&amp;quot; is to
distinguish what HM does from the simpler &amp;quot;uni-directional&amp;quot; inference
described at the beginning.&lt;/p&gt;
&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</content><category term="misc"></category><category term="Python"></category><category term="Programming"></category><category term="Haskell"></category></entry></feed>